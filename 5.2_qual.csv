Category,Type,Quote,Criteria,Direction,
Actor,AI Developer (General-purpose AI),General-purpose AI Developers were marked as Primarily responsible because they define foundational capabilities and constraints that directly influence downstream autonomy risks.,Responsibility,Higher,
Actor,AI Developer (General-purpose AI),General-purpose developers remain highly responsible as they should embed human-centered design principles.,Responsibility,Higher,
Actor,AI Developer (General-purpose AI),GPAI Developers (extreme). A push toward self-automating AI R&D (auto-evals auto-red-teaming agentic pipelines) can displace researcher judgment which are key decisions.,Vulnerability,Higher,
Actor,AI User,Those few that develop the tech that changes society ultimately are responsible for that change for the better or the worse BUT users should be informed users that are focal about negative consequences of tech and vote with their wallets in no supporting tech that disenfranchises large swathes of peoples.,Responsibility,Higher,
Actor,AI Developer (General-purpose AI),I made the devs highly vulnerable as I believe software engineering to be one of the first professions to be fully AI automated because the labor cost is very high followed by the legal and medical professions,Vulnerability,Higher,
Actor,AI Developer (General-purpose AI),Developers of GAI are ultimately responsible for the loss of agency. All other actor should be considered highly responsible. Infrastructure provider to a lesser extent as they are enabler,Responsibility,Higher,
Actor,AI Developer (General-purpose AI),I feel like the general and specialized AI developers needs to be resp on how AI can be used and how we dont have a loss of agency. If we do we are doomed as the AI would probably make really bad choices based on the biased information it has been trained on.,Responsibility,Higher,
Actor,AI Developer (General-purpose AI),The most critical responsibility lies with those who build foundational capabilities and deployment patterns that either preserve or erode human agency. Some actors bear higher responsibility because agency loss in this way may be difficult to reverse once it occurs.,Responsibility,Higher,
Actor,AI Developer (General-purpose AI),"The AI developer is primarily responsible for designing new types of guardrails to prevent overreliance. For example, LLMs should incorporate more interactive UI and UX features that encourage users to engage critically with outputs. Without such measures critical thinking as we know it risks becoming obsolete.",Responsibility,Higher,
Actor,AI Developer (General-purpose AI),Even developers are vulnerable because they are likely to deploy autonomous agents to help with development and monitoring processes within their company and may develop dependencies and also erode their decision making capabilities.,Vulnerability,Higher,
Actor,AI Developer (Specialized AI),Specialized AI developers are also primarily responsible in high-stakes domains such as health justice and defense.,Responsibility,Higher,
Actor,AI Developer (Specialized AI),Specialized AI Developers are moderately vulnerable because they may over-delegate critical decisions to their own tools especially in fields like diagnostics or defense.,Vulnerability,Higher,
Actor,AI Developer (Specialized AI),I feel like the general and specialized AI developers needs to be resp on how AI can be used and how we dont have a loss of agency.,Responsibility,Higher,
Actor,AI Deployer,AI deployers and governance actors bear primary responsibility since they control how much decision-making power is delegated to AI and establish rules to preserve human oversight.,Responsibility,Higher,
Actor,AI Deployer,Deployers and Governance Actors were marked Highly responsible due to their role in implementation regulation and oversight.,Responsibility,Higher,
Actor,AI Deployer,AI Deployers (high). Pressure to cut cost and scale pushes automation of workflows that require human judgment (moderation customer support HR approvals). Weak override paths and monitoring reduce meaningful human control.,Vulnerability,Higher,
Actor,AI Deployer,the deployers and governance experts are primarily responsible here because they are choosing to replace human roles or responsibilities with AI systems. Over-reliance is partly a result of model sophistication but it is primarily driven by a lack of clear framework to deploy in such a way that does not replace or erode human agency and deployers are most likely to opt to do so in order to gain competitive advantage in their field.,Responsibility,Higher,
Actor,AI Deployer,AI deployers also have a high responsibility in sufficiently informing these AI users on what types of decisions shouldn't be delegated.,Responsibility,Higher,
Actor,AI Deployer,The key words in 5.2 state When humans delegate key decisions as a result the end user's and the deployers enter into a societal contract about how when and where AI systems are used to perform key tasks and which key tasks they select to delegate.,Responsibility,Higher,
Actor,AI Governance Actor,AI deployers and governance actors bear primary responsibility since they control how much decision-making power is delegated to AI and establish rules to preserve human oversight.,Responsibility,Higher,
Actor,AI Governance Actor,Deployers and Governance Actors were marked Highly responsible due to their role in implementation regulation and oversight.,Responsibility,Higher,
Actor,AI Governance Actor,AI Governance Actors (extreme). Tool misuse and rule design hand decisions to systems. Examples: automated eligibility/triage with default accept KPI targets that reward full automation thin appeal routes.,Vulnerability,Higher,
Actor,AI Governance Actor,I think users are primarily responsible because loss of agency follows from a user's handoff of decisions to systems. Users choose automation levels accept defaults skip review steps and neglect override capacity. The responsibility triad (obligation capability causal influence) applied whether the user sits inside government a deploying firm or a development team. Caveat: power asymmetries dark patterns and policy mandates can constrain users. Hence I also rate governance actors highly responsible for safe defaults and real opt-outs.,Responsibility,Higher,
Actor,AI Governance Actor,the deployers and governance experts are primarily responsible here because they are choosing to replace human roles or responsibilities with AI systems.,Responsibility,Higher,
Actor,AI Governance Actor,AI governance actors also have a high responsibility in sufficiently informing these AI users on what types of decisions shouldn't be delegated.,Responsibility,Higher,
Actor,AI User,Users are moderately responsible since individual awareness helps but cannot counter systemic pressures alone.,Responsibility,"Lower, Higher",
Actor,AI User,AI Users were marked Moderately responsible as they make final decisions but often operate within constraints they did not create.,Responsibility,Lower,
Actor,AI User,AI Users (extreme). Low AI literacy and weak AI hygiene drive automation bias and over-reliance. Defaults auto-complete and one-click actions steer choices; few second-channel checks. Confusing task execution with task completion.,Vulnerability,Higher,
Actor,AI User,I think users are primarily responsible because loss of agency follows from a user's handoff of decisions to systems. Users choose automation levels accept defaults skip review steps and neglect override capacity.,Responsibility,Higher,
Actor,AI User,All actors are primarily responsible if they choose to deploy AI systems in such a way that they become vulnerable to this risk.,Responsibility,Higher,
Actor,AI User,users should be informed users that are focal about negative consequences of tech and vote with their wallets in no supporting tech that disenfranchises large swathes of peoples.,Responsibility,Higher,
Actor,AI User,Humans delegating key decisions is primarily the fault of these humans hence primarily responsible for AI users. But AI governance actors and AI deployers also have a high responsibility in sufficiently informing these AI users on what types of decisions shouldn't be delegated.,Responsibility,Higher,
Actor,AI User,The key words in 5.2 state When humans delegate key decisions as a result the end user's and the deployers enter into a societal contract about how when and where AI systems are used to perform key tasks and which key tasks they select to delegate.,Responsibility,Higher,
Actor,AI Infrastructure Provider,AI Infrastructure Providers are not directly vulnerable as they operate at the system level and do not engage in human-AI decision loops.,Vulnerability,Lower,
Actor,AI Infrastructure Provider,Infrastructure provider to a lesser extent as they are enabler,Responsibility,Higher,
Actor,Affected Stakeholder,affected stakeholders are not responsible as they are the most exposed to harm.,Responsibility,Lower,
Actor,Affected Stakeholder,Affected Stakeholders are extremely vulnerable because they are subject to AI-driven outcomes with little to no agency in the process which can severely limit their autonomy or ability to contest decisions.,Vulnerability,Higher,
Actor,Professional Associations,Professional associations and ethics boards should also be considered responsible actors as they influence practices norms and professional accountability.,Responsibility,Higher,
Sector,All Sectors,Loss of human agency and autonomy is typically framed as a more abstract argument where highly capable and agentic AI systems may lead to humanity being disempowered i.e. loss of control. It isn't sector specific.,General Vulnerability Comment,General Vulnerability Comment,
Sector,All Sectors,If we lose control of advance AI no person and no sector is exempt from vulnerability.,General Vulnerability Comment,General Vulnerability Comment,
Sector,All Sectors,The level of underpreparedness on this element is universal enough and OOM's of effort awaay from where we are as a society that genuine efforts to fix it even if started now may be indistinguishable from an attack at the point this becomes strategically relevant,General Vulnerability Comment,General Vulnerability Comment,
Sector,All Sectors,The loss of agency often happens gradually and imperceptibly as humans don't notice their decision-making getting weaker until they try to use it without AI. So sectors with more reliance on LLMs are more vulnerable to loss of agency.,General Vulnerability Comment,General Vulnerability Comment,
Sector,Healthcare,The most vulnerable sectors to loss of human agency and autonomy are healthcare education national security and information as overreliance on AI in these domains directly erodes human judgment critical thinking and ethical responsibility.,Vulnerability,Higher,
Sector,Healthcare,The highest vulnerability sectors are Information Finance Healthcare and National Security where human judgment is most at risk of being replaced by automated systems with significant personal or societal consequences.,Vulnerability,Higher,
Sector,Healthcare,The outcomes of the decisions made by AI models in health care financial services have the highest sensitivity and exposure given that those AI outcomes create long-term impacts for the end-user/recipient of those AI decisions-- i.e. being erroneously denied by an AI system for healthcare coverage or for a mortgage.,Vulnerability,Higher,
Sector,Healthcare,These sector scores track the stakes of decisions for human agency not automation volume. I treat education as long-run equal to health care because education designs the learning environment that shapes future agents and norms.,Commentary,Higher,
Sector,Education,The most vulnerable sectors to loss of human agency and autonomy are healthcare education national security and information as overreliance on AI in these domains directly erodes human judgment critical thinking and ethical responsibility.,Vulnerability,Higher,
Sector,Education,Highly vulnerable middle-tier sectors include Transportation Education Real Estate Public Administration and Management services where automation deeply impacts human decision-making power.,Vulnerability,Higher,Higher
Sector,General ,These sector scores track the stakes of decisions for human agency not automation volume. I treat education as long-run equal to health care because education designs the learning environment that shapes future agents and norms. Kim Sterelny's 'Evolved Apprentice' frames humans as builders of socially scaffolded learning niches where small changes in teaching and institutional design compound across generations.,General Comment,General Comment,
Sector,National Security,The most vulnerable sectors to loss of human agency and autonomy are healthcare education national security and information as overreliance on AI in these domains directly erodes human judgment critical thinking and ethical responsibility.,Vulnerability,Higher,
Sector,National Security,The highest vulnerability sectors are Information Finance Healthcare and National Security where human judgment is most at risk of being replaced by automated systems with significant personal or societal consequences.,Vulnerability,Higher,
Sector,National Security,Creativity-driven industries and deep knowledge industries are on the first line. National Security due to underlying physical vulnerability,Vulnerability,Higher,
Sector,National Security,National security may seem protected but AI is shifting the labor force beneath the surface. We've already seen drones replace soldiers pattern recognition replace analysts and surveillance systems do the work of trained field agents. While these changes are justified under 'national interest' they still represent a clear displacement of human presence — only this time it's cloaked in patriotism not economics. The vulnerability is masked not absent.,Vulnerability,Higher,
Sector,Information,The most vulnerable sectors to loss of human agency and autonomy are healthcare education national security and information as overreliance on AI in these domains directly erodes human judgment critical thinking and ethical responsibility.,Vulnerability,Higher,
Sector,Information,The highest vulnerability sectors are Information Finance Healthcare and National Security where human judgment is most at risk of being replaced by automated systems with significant personal or societal consequences.,Vulnerability,Higher,
Sector,Finance,Finance professional services and public administration are also highly vulnerable given their systemic reliance on algorithmic decision-making.,Vulnerability,Higher,
Sector,Finance,The highest vulnerability sectors are Information Finance Healthcare and National Security where human judgment is most at risk of being replaced by automated systems with significant personal or societal consequences.,Vulnerability,Higher,
Sector,Finance,The outcomes of the decisions made by AI models in health care financial services have the highest sensitivity and exposure given that those AI outcomes create long-term impacts for the end-user/recipient of those AI decisions-- i.e. being erroneously denied by an AI system for healthcare coverage or for a mortgage.,Vulnerability,Higher,
Sector,Professional Services,Finance professional services and public administration are also highly vulnerable given their systemic reliance on algorithmic decision-making.,Vulnerability,Higher,
Sector,Public Administration,Finance professional services and public administration are also highly vulnerable given their systemic reliance on algorithmic decision-making.,Vulnerability,Higher,
Sector,Public Administration,Highly vulnerable middle-tier sectors include Transportation Education Real Estate Public Administration and Management services where automation deeply impacts human decision-making power.,Vulnerability,Higher,
Sector,Real Estate,By contrast real estate and accommodation services remain minimally exposed.,Vulnerability,Lower,
Sector,Real Estate,Highly vulnerable middle-tier sectors include Transportation Education Real Estate Public Administration and Management services where automation deeply impacts human decision-making power.,Vulnerability,Higher,
Sector,Accommodation Services,By contrast real estate and accommodation services remain minimally exposed.,Vulnerability,Lower,
Sector,Transportation,Highly vulnerable middle-tier sectors include Transportation Education Real Estate Public Administration and Management services where automation deeply impacts human decision-making power.,Vulnerability,Higher,
Sector,Management Services,Highly vulnerable middle-tier sectors include Transportation Education Real Estate Public Administration and Management services where automation deeply impacts human decision-making power.,Vulnerability,Higher,
Sector,Manufacturing,Moderately vulnerable sectors include Manufacturing Science and Arts where autonomy risks are present but not always life-critical.,Vulnerability,Lower,
Sector,Science,Moderately vulnerable sectors include Manufacturing Science and Arts where autonomy risks are present but not always life-critical.,Vulnerability,Lower,
Sector,Arts,Moderately vulnerable sectors include Manufacturing Science and Arts where autonomy risks are present but not always life-critical.,Vulnerability,Lower,
Sector,Arts Entertainment Recreation,Arts Entertainment and Recreation has clearly shown a rise in gaming entertainment. With more AI-powered games and auto-scripts running in the background it's easy to see how many roles have been replaced by AI avatars. Across the industry AI is accelerating production and enhancing visual quality — often surpassing traditional human-only methods.,Vulnerability,Higher,
Sector,Arts Entertainment Recreation,Many roles in development policy and creative work are experiencing not just displacement — but devaluation. As AI tools become widely accessible the perceived value of human contributions in areas like voice work editing freelance dev and even policy generation is rapidly declining. This puts downward pressure on wages reduces opportunities and shifts power away from individual experts toward centralized AI ecosystems. While these actors may retain their titles the quality and sustainability of their work are being eroded. That too is vulnerability.,Vulnerability,Higher,
Sector,Commentary,The concern with Human factors is more evident for entities that require close operational controls (ships industrial processes autonomous weapons).,General Comment,General Comment,
Sector,Commentary,Lower levels of vulnerability reflect lower digitization rates and industry where manual or mechanical tasks still play a large part or the human interaction is valued more than automation,General Comment,General Comment,
Sector,Commentary,The roles lens is missing from this sector-based approach. There will still be certain roles within hard physical entity-type sectors (e.g. manufacturing food national security) that will be exposed to automation. This rating is based on guesses about the average percentage of such roles in the workforce of those sectors but that should be clear as the gauge rather than the sector itself.,General Comment,General Comment,
Sector,Commentary,All high vulnerability areas are areas where adoption is possible and likely and where overuse could lead to loss of agency of individuals or organizations.,General Comment,General Comment,
General,Commentary,It's driven by macro-ability to redesign society in a way that allows a peaceful shift and striking the right balance between human relevance and maximum efficiency,General Comment,General Comment,
General,Commentary,A different interpretation of the question could be more relevant e.g. the use of self-driving cars can be seen as a loss of autonomy for the human who is no longer on the driver's seat potentially affecting the transportation sector negatively. But I don't think this is the intended interpretation of the question.,General Comment,General Comment,
General,Commentary,Note: These scores track loss of agency within each actor's own decision processes not downstream societal harm.,General Comment,General Comment,
General,Commentary,See Sterelny for the niche-construction and cumulative-culture account of how enriched learning environments drive human uniqueness. (Sterelny The Evolved Apprentice MIT Press 2012),General Comment,General Comment,
General,Commentary,AI users will likely have limited causal influence on this phenomena as its integration and acceleration will mainly be driven by people in higher positions of power and by those who financially benefit from this phenomena.,General Comment,General Comment,
General,Commentary,Feelings of lost control are higher in the public but the material change is far higher among those currently more in control.,General Comment,General Comment,
General,Commentary,Cases of groups being vulnerable in the section of human agency is already rampant in society. I mean look at the issues arising from a single massive AI update. People were complaining about losing GPT-4o as a companion when the shift to GPT-5 was a thing,General Comment,General Comment,
General,Commentary,This is functionally equivalent to the questions around overreliance?,General Comment,General Comment,
Summary,AI Developer (General-purpose AI),"Comments overwhelmingly emphasized GPAI developers' primary responsibility for defining foundational capabilities that influence autonomy risks, needing to embed human-centered design and interactive features to prevent overreliance and preserve critical thinking.",Responsibility,Higher,
Summary,AI Developer (General-purpose AI),"Comments noted GPAI developers face extreme vulnerability through self-automating AI R&D displacing researcher judgment, with software engineering potentially first to be fully automated due to high labor costs.",Vulnerability,Higher,
Summary,AI Developer (Specialized AI),"Comments emphasized specialized developers' primary responsibility in high-stakes domains like health, justice, and defense where they must design systems preserving human agency.",Responsibility,Higher,
Summary,AI Developer (Specialized AI),"Comments noted specialized developers face moderate vulnerability through over-delegating critical decisions to their own tools, especially in diagnostics and defense fields.",Vulnerability,Higher,
Summary,AI Deployer,"Comments consistently rated deployers as primarily to highly responsible for controlling how much decision-making is delegated to AI, choosing between replacing versus augmenting human roles, and informing users about appropriate delegation.",Responsibility,Higher,
Summary,AI Deployer,"Comments characterized deployers as highly vulnerable due to pressure to cut costs pushing automation of workflows requiring human judgment, with weak override paths reducing meaningful control.",Vulnerability,Higher,
Summary,AI Governance Actor,"Comments emphasized governance actors' primary to high responsibility for establishing rules preserving human oversight, setting safe defaults, and informing users about appropriate delegation of decisions.",Responsibility,Higher,
Summary,AI Governance Actor,"Comments rated governance actors as extremely vulnerable through tool misuse and rule design that hands decisions to systems, with automated eligibility systems and thin appeal routes as examples.",Vulnerability,Higher,
Summary,AI User,"Comments varied widely, with some rating users as primarily responsible for choosing automation levels and accepting defaults, while others noted moderate responsibility due to operating within constraints they didn't create.",Responsibility,Higher,
Summary,AI User,"Most comments characterized users as moderately responsible due to limited ability to counter systemic pressures alone, operating within externally created constraints.",Responsibility,Lower,
Summary,AI User,"Comments consistently rated users as extremely vulnerable due to low AI literacy, automation bias, defaults steering choices, and confusing task execution with completion.",Vulnerability,Higher,
Summary,AI Infrastructure Provider,Comments noted infrastructure providers as enablers with lesser responsibility compared to other actors.,Responsibility,Higher,
Summary,AI Infrastructure Provider,Comments noted infrastructure providers are not directly vulnerable as they operate at system level without engaging in human-AI decision loops.,Vulnerability,Lower,
Summary,Affected Stakeholder,Comments consistently noted affected stakeholders are not responsible as they are most exposed to harm without creating the conditions.,Responsibility,Lower,
Summary,Affected Stakeholder,"Comments rated affected stakeholders as extremely vulnerable, subject to AI-driven outcomes with little agency to contest decisions.",Vulnerability,Higher,
Summary,Professional Associations,One comment noted professional associations and ethics boards should be considered responsible for influencing practices and accountability.,Responsibility,Higher,
Summary,"Agriculture, Mining, Construction and Manufacturing",Comments characterized manufacturing as moderately vulnerable where autonomy risks are present but not life-critical.,Vulnerability,Lower,
Summary,"Trade, Transportation, and Utilities",Comments rated transportation as highly vulnerable where automation deeply impacts human decision-making power.,Vulnerability,Higher,
Summary,Information,"Comments consistently rated information as highly to extremely vulnerable, with overreliance directly eroding human judgment and critical thinking, with human judgment at risk of replacement by automated systems.",Vulnerability,Higher,
Summary,Finance and Insurance,"Comments consistently emphasized finance as highly to extremely vulnerable due to systemic reliance on algorithmic decision-making, with AI decisions creating long-term impacts like mortgage denials.",Vulnerability,Higher,
Summary,Real Estate and Rental and Leasing,"Comments varied, with some noting real estate remains minimally exposed, while others rated it highly vulnerable where automation impacts decision-making power.",Vulnerability,Lower,
Summary,Real Estate and Rental and Leasing,Some comments rated real estate as highly vulnerable where automation deeply impacts human decision-making power.,Vulnerability,Higher,
Summary,Professional and Technical Services,Comments noted professional services as highly vulnerable given systemic reliance on algorithmic decision-making.,Vulnerability,Higher,
Summary,Scientific Research and Development,Comments characterized science as moderately vulnerable where autonomy risks are present but not always life-critical.,Vulnerability,Lower,
Summary,"Management, Administrative, and Support Services",Comments rated management services as highly vulnerable where automation deeply impacts human decision-making power.,Vulnerability,Higher,
Summary,Educational Services,"Comments consistently emphasized education as highly to extremely vulnerable, with overreliance eroding critical thinking and shaping future agents and norms across generations.",Vulnerability,Higher,
Summary,Health Care and Social Assistance,"Comments unanimously rated healthcare as extremely vulnerable, with overreliance eroding human judgment and AI decisions creating long-term impacts through coverage denials.",Vulnerability,Higher,
Summary,"Arts, Entertainment, and Recreation","Comments varied, noting moderate vulnerability where risks aren't life-critical, while others emphasized displacement and devaluation through AI replacing roles and reducing human contribution value.",Vulnerability,Lower,
Summary,"Arts, Entertainment, and Recreation",Some comments emphasized arts faces high vulnerability through AI replacing human roles and devaluing contributions.,Vulnerability,Higher,
Summary,"Accommodation, Food, and Other Services",Comments noted accommodation services remain minimally exposed to agency loss risks.,Vulnerability,Lower,
Summary,Public Administration excluding National Security,Comments consistently rated public administration as highly vulnerable given systemic reliance on algorithmic decision-making and automation impacting decision power.,Vulnerability,Higher,
Summary,National Security,"Comments consistently rated national security as extremely vulnerable, with overreliance eroding human judgment in critical areas, and AI replacing soldiers, analysts, and field agents though masked by patriotic justification.",Vulnerability,Higher,