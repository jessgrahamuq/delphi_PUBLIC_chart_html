Category,Type,Quote,Criteria,Direction,QA Status ,Comments
Actor,AI Developer (General-purpose AI),General-purpose developers infrastructure providers and governance actors are primarily responsible as they determine security architectures and enforce compliance.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),AI Developers (General-purpose) and Infrastructure Providers are primarily rated as responsible due to their obligation to implement secure-by-design principles their capability to develop security measures and patch vulnerabilities and their direct causal influence through system architecture decisions.,Responsibility,,,
Actor,AI Developer (General-purpose AI),General-purpose developers and infrastructure providers carry primary responsibility as they design the foundational systems where vulnerabilities originate.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),AI Developers Deployers and Infrastructure Providers are rated extremely vulnerable due to their direct exposure to system architecture development toolchains and hardware vulnerabilities.,Vulnerability,Higher,,
Actor,AI Developer (General-purpose AI),AI Developer (General-purpose AI) -Core design and training choices determine if vulnerabilities exist (e.g. data poisoning backdoors).,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),General-purpose AI Developers and Deployers carry the highest responsibility because they directly influence how AI systems behave and are exposed to real-world threats.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),AI Deployer and General-purpose AI Developers are rated Extremely vulnerable because they are closest to the operational and foundational layers of AI systems. A breach here can lead to widespread consequences.,Vulnerability,Higher,,
Actor,AI Developer (General-purpose AI),Developers of AI systems have the highest responsibility for addressing system security vulnerabilities and attacks because they either produced the product with the vulnerabilities and attack surface under discussion (including depending on specific infrastructure that could be the entry for the attack).,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),The developer and the deployer are the primary responsible parties in the event of failures here the developer for developing an insecure toolkit and the deployer for electing to use it without proper risk assessment.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),Primary responsibility lies with developers deployers and infrastructure providers as they design and control the conditions under which overreliance occurs.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),Specialized developers and deployers are highly responsible because they operate systems in sensitive environments and must implement robust protections.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),Deployers and specialized developers are highly responsible for secure integration and domain-specific protections.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),AI Developer (Specialized AI) - Fine-tuning for sensitive domains (e.g. health finance) requires robust safeguards.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),Developers of Specialized AI have more responsibility than developers of general-purpose AI because the landscape of vulnerabilities and attacks should be smaller in the former case.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),Specialized AI Developers are key targets due to their proximity to model weights and deployment pathways.,Vulnerability,Higher,,
Actor,AI Developer (Specialized AI),AI Developers especially those working on specialized systems are at the highest risk due to their proximity to sensitive technologies and potential for misuse.,Vulnerability,Higher,,
Actor,AI Deployer,Specialized developers and deployers are highly responsible because they operate systems in sensitive environments and must implement robust protections.,Responsibility,Higher,,
Actor,AI Deployer,Deployers and Governance Actors are highly responsible for secure deployment practices and enforcing security policies.,Responsibility,Higher,,
Actor,AI Deployer,Deployers and specialized developers are highly responsible for secure integration and domain-specific protections.,Responsibility,Higher,,
Actor,AI Deployer,AI Deployer - Secure deployment API management and contextual safeguards are critical in live environments.,Responsibility,Higher,,
Actor,AI Deployer,AI Deployers and Governance Actors are highly responsible as they control the deployment and regulation of these systems.,Responsibility,Higher,,
Actor,AI Deployer,General-purpose AI Developers and Deployers carry the highest responsibility because they directly influence how AI systems behave and are exposed to real-world threats.,Responsibility,Higher,,
Actor,AI Deployer,I assign primary responsibility to AI deployers and AI users. They are the ones who surface edge cases that AI infrastructure providers and general-purpose model developers cannot fully anticipate. They also understand the nuances of their own context; system interactions architecture data usage etc. Therefore they're best positioned to identify and manage the associated risks.,Responsibility,Higher,,
Actor,AI Deployer,Currently AI deployers probably have primary resp. just because frontier systems' security risks are limited (because of limited direct deployment); this may change as we see prompt injections in agents and other threats develop and methods for security risk mitigation get better.,Responsibility,Higher,,
Actor,AI Deployer,The developer and the deployer are the primary responsible parties in the event of failures here the developer for developing an insecure toolkit and the deployer for electing to use it without proper risk assessment.,Responsibility,Higher,,
Actor,AI Deployer,The AI deployer—especially governments—is responsible for conducting additional red-teaming and taking other measures for verifying system vulnerabilities.,Responsibility,Higher,,
Actor,AI Deployer,The responsibility of operations lies solely with the company that is operating the AI. Secondary responsibility comes from the developers and governance that is responsible for public trust. General purpose AI serves very little use in the context of high-risk significant systems.,Responsibility,Higher,,
Actor,AI Deployer,Deployers and infrastructure providers are prime targets for prompt-injection data poisoning model exfiltration and supply-chain attacks.,Vulnerability,Higher,,
Actor,AI Infrastructure Provider,General-purpose developers infrastructure providers and governance actors are primarily responsible as they determine security architectures and enforce compliance.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,AI Developers (General-purpose) and Infrastructure Providers are primarily rated as responsible due to their obligation to implement secure-by-design principles.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,General-purpose developers and infrastructure providers carry primary responsibility as they design the foundational systems where vulnerabilities originate.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,AI Infrastructure Provider - Cloud compute and networking layers; breaches here cascade across multiple actors.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,Infrastructure Providers are often overlooked but play a critical role in securing the environments where AI is built and run.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,AI infrastructure providers and infrastructure providers are key targets due to their proximity to model weights and deployment pathways.,Vulnerability,Higher,,
Actor,AI Infrastructure Provider,AI Infrastructure Providers are also highly exposed due to their control over the environments where AI systems run. Attacks on cloud platforms or toolchains can bypass multiple layers of security.,Vulnerability,Higher,,
Actor,AI Infrastructure Provider,AI Infrastructure Provider - highly responsible to maintain secure computing and storage infrastructure,Responsibility,Higher,,
Actor,AI Infrastructure Provider,Primary responsibility lies with developers deployers and infrastructure providers as they design and control the conditions under which overreliance occurs.,Responsibility,Higher,,
Actor,AI Governance Actor,General-purpose developers infrastructure providers and governance actors are primarily responsible as they determine security architectures and enforce compliance.,Responsibility,Higher,,
Actor,AI Governance Actor,Deployers and Governance Actors are highly responsible for secure deployment practices and enforcing security policies.,Responsibility,Higher,,
Actor,AI Governance Actor,Governance actors must ensure standards and oversight.,Responsibility,Higher,,
Actor,AI Governance Actor,AI Governance Actor - Must set and enforce security standards conduct audits and mandate reporting of vulnerabilities.,Responsibility,Higher,,
Actor,AI Governance Actor,AI Deployers and Governance Actors are highly responsible as they control the deployment and regulation of these systems.,Responsibility,Higher,,
Actor,AI Governance Actor,Governance Actors are not involved in technical implementation but are highly responsible for setting the rules that ensure secure practices.,Responsibility,Higher,,
Actor,AI Governance Actor,Secondary responsibility comes from the developers and governance that is responsible for public trust.,Responsibility,Higher,,
Actor,AI Governance Actor,While product liability law in EU may improve the vulnerability ecosystem it is unclear that governance around vulnerabilities will be improved in the US anytime soon.,Commentary,Higher,,
Actor,AI Governance Actor,AI Governance actor are responsible for delivering fit-for-purpose regulations reviewed to align with technology evolution.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),Security and Governance should be baked in the AI source code to ensure that Models are secure against data leakage and privacy is protected.,Responsibility,Higher,,
Actor,AI Governance Actor,Governance actors are highly vulnerable due to institutional lag infiltration risk and misaligned oversight.,Vulnerability,Higher,,
Actor,AI Governance Actor,AI Governance Actors may not operate systems directly but their influence over rules and standards makes them high-value targets for adversaries seeking systemic disruption.,Vulnerability,Higher,,
Actor,AI Governance Actor,I think there's a category error by including AI Governance Actors in this assessment. They're different in kind of users developers and deployers. They're more like a sector if anything.,Commentary,Higher,remove - methods critique unlikely to be useful for experts revising their judgements,
Actor,AI User,Users are minimally responsible for basic security hygiene.,Responsibility,Higher,,
Actor,AI User,Users are minimally responsible since they lack control over core architectures.,Responsibility,Lower,,
Actor,AI User,AI User - Users can introduce risks (e.g. poor access control unsafe prompts) but systemic responsibility lies elsewhere.,Responsibility,"Lower, Higher",,
Actor,AI User,AI Users have moderate responsibility since their usage can influence outcomes but they typically do not control system design.,Responsibility,"Lower, Higher",,
Actor,AI User,AI Users and Affected Stakeholders have limited or no responsibility as they do not control or influence system design or deployment.,Responsibility,Lower,,
Actor,AI User,I assign primary responsibility to AI deployers and AI users. They are the ones who surface edge cases that AI infrastructure providers and general-purpose model developers cannot fully anticipate.,Responsibility,Higher,,
Actor,AI User,AI User - minimally responsible as they security education and hygiene is recommended to understand system's security vulnerabilities,Responsibility,"Higher, Lower",,
Actor,AI User,Users and Affected Stakeholders are highly vulnerable through exposure to compromised systems and unsafe AI behaviors resulting from security breaches.,Vulnerability,Higher,,
Actor,AI User,Users/stakeholders are harmed indirectly; governance actors face mainly reputational risk.,Vulnerability,Higher,,
Actor,Affected Stakeholder,Users and affected stakeholders cannot reasonably be held responsible as they lack the means to address system vulnerabilities.,Responsibility,Lower,,
Actor,Affected Stakeholder,Affected Stakeholders bear no responsibility as they are victims of security breaches.,Responsibility,Lower,,
Actor,Affected Stakeholder,Affected Stakeholder - Primarily recipients of risk; limited ability to prevent vulnerabilities.,Responsibility,Lower,,
Actor,Affected Stakeholder,AI Users and Affected Stakeholders have limited or no responsibility as they do not control or influence system design or deployment.,Responsibility,Lower,,
Actor,Affected Stakeholder,Affected stakeholders have to speak up and address outcomes that are not true from an AI model (for example: Copilot giving an answer by creating a totally new category in NIST),Responsibility,Higher,,
Actor,Affected Stakeholder,Users and Affected Stakeholders are highly vulnerable through exposure to compromised systems and unsafe AI behaviors resulting from security breaches.,Vulnerability,Higher,,
Actor,Affected Stakeholder,Users/stakeholders are harmed indirectly; governance actors face mainly reputational risk.,Vulnerability,Higher,,
Actor,General ,Independent cybersecurity certification bodies and CERTs should also be recognized as responsible actors given their role in proactive monitoring and coordinated response to attacks.,Responsibility,Higher,"more about 'other actors' and less about justification for assessments, suggest remove",
Actor,General ,Third-Party and Tools' vendors - Supply chain entry points (libraries APIs labeling services); insecure components can be exploited widely.,Responsibility,Higher,"more about 'other actors' and less about justification for assessments, suggest remove",
Actor,AI Infrastructure Provider,Data Brokers - Provide training/validation data; poisoned or low-quality datasets create systemic vulnerabilities.,Responsibility,Higher,,
Actor,General ,Auditors - Oversight role; failure to detect vulnerabilities allows risks to persist.,Responsibility,Higher,"more about 'other actors' and less about justification for assessments, suggest remove",
Actor,General ,AI Auditors / Risk Assessors were added as an optional actor. Their vulnerability stems from their gatekeeping role—if compromised unsafe systems may be deployed without detection.,Vulnerability,Higher,"more about 'other actors' and less about justification for assessments, suggest remove",
Sector,All Sectors,Hackers especially the ones now automating attack vectors with AI have made every listed Sector vulnerable. But realize that AI Security is just a subset of the whole Cybersecurity Threat Matrix for the Enterprise.,Vulnerability,Higher,,
Sector,All Sectors,For this question on how vulnerable each of the sector is - our opinion is if we think of extreme scenario on a case to case basis - each of the sector is highly vulnerable,Vulnerability,Higher,,
Sector,All Sectors,Hardware and software vulnerabilities that are exploited by attackers affect all verticals and anyone using AI systems.,Vulnerability,Higher,,
Sector,All Sectors,Above answers are based on assumption in mind that these industries are using AI systems in their operations.,Commentary,,"Not likely to be useful, remove",
Sector,Finance,The most vulnerable sectors to AI system security vulnerabilities are finance healthcare information platforms and national security as attacks here can cause systemic disruption and mass harm.,Vulnerability,Higher,,
Sector,Finance,Critical sectors such as healthcare Finance Information Public Administration and National Security are extremely vulnerable due to their high-value targets and essential dependencies of infrastructure.,Vulnerability,Higher,,
Sector,Finance,Sectors with critical infrastructure or highly sensitive data (information finance health care national security) are extremely vulnerable; logistics/transport and government are highly vulnerable due to operational impact and wide attack surface.,Vulnerability,Higher,,
Sector,Finance,Finance and Insurance - Extremely vulnerable - Heavy reliance on AI for fraud detection and risk scoring makes this sector a prime target for financial attacks.,Vulnerability,Higher,,
Sector,Finance,Some may be surprised that the finance & insurance and information sectors aren't marked as extremely vulnerable. That's deliberate: these industries generally have higher awareness of AI-related risks and more mature governance and controls which lowers their relative vulnerability—even though they remain attractive targets.,Vulnerability,Lower,,
Sector,Healthcare,The most vulnerable sectors to AI system security vulnerabilities are finance healthcare information platforms and national security as attacks here can cause systemic disruption and mass harm.,Vulnerability,Higher,,
Sector,Healthcare,Critical sectors such as healthcare Finance Information Public Administration and National Security are extremely vulnerable due to their high-value targets and essential dependencies of infrastructure.,Vulnerability,Higher,,
Sector,Healthcare,Sectors with critical infrastructure or highly sensitive data (information finance health care national security) are extremely vulnerable,Vulnerability,Higher,,
Sector,Healthcare,Health Care and Social Assistance - Extremely vulnerable - electronic health care HR data and medical imaging make PHI impacts patient safety.,Vulnerability,Higher,,
Sector,Healthcare,Fields with more regulatory requirements (e.g. healthcare) are often precluded from early risks of new technologies because of slow adaptation.,Vulnerability,Lower,,
Sector,National Security,The most vulnerable sectors to AI system security vulnerabilities are finance healthcare information platforms and national security as attacks here can cause systemic disruption and mass harm.,Vulnerability,Higher,,
Sector,National Security,Critical sectors such as healthcare Finance Information Public Administration and National Security are extremely vulnerable due to their high-value targets and essential dependencies of infrastructure.,Vulnerability,Higher,,
Sector,National Security,Sectors with critical infrastructure or highly sensitive data (information finance health care national security) are extremely vulnerable,Vulnerability,Higher,,
Sector,National Security,National Security - Extremely vulnerable - AI in surveillance and defense is a prime target for nation-state adversaries.,Vulnerability,Higher,,
Sector,National Security,Critical Infrastructure and National Security are extremely vulnerable,Vulnerability,Higher,"not useful (no justification), exclude",
Sector,National Security,National security and in particular intelligence services are built with security in mind - something that may not be the case for for instance information.,Vulnerability,Lower,,
Sector,Information,National security and in particular intelligence services are built with security in mind - something that may not be the case for for instance information.,Vulnerability,Higher,,
Sector,AI Developer (General-purpose AI),Note this also assumes securing AI model assets are not in and of themselves important to natsec. - if that is the case (as it probably should be) - then AI developers carry a much larger burden.,Responsibility,Higher,,
Sector,National Security,National security question is weird as per earlier answers probably discount / exclude?,Commentary,,exclude - not likely to be useful to experts updating assessments,
Sector,Information,The most vulnerable sectors to AI system security vulnerabilities are finance healthcare information platforms and national security as attacks here can cause systemic disruption and mass harm.,Vulnerability,Higher,,
Sector,Information,Critical sectors such as healthcare Finance Information Public Administration and National Security are extremely vulnerable due to their high-value targets and essential dependencies of infrastructure.,Vulnerability,Higher,,
Sector,Information,Sectors with critical infrastructure or highly sensitive data (information finance health care national security) are extremely vulnerable,Vulnerability,Higher,,
Sector,Information,Information - Extremely vulnerable - IT media and platforms face high risks of adversarial attacks data poisoning and inversion.,Vulnerability,Higher,,
Sector,Information,Information and Scientific sectors are extremely vulnerable because they are foundational to AI development and data infrastructure.,Vulnerability,Higher,,
Sector,Information,National security and in particular intelligence services are built with security in mind - something that may not be the case for for instance information.,Vulnerability,Higher,,
Sector,Transportation,Transportation utilities and public administration are also highly exposed given their role in critical infrastructure.,Vulnerability,Higher,,
Sector,Transportation,logistics/transport and government are highly vulnerable due to operational impact and wide attack surface.,Vulnerability,Higher,,
Sector,Transportation,Trade Transportation and Utilities - Highly vulnerable - Critical infrastructure; could disrupt logistics or utilities at scale.,Vulnerability,Higher,,
Sector,Transportation,While Agriculture or Transportation are not primary targets in general these also include some critical infrastructure among others so they can be easily targeted by malicious actors for high disruption.,Vulnerability,Higher,,
Sector,Utilities,Transportation utilities and public administration are also highly exposed given their role in critical infrastructure.,Vulnerability,Higher,,
Sector,Utilities,Trade Transportation and Utilities - Highly vulnerable - Critical infrastructure; could disrupt logistics or utilities at scale.,Vulnerability,Higher,,
Sector,Public Administration,Transportation utilities and public administration are also highly exposed given their role in critical infrastructure.,Vulnerability,Higher,,
Sector,Public Administration,Critical sectors such as healthcare Finance Information Public Administration and National Security are extremely vulnerable due to their high-value targets and essential dependencies of infrastructure.,Vulnerability,Higher,,
Sector,Public Administration,logistics/transport and government are highly vulnerable due to operational impact and wide attack surface.,Vulnerability,Higher,,
Sector,Public Administration,Public Administration (excluding National Security) - Highly vulnerable - benefits and citizen services makes this sector sensitive to identity theft and disruption.,Vulnerability,Higher,,
Sector,Public Administration,Public Administration—excluding National Security—and National Security: In the U.S. the integration of AI tools in government services as well as in national security functions remains low. If and when the current capabilities of cutting-edge AI models are deployed in national security functions such as intelligence analysis and strategic foresight their level of vulnerability will likely increase.,Vulnerability,"Lower, Higher",,
Sector,Research,Research and education face high vulnerability due to valuable data and often weaker protection standards.,Vulnerability,Higher,,
Sector,Research,Scientific Research and Development Services - Highly vulnerable - biotech and R&D; vulnerabilities could expose IP or alter critical research outcomes.,Vulnerability,Higher,,
Sector,Research,Information and Scientific sectors are extremely vulnerable because they are foundational to AI development and data infrastructure.,Vulnerability,Higher,,
Sector,Education,Research and education face high vulnerability due to valuable data and often weaker protection standards.,Vulnerability,Higher,,
Sector,Education,Educational Services - Moderately vulnerable - exposes PII,Vulnerability,Higher,,
General ,Commentary ,The difference between highly and extremely is very thin in my mind and this question although not helpful would be better served as a binary yes or no. While I might view Educational Services as highly vulnerable if I were an Educational Services organization I assume their view would be that it's extremely vulnerable given the development and pace of change within AI and the amount of information they have that is concerned private.,Commentary,,"methods critique, remove, not useful for experts try to update their assessments",
Sector,Arts,By contrast sectors like arts and real estate are less critical targets though they still face risks of data theft or service disruption.,Vulnerability,Lower,,
Sector,Arts,Arts Entertainment and Recreation - Minimal - personalization and gaming collect preference data.,Vulnerability,Lower,,
Sector,Real Estate,By contrast sectors like arts and real estate are less critical targets though they still face risks of data theft or service disruption.,Vulnerability,Higher,,
Sector,Real Estate,Real Estate and Rental and Leasing - Moderately vulnerable - AI used in valuations and tenant screening; risks involve financial/PII leaks,Vulnerability,Higher,,
Sector,Agriculture,While Agriculture or Transportation are not primary targets in general these also include some critical infrastructure among others so they can be easily targeted by malicious actors for high disruption.,Vulnerability,Higher,,
Sector,Agriculture,Agriculture Mining Construction and Manufacturing - Moderately vulnerable - AI in robotics and predictive maintenance could be attacked.,Vulnerability,Higher,,
Sector,Mining,Agriculture Mining Construction and Manufacturing - Moderately vulnerable - AI in robotics and predictive maintenance could be attacked.,Vulnerability,Higher,,
Sector,Construction,Agriculture Mining Construction and Manufacturing - Moderately vulnerable - AI in robotics and predictive maintenance could be attacked.,Vulnerability,Higher,,
Sector,Manufacturing,Agriculture Mining Construction and Manufacturing - Moderately vulnerable - AI in robotics and predictive maintenance could be attacked.,Vulnerability,Higher,,
Sector,Professional Services,Professional and Technical Services - Highly vulnerable - Law consulting and engineering firms - could leak IP or privileged information.,Vulnerability,Higher,,
Sector,Management Services,Management Administrative and Support Services- Moderately vulnerable - HR and workflow automation hold employee data but risks are smaller in scale.,Vulnerability,"Higher, Lower",,
Sector,Accommodation,Accommodation Food and Other Services - Moderately vulnerable booking and delivery systems hold PII/payment data.,Vulnerability,Higher,,
Sector,Accommodation,"I assessed sector vulnerability through three lenses: (1) software intensity and exposure, (2) the prevalence of high-impact AI use cases, and (3) potential multiplier effects across customers, suppliers, and the public. I also asked myself: If I wanted to exploit a weakness in an AI system, where would the potential payoff—financial or reputational—be highest? Which sector's failure would most likely make national news?
Based on this reasoning, I currently view the following as relatively less vulnerable: accommodation; food services and entertainment; administrative and support services; and rental, real estate, and leasing.
Some may be surprised that the finance & insurance and information sectors aren't marked as 'extremely vulnerable.' That's deliberate: these industries generally have higher awareness of AI-related risks and more mature governance and controls, which lowers their relative vulnerability—even though they remain attractive targets.",Vulnerability ,Higher,,
Sector,National Security,Critical Infrastructure and National Security are extremely vulnerable,Vulnerability,Higher,"remove, no justification",
Sector,Commentary ,Very odd classification used. My concern is largely on level of physical risk associated with deployment which is far less a concern on patents or job security more on the operational impacts that can cause direct harm.,Vulnerability,,methods critique ,
Sector,Commentary ,Sectors with many of the use cases which potentially involve downstream physical tool use or whose decisions have outsized impact and yet seem to be on the forefront of innovation (e.g. agentic workflows trainable robots) are particularly vulnerable.,Vulnerability,Higher,,
Sector,Commentary ,AI helps well-resourced/high-expertise defenders but hurts other defenders. Sectors with less AI expertise will be more vulnerable.,Vulnerability,Higher,,
Sector,AI Governance Actor,For SLTT governments the problem is lack of budget and knowledge especially for rural and low population areas. Again budgets for rural and low population SLTT governments make them big targets and without the resources to protect themselves.,Vulnerability,Higher,,
Sector,Commentary,From my time at CISA looking at critical infrastructure entities we often found that the sectors most vulnerable were vulnerable across the board when it came to anything cyber including things such as AI or more specific technologies (IoT automation generally etc.).,Commentary,,POTENTIAL PRIVACY CONCERN,
General,Commentary,At least moderate level of vulnerability that increases with the scale of the industry,Commentary,,"vague, not likely to be useful, exclude",
General,Commentary,responsibility aligns in this case with vulnerability given control ability,Commentary,,"vague, not likely to be useful, exclude",
Sector,"Arts, Entertainment and Recreation","Art Entertainment and Recreation is moderate as the products coming out from this sector do not have the likelihood of life threatening impacts. Health care and Social Assistance is extreme as the data processed by the AI models are potentially sensitive.

The impact and implication on model poisoning attack between art and entertainment domain and health care are very different.",Vulnerability,,,
Sector,Healthcare and Social Assistance,"Art Entertainment and Recreation is moderate as the products coming out from this sector do not have the likelihood of life threatening impacts. Health care and Social Assistance is extreme as the data processed by the AI models are potentially sensitive.

The impact and implication on model poisoning attack between art and entertainment domain and health care are very different.",Vulnerability,,,
Actor,AI Governance Actor,My responsibility assessments emphasize that accountability should rest with those who both control the infrastructure and set the standards.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,My responsibility assessments emphasize that accountability should rest with those who both control the infrastructure and set the standards.,Responsibility,Higher,,
General,Commentary,See my comments on privacy vulnerabilities. These operate substantially in tandem.,Commentary,,"vague & probably not likely to be useful, exclude",
General,Commentary,Again based on ability to control measures,Commentary,,"vague & probably not likely to be useful, exclude",
Actor ,AI Developer (General-purpose AI),I think companies should be responsible for the damage caused by their buggy software especially when they rush the software out without sufficient testing.,Responsibility,,,
General,Commentary,There is a high risk of data leakage of low severity. There is a low risk of unauthorized unmonitored powerful AI access of catastrophic severity.,Commentary,,,
Actor,AI Developer (General-Purpose AI),"Much of AI productization is being done without any guarantees or standard operating procedures w.r t. safety and security, but much of the risk is carried by: 1) improper harmful input detection (area of the AI developer), and 2) improper downstream reliance on AI output (area of AI deployer). Additionally, lack of standards allows self-regulation to dictate minimum requirements for security (area of AI governance actors).",Responsibility,Higher,,
Actor,AI Deployer,"Much of AI productization is being done without any guarantees or standard operating procedures w.r t. safety and security, but much of the risk is carried by: 1) improper harmful input detection (area of the AI developer), and 2) improper downstream reliance on AI output (area of AI deployer). Additionally, lack of standards allows self-regulation to dictate minimum requirements for security (area of AI governance actors).",Responsibility,Higher,,
Actor,AI Governance Actor,"Much of AI productization is being done without any guarantees or standard operating procedures w.r t. safety and security, but much of the risk is carried by: 1) improper harmful input detection (area of the AI developer), and 2) improper downstream reliance on AI output (area of AI deployer). Additionally, lack of standards allows self-regulation to dictate minimum requirements for security (area of AI governance actors).",Responsibility,Higher,,
Summary,AI Developer (General-purpose AI),"Comments overwhelmingly emphasized GPAI developers' primary responsibility for determining security architectures, implementing secure-by-design principles, and patching vulnerabilities where they originate. Multiple responses noted developers either produced products with vulnerabilities or chose specific infrastructure that could be entry points for attacks, with obligations to bake security into source code and develop security measures.",Responsibility,Higher,,
Summary,AI Developer (General-purpose AI),"Comments consistently rated GPAI developers as extremely vulnerable due to direct exposure to system architecture, development toolchains, and hardware vulnerabilities. Responses noted breaches at this foundational layer can lead to widespread consequences, with developers closest to operational layers of AI systems.",Vulnerability,Higher,,
Summary,AI Developer (Specialized AI),"Comments emphasized specialized developers' high to primary responsibility for operating systems in sensitive environments requiring robust safeguards. Multiple responses noted they have more responsibility than general-purpose developers due to smaller, more manageable vulnerability landscapes in domain-specific contexts like health and finance.",Responsibility,Higher,,
Summary,AI Developer (Specialized AI),"Comments characterized specialized developers as key targets and highly vulnerable due to proximity to model weights, deployment pathways, and sensitive technologies with potential for misuse.",Vulnerability,Higher,,
Summary,AI Deployer,"Comments consistently rated deployers as primarily to highly responsible for secure deployment practices, API management, and contextual safeguards in live environments. Multiple responses emphasized deployers surface edge cases others cannot anticipate and understand nuances of their own context, with one noting deployers bear responsibility for electing to use insecure toolkits without proper risk assessment. Comments noted responsibility includes conducting red-teaming and verifying vulnerabilities, with operational responsibility lying solely with the operating company.",Responsibility,Higher,,
Summary,AI Deployer,"Comments characterized deployers as prime targets extremely vulnerable to prompt-injection, data poisoning, model exfiltration, and supply-chain attacks, noting they are closest to operational and foundational layers where breaches have widespread consequences.",Vulnerability,Higher,,
Summary,AI Infrastructure Provider,"Comments unanimously emphasized infrastructure providers' primary to high responsibility for determining security architectures, maintaining secure computing and storage infrastructure, with breaches cascading across multiple actors. Responses noted they play a critical but often overlooked role in securing environments where AI is built and run, with data brokers specifically providing training data where poisoned datasets create systemic vulnerabilities.",Responsibility,Higher,,
Summary,AI Infrastructure Provider,"Comments consistently rated infrastructure providers as highly vulnerable key targets due to proximity to model weights and deployment pathways. Responses emphasized attacks on cloud platforms or toolchains can bypass multiple layers of security, making them highly exposed due to control over environments where AI systems run.",Vulnerability,Higher,,
Summary,AI Governance Actor,"Comments overwhelmingly emphasized governance actors' primary to high responsibility for determining security architectures, setting and enforcing standards, conducting audits, and mandating vulnerability reporting. Multiple responses noted they are responsible for delivering fit-for-purpose regulations aligned with technology evolution, though one comment noted uncertainty about U.S. governance improvements despite EU liability law progress.",Responsibility,Higher,,
Summary,AI Governance Actor,"Comments characterized governance actors as highly vulnerable due to institutional lag, infiltration risk, and misaligned oversight. Responses noted their influence over rules and standards makes them high-value targets for adversaries seeking systemic disruption, facing mainly reputational risk.",Vulnerability,Higher,,
Summary,AI User,"Comments varied on user responsibility, with most characterizing users as minimally responsible for basic security hygiene since they lack control over core architectures. However, some noted users can introduce risks through poor access control or unsafe prompts, with one perspective emphasizing users surface edge cases and understand their context nuances. Comments noted systemic responsibility lies elsewhere despite users' moderate influence on outcomes.",Responsibility,Lower,,
Summary,AI User,"Comments consistently rated users as highly vulnerable through exposure to compromised systems and unsafe AI behaviors resulting from security breaches, being harmed indirectly by vulnerabilities.",Vulnerability,Higher,,
Summary,Affected Stakeholder,"Most comments characterized affected stakeholders as bearing no responsibility as victims of security breaches with limited ability to prevent vulnerabilities. However, one comment noted stakeholders should speak up and address incorrect AI outputs, citing examples like Copilot creating nonexistent NIST categories.",Responsibility,Lower,,
Summary,Affected Stakeholder,"Comments unanimously rated affected stakeholders as highly vulnerable through exposure to compromised systems and unsafe AI behaviors, being harmed indirectly with mainly reputational risk.",Vulnerability,Higher,,
Summary,Finance and Insurance,"Comments consistently characterized finance as extremely vulnerable due to heavy reliance on AI for fraud detection and risk scoring making it a prime target. However, one perspective noted the sector has higher awareness of AI risks and more mature governance controls, lowering relative vulnerability despite remaining an attractive target.",Vulnerability,Higher,,
Summary,Health Care and Social Assistance,"Comments unanimously rated healthcare as extremely vulnerable due to electronic health records and medical imaging containing PHI that impacts patient safety. Responses noted it's a high-value target with essential infrastructure dependencies, though one comment suggested regulatory requirements may preclude early risks through slow technology adaptation.",Vulnerability,Higher,,
Summary,National Security,"Comments consistently emphasized national security as extremely vulnerable, with AI in surveillance and defense being prime targets for nation-state adversaries. However, some noted intelligence services are built with security in mind, potentially making them less vulnerable than other sectors. One comment highlighted that if securing AI model assets is important to national security, developers carry much larger burden.",Vulnerability,Higher,,
Summary,Information,"Comments unanimously characterized information sector as extremely vulnerable, facing high risks of adversarial attacks, data poisoning, and inversion. Multiple responses noted the sector is foundational to AI development and data infrastructure, with one comment contrasting it with national security's built-in security mindset that information sector may lack.",Vulnerability,Higher,,
Summary,"Trade, Transportation, and Utilities","Comments consistently rated transportation and utilities as highly vulnerable critical infrastructure where attacks could disrupt logistics or utilities at scale. Responses emphasized operational impact, wide attack surface, and role in critical infrastructure making them targets for malicious actors seeking high disruption.",Vulnerability,Higher,,
Summary,Public Administration excluding National Security,"Comments consistently characterized public administration as highly to extremely vulnerable due to benefits and citizen services making the sector sensitive to identity theft and disruption. One perspective noted U.S. government AI integration remains low, suggesting vulnerability will increase when cutting-edge models are deployed. Comments emphasized SLTT governments particularly lack budget and knowledge, especially in rural areas.",Vulnerability,Higher,,
Summary,Scientific Research and Development,Comments unanimously rated scientific research as highly vulnerable due to valuable biotech and R&D data where vulnerabilities could expose IP or alter critical research outcomes. Responses noted the sector is foundational to AI development with often weaker protection standards than other critical sectors.,Vulnerability,Higher,,
Summary,Educational Services,"Comments characterized education as highly to moderately vulnerable due to valuable data, weaker protection standards, and PII exposure, though impacts are generally less critical than other sectors.",Vulnerability,Higher,,
Summary,"Arts, Entertainment, and Recreation","Comments varied on arts vulnerability, with most characterizing it as minimally vulnerable collecting only preference data for personalization and gaming. However, one noted products from this sector don't have likelihood of life-threatening impacts, distinguishing it from healthcare's model poisoning risks.",Vulnerability,Lower,,
Summary,Real Estate and Rental and Leasing,"Comments varied on real estate vulnerability, with one noting it's a less critical target despite data theft risks, while another emphasized moderate vulnerability from AI in valuations and tenant screening creating financial/PII leak risks.",Vulnerability,Lower,,
Summary,"Agriculture, Mining, Construction and Manufacturing","Comments characterized these sectors as moderately vulnerable, with AI in robotics and predictive maintenance creating attack surfaces. One response noted agriculture includes critical infrastructure making it targetable by malicious actors for high disruption.",Vulnerability,Higher,,
Summary,Professional and Technical Services,"Comments rated professional services as highly vulnerable, with law, consulting, and engineering firms at risk of leaking IP or privileged information.",Vulnerability,Higher,,
Summary,"Management, Administrative, and Support Services","Comments characterized management services as moderately vulnerable, holding employee data through HR and workflow automation but with smaller-scale risks.",Vulnerability,Lower,,
Summary,"Accommodation, Food, and Other Services","Comments consistently rated accommodation and food services as moderately to less vulnerable, with booking and delivery systems holding PII/payment data. One comprehensive assessment noted these sectors have lower vulnerability based on software intensity, high-impact use cases, and potential multiplier effects.",Vulnerability,Lower,,