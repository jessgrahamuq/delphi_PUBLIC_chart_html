<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>1.2 Exposure to toxic content - Responsibility</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;        }

        h1 {
            text-align: center;
            margin-bottom: 30px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 30px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 4px 10px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 14px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #000000;
            color: white;
            border-color: #000000;
        }

        .actor-section {
            display: none;
        }

        .actor-section.active {
            display: block;
        }

        .content-grid {
            display: flex;
            width: 100%;
            gap: 10px;
        }

        .content-column {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;        }

        .criteria-header {
            font-size: 16px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid;
        }

        .criteria-header.higher {
            color: #FF0000;
            border-bottom-color: #FF0000;
        }

        .criteria-header.lower {
            color: #2E5C8A;
            border-bottom-color: #2E5C8A;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 14px;
            padding: 8px 0;
            border-bottom: 1px dotted #a32035;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 12px;
            line-height: 1.3;
            color: #000000;
        }

        @media (max-width: 768px) {
            .content-grid {
                gap: 10px;
            }

            .nav-pills {
                justify-content: flex-start;
            }

            .nav-pill {
                font-size: 10px;
                padding: 4px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>1.2 Exposure to toxic content - Responsibility</h1>

        <div class="nav-pills">
            
            <button class="nav-pill active" data-target="AIDeveloperGeneralpurposeAI">
                AI Developer (General-purpose AI)
            </button>
            <button class="nav-pill " data-target="AIDeployer">
                AI Deployer
            </button>
            <button class="nav-pill " data-target="AIGovernanceActor">
                AI Governance Actor
            </button>
            <button class="nav-pill " data-target="AIUser">
                AI User
            </button>
        </div>

        <div class="content-sections">
            
            <div class="actor-section active" id="AIDeveloperGeneralpurposeAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments consistently emphasized developers' primary responsibility as toxic generation begins at the foundation model level, choosing training data, architecture, and alignment techniques that directly determine toxic content emission.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"General-purpose developers are primarily responsible since toxic generation begins at the foundation model."</li><li>"AI developers/deployers/providers should be responsible to prevent accidental creation of this content, and generally to discourage creation of this content."</li><li>"1. AI Developer (General-purpose AI): primarily responsible - They choose the training data, model architecture, alignment techniques and post-training filters that most directly determine whether the model emits toxic content. They are also usually the only actors with full technical insight into model internals."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments unanimously emphasized deployers' primary to high responsibility for conducting due diligence, understanding risks, implementing moderation layers, and deciding what reaches end-users, with some noting deployers using wrappers are still considered developers.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (5)</summary>
                <ul class="quote-list">
                    <li>"Deployers and specialized developers are highly responsible for moderation and contextual safeguards."</li><li>"AI developers/deployers/providers should be responsible to prevent accidental creation of this content, and generally to discourage creation of this content."</li><li>"AI Deployer (Primarily Responsible) - initially set to Highly Responsible, the obligations for an AI Deployer is to conduct due diligence when building around AI Developer systems or procuring them"</li><li>"some AI Deployers are still considered AI Developers with wrappers around General-purpose AI designed by other AI Developers. The Terms and Conditions for AI Deployers still stand that they are primarily responsible for understanding and knowing the risks taken with using AI Developer systems."</li><li>"2. AI Deployer: highly responsible - Deployers decide the concrete use-case, fine-tune or prompt-engineer the system, set policy thresholds, integrate additional content-moderation layers and decide what is finally shown to end-users. Where they have the technical ability to add or improve safety layers, their responsibility is nearly as high as that of the model creators."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments consistently rated governance actors as highly responsible for setting enforceable protections and creating legal frameworks that ensure other actors implement effective toxicity safeguards.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"Governance actors hold high responsibility for setting enforceable protections."</li><li>"3. AI Governance Actor: highly responsible - They create and enforce the legal and normative framework that makes the other actors implement effective toxicity safeguards and provide redress mechanisms for affected users."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "Intentional creation of this content lands on the AI user."</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments varied widely, with most characterizing users as victims bearing harm without responsibility, though some noted intentional creation lands on users and they have moderate responsibility for requesting, amplifying, or reporting content.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"Users and affected stakeholders bear the harm but should not carry responsibility."</li><li>"Affected Stakeholder & AI User (Not responsible at all) - first point to make is that affected stakeholders and AI User are victims of exposure to toxic content"</li><li>"although AI User can still be leaned towards Minimally responsible. The reason behind this is while they don't have proactive obligation to prevent systemic toxic content exposure, AI User are still required to conduct due diligence when reading AI Developer/AI Deployer Terms and Conditions and/or company policies."</li><li>"4. AI User: moderately responsible - Users can decide whether to request, amplify or report toxic content, but they cannot change the model or deployment stack itself. Their responsibility is therefore real but secondary."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.actor-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    // Remove active class from all pills and sections
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    // Add active class to clicked pill
                    this.classList.add('active');

                    // Show corresponding section
                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>