Category,Type,Quote,Criteria ,Direction
Actor,AI Developer (General-purpose AI),"General-purpose AI developers and governance actors bear primary responsibility because they design, regulate, and oversee systems whose interactions may cause cascading failures.",Responsibility,Higher
Actor,AI Developer (General-purpose AI),"I rated AI Developers (General-purpose) and AI Governance Actors as highly to extremely vulnerable because they often operate without clear semantic alignment between intent, implementation, and deployment contexts-magnifying drift and the potential for cascading system failures.",Vulnerability,Higher
Actor,AI Developer (General-purpose AI),"AI Developer (General-Purpose AI): Extremely vulnerable - since their models are widely combined with others, and failures at this level scale across many domains.",Vulnerability,Higher
Actor,AI Developer (General-purpose AI),General-purpose AI developers - primarily responsible - as their systems underpin most multi-agent architectures.,Responsibility,Higher
Actor,AI Developer (General-purpose AI),"4. AI Developer (General-Purpose AI): Extremely Vulnerable - General models are widely embedded in downstream agent networks. Once strategies are exploited by other agents or weaknesses are exposed in a gaming environment, system-wide security incidents can rapidly occur, impacting a large number of users.",Vulnerability,Higher
Actor,AI Developer (General-purpose AI),"1. AI Developer (General-Purpose AI): Primarily Responsible - Determines agent architecture, communication protocols, and incentive mechanisms. Ability to incorporate negotiation algorithms, game safety testing, and adversarial training at the model level, enabling systematic mitigation of risks at the source.",Responsibility,Higher
Actor,AI Developer (General-purpose AI),"The developers of AI systems should be primarily responsible for failures of multi-agent risks but deployers, governance actors and users should also held accountable the same way managing other risks is ultimately a shared responsibility.",Commentary,
Actor,AI Developer (General-purpose AI),"Current and forseeable 'Agentic' AI is literally LLM completions with some tool-calling wrappers, so this issue boils down (from a technology perspective) into equivalent of LLM hallucinations and untrustworthy outputs. Based on this, responsibility lies with LLM vendors, and parties selling products / services based on LLM's.",Commentary,
Actor,AI Governance Actor,"General-purpose AI developers and governance actors bear primary responsibility because they design, regulate, and oversee systems whose interactions may cause cascading failures.",Responsibility,Higher
Actor,AI Governance Actor,"I rated AI Developers (General-purpose) and AI Governance Actors as highly to extremely vulnerable because they often operate without clear semantic alignment between intent, implementation, and deployment contexts-magnifying drift and the potential for cascading system failures.",Vulnerability,Higher
Actor,AI Governance Actor,AI Governance Actor - Highly vulnerable - as regulators face difficulty predicting and mitigating emergent behaviors when multiple AI systems interact.,Vulnerability,Higher
Actor,AI Governance Actor,Governance actors - highly responsible - for setting standards and monitoring systemic risks,Responsibility,Higher
Actor,AI Governance Actor,"2. AI Governance Actor: Moderately Vulnerable - Regulators need to integrate intelligence and monitoring agents across agencies and systems. Information asymmetry between agents can weaken monitoring effectiveness, but their organizational security and coercive power provide a degree of resilience.",Vulnerability,Higher
Actor,AI Governance Actor,3. AI Governance Actor: Highly Responsible - Has the authority to develop technical standards (such as interoperability protocols and simulation benchmarks) and enforce prior review and incident reporting. Cross-industry coordination is crucial for mitigating risks in multi-agent games.,Responsibility,higher
Actor,AI Deployer,"Deployers hold significant responsibility in operational contexts, where competitive or conflicting incentives may emerge.",Responsibility,Higher
Actor,AI Deployer,Here most of the responsibility lies around developers and deployers as they are the ones actively developing these systems.,Responsibility,Higher
Actor,AI Deployer,"AI Deployer - Highly vulnerable - because they integrate and operate systems in real-world settings, making them directly exposed to failures caused by agent interactions.",Vulnerability,Higher
Actor,AI Deployer,Specialized developers and deployers - primarily responsible - since they determine how agents are combined in sensitive use cases.,Responsibility,Higher
Actor,AI Deployer,"3. AI Deployer: Extremely Vulnerable - Responsible for assembling diverse models, plugins, and APIs into complete workflows, they serve as the 'command center' of multi-agent systems. Conflict, collusion, or cascading failures will primarily impact deployers, posing significant legal and reputational risks.",Vulnerability,Higher
Actor,AI Deployer,"2. AI Deployer: Highly Responsible - Assembles multiple agents, plugins, and external APIs into workflows, effectively setting resource permissions and objective functions. Implements real-time monitoring, conflict detection, and shutdown mechanisms, otherwise it bears the brunt of cascading failures.",Responsibility,Higher
Actor,AI Deployer,"There are several key problems to address in agentic security - agentic identity and authorization, activity guardrails and alignment evaluation... All of these are technical challenges for deployers of AI systems, in coordination with model creators.",Vulnerability,Higher
Actor,AI Developer (Specialized AI),"Specialized AI developers and infrastructure providers are also highly responsible, as they influence architectures and coordination frameworks across agents.",Responsibility,Higher
Actor,AI Developer (Specialized AI),"AI Developer (Specialized AI) - Highly vulnerable - since specialized systems in health, finance, or defense can interact in unpredictable ways with severe consequences.",Vulnerability,Higher
Actor,AI Developer (Specialized AI),"6. AI Developer (Specialized AI): Moderately Vulnerable - Vertical domain models operate within a closed environment but still require interaction with external agents. Improper protocol or incentive design can lead to collaborative failure or manipulation, resulting in moderate risk.",Vulnerability,Higher
Actor,AI Developer (Specialized AI),"7. AI Developer (Specialized AI): Highly Responsible - They directly design agent interaction rules in vertical scenarios such as autonomous driving platooning and algorithmic trading, ensuring conflict resolution, fault tolerance, and auditing capabilities.",Responsibility,Higher
Actor,AI Infrastructure Provider,"Specialized AI developers and infrastructure providers are also highly responsible, as they influence architectures and coordination frameworks across agents.",Responsibility,Higher
Actor,AI Infrastructure Provider,"AI Infrastructure Provider: Moderately vulnerable - as connectivity or compute issues can amplify risks, though they are not usually the root cause.",Vulnerability,Lower
Actor,AI Infrastructure Provider,infrastructure providers carry a moderate role by enforcing operational safeguards.,Responsibility,Lower
Actor,AI Infrastructure Provider,"5. AI Infrastructure Provider: Minimally Vulnerable - Primarily provides computing power and network resources, with limited exposure to internal incentive conflicts among multiple agents. Risks can be mitigated through resource isolation, quotas, and other measures.",Vulnerability,Lower
Actor,AI Infrastructure Provider,"5. AI Infrastructure Provider: Minimally Responsible - Their primary responsibility is to provide computing power and network isolation. They can mitigate amplification effects through rate limiting, quotas, and partitioning, but they do not directly determine agent strategies or incentives.",Responsibility,Lower
Actor,AI Infrastructure Provider,Infrastructure providers have a lower rating as they are tech enablers,Responsibility,Lower
Actor,AI User,"Users, while less central, still have a moderate responsibility to ensure appropriate use and monitoring of multi-agent interactions.",Responsibility,Lower
Actor,AI User,AI User - Moderately vulnerable - since users experience the consequences of multi-agent failures but have little awareness or control over how they arise.,Vulnerability,Lower
Actor,AI User,"AI Users: Marked as Moderately Responsible - although users don't design or deploy models, they interact with outputs and can intentionally misuse them. They must be held to a clear standard.",Responsibility,Lower
Actor,AI User,Users and affected stakeholders - not at all responsible - as they have little influence over technical design or integration.,Responsibility,Lower
Actor,AI User,"1. AI User: Highly Vulnerable - Simultaneously using or relying on multiple intelligent agents (for price comparison, financial management, chat assistants, etc.), users often struggle to identify conflicts or malicious manipulation between agents, potentially leading to financial, privacy, or decision-making losses.",Vulnerability,Higher
Actor,AI User,"4. AI User: Moderately Responsible - Selects which agents to collaborate with, allocates budgets and access permissions, and reports anomalous behavior. However, lacks underlying technical control, resulting in a moderate level of responsibility.",Responsibility,Lower
Actor,AI User,Users bare the brunt of most of the risk when models are not transparent unless their is a catastrophic failure of a system that brings down the company.,Vulnerability,Lower
Actor,Affected Stakeholder,Affected Stakeholder - Extremely vulnerable - because they ultimately bear the harms of failures without having the ability to prevent them.,Vulnerability,Lower
Actor,Affected Stakeholder,Users and affected stakeholders - not at all responsible - as they have little influence over technical design or integration.,Responsibility,Lower
Actor,Affected Stakeholder,"7. Affected Stakeholder: Highly Vulnerable - Public users, employees, or partners are vulnerable to the spillover effects of multi-agent chain failures (e.g., supply chain disruptions, algorithmic price manipulation). Lack of transparency and emergency response measures leads to significant losses and difficulty in self-protection.",Vulnerability,Higher
Actor,Affected Stakeholder,6. Affected Stakeholder: Not at All Responsible - They are passively affected and cannot participate in the agent design or deployment process. They should be protected by other entities.,Responsibility,Lower
Sector,"Finance, Information, and National Security","Finance, Information, and National Security sectors are considered extremely vulnerable because they rely heavily on interconnected multi-agent AI systems, where cascading failures or collusion can generate systemic risks.",Vulnerability,Higher
Sector,"Finance, Information, and National Security","Sectors such as Information, Finance, and National Security are rated extremely vulnerable due to their critical dependencies, adversarial threat surfaces, and the layered interactions between autonomous systems.",Vulnerability,Higher
Sector,"Transportation, Healthcare, and Public Administration","Transportation, healthcare, and public administration are highly vulnerable due to their dependence on distributed coordination across agents, with potential consequences for safety and service delivery.",Vulnerability,Higher
Sector,Real Estate and Accommodation,Real Estate and Accommodation are minimally vulnerable since their exposure to multi-agent architectures is relatively limited.,Vulnerability,Lower
Sector,"Education, Healthcare, and Scientific R&D","Education, Healthcare, and Scientific R&D are highly vulnerable due to their reliance on AI for decision support in human-critical domains, while lacking robust cross-agent calibration protocols.",Vulnerability,Higher
Sector,Arts and Entertainment and Accommodation/Food,"I marked Arts and Entertainment and Accommodation/Food as minimally vulnerable because their multi-agent interactions, while complex, are not structurally mission-critical in systemic stability terms.",Vulnerability,Lower
Sector,"Informational, Professional, Scientific, Educational","Informational, professional, scientific, educational are likely to be more affected in the medium term as capable AI agents begin proliferating and autonomously performing day-to-day or knowledge tasks on behalf of humans.",Vulnerability,Higher
Sector,"Infrastructure, Finance, Health and Military","Infrastructure, finance, health and military sectors are increasingly using multi-agent systems, and have the greatest exposure to vulnerabilities arising from interaction of many differently capable systems.",Vulnerability,Higher
Sector,Finance,"Risks like flash crashes and the emergence of illegal or detrimental collusive behaviour between agents that trade are very real with current AI technology, they are not theoretical.",Vulnerability,Higher
Sector,Finance,"Risks of collusion differ by area; automated interfaces governing industry outcomes, like those used in finance, are a particular risk.",Vulnerability,Higher
Sector,"Agriculture, Mining, Construction, and Manufacturing","Agriculture, Mining, Construction, and Manufacturing: Moderately vulnerable -failures in robotics or automation may disrupt production but are less systemic.",Vulnerability,Lower
Sector,"Trade, Transportation, and Utilities","Trade, Transportation, and Utilities: Highly vulnerable - failures in logistics, traffic systems, or smart grids can cascade across critical infrastructure.",Vulnerability,Higher
Sector,Information,Information: Extremely vulnerable - interacting recommender systems or bots can amplify misinformation and distort public discourse.,Vulnerability,Higher
Sector,Finance and Insurance,Finance and Insurance: Extremely vulnerable - trading algorithms or risk models interacting can create flash crashes or systemic instability.,Vulnerability,Higher
Sector,Real Estate and Rental and Leasing,Real Estate and Rental and Leasing - Minimally to moderately vulnerable - AI interactions here are limited and carry narrower consequences.,Vulnerability,Lower
Sector,Professional and Technical Services,"Professional and Technical Services - Highly vulnerable - interacting AI tools in legal, consulting, or engineering contexts can amplify flawed advice.",Vulnerability,Higher
Sector,Scientific Research and Development Services,Scientific Research and Development Services - Highly vulnerable - AI collaboration across domains can reinforce false assumptions or unsafe results.,Vulnerability,Higher
Sector,"Management, Administrative, and Support Services","Management, Administrative, and Support Services - Moderately vulnerable - multi-agent HR or admin systems may amplify bias or inefficiency.",Vulnerability,Lower
Sector,Educational Services,"Educational Services - Moderately vulnerable - AI tutoring and testing tools may conflict, but consequences are bounded.",Vulnerability,Lower
Sector,Health Care and Social Assistance,"Health Care and Social Assistance - Extremely vulnerable - diagnostic and treatment systems interacting can lead to severe, even life-threatening, errors.",Vulnerability,Higher
Sector,"Arts, Entertainment, and Recreation","Arts, Entertainment, and Recreation - Moderately vulnerable - generative models interacting can reinforce bias or distort content, though not safety-critical.",Vulnerability,Lower
Sector,"Accommodation, Food, and Other Services","Accommodation, Food, and Other Services: -Moderately vulnerable - failures in booking or recommendation systems may disrupt services but not cause systemic harm.",Vulnerability,Lower
Sector,Public Administration (excluding National Security),"Public Administration (excluding National Security): -Highly vulnerable - interacting AI in welfare, benefits, or policing can create systemic unfairness.",Vulnerability,Higher
Sector,National Security,National Security - Extremely vulnerable - interactions between autonomous defense or surveillance systems can escalate into catastrophic failures.,Vulnerability,Higher
General,Commentary,The main harm I see is indirect and routes through loss of control risk.,Commentary,
General,Commentary,"Focusing on the harm through loss of control risk, the primary interventions are limiting misalignment and reducing how easy covert collusion is in high-stakes applications.",Commentary,
General,Commentary,The Clarity Protocol I am developing aims to minimize these risks through multi-agent semantic alignment loops and drift detection methods.,Commentary,
General,Commentary,"I propose implementing mandatory user consent protocols (similar to cookie banners), where users check a box affirming: They understand usage rules, They acknowledge their accountability, Refusal = access denied.",Commentary,
General,Commentary,Another non-theoretical risk two or more AIs feeding on outputs from each other and totally losing touch with reality,Commentary,
General,Commentary,A survey of the interconnectedness of existing systems within each of these sectors would help ground the risk from multi-agent systems. My ratings are based on my current understanding of that connectedness.,Commentary,
General,Commentary,"With the rise of agentic software, if ill intentioned agents are created, the risks would propagate a lot more industries",Commentary,
General,Commentary,"In general I think multi-agent risks are severe but not >50% likely to occur by default, unlike loss of control and concentration of power risks.",Commentary,
General,Commentary,"The confused deputy problem is a classic in multi-agent systems, and capable AI systems may exploit this to use agents to accomplish actions outside of their allowed actions.",Commentary,
General,Commentary,"Identity should incorporate the BOM that comprises the agent, signed to assure its content and ownership, and part of a reputable ecosystem (never trust unknown software).",Commentary,
General,Commentary,"Authorization for tasks should be according to least privilege required, including least model capable of solving the task, and should be just-in-time and just-long-enough.",Commentary,
General,Commentary,multi agent set-up requires very specific knowledge that is rare.,Commentary,
Summary,AI Developer (General-purpose AI),"Comments unanimously emphasized GPAI developers' primary responsibility as they design systems whose interactions cause cascading failures, underpin most multi-agent architectures, and determine agent architecture, communication protocols, and incentive mechanisms. Multiple responses noted their ability to incorporate negotiation algorithms, game safety testing, and adversarial training at the model level enables systematic mitigation at the source.",Responsibility,Higher
Summary,AI Developer (General-purpose AI),"Comments consistently rated GPAI developers as extremely vulnerable, operating without clear semantic alignment between intent and deployment contexts, magnifying drift and cascading failures. Responses emphasized their models are widely combined with others causing failures that scale across domains, with system-wide security incidents rapidly occurring once strategies are exploited in gaming environments.",Vulnerability,Higher
Summary,AI Governance Actor,"Comments consistently emphasized governance actors' primary to high responsibility for regulating and overseeing systems, setting standards, monitoring systemic risks, and developing technical standards like interoperability protocols. Responses noted they have authority to enforce prior review, incident reporting, and cross-industry coordination crucial for mitigating multi-agent game risks.",Responsibility,Higher
Summary,AI Governance Actor,"Comments characterized governance actors as highly to moderately vulnerable, facing difficulty predicting and mitigating emergent behaviors when multiple AI systems interact. Responses noted they need to integrate intelligence and monitoring agents across agencies where information asymmetry between agents weakens monitoring effectiveness, though organizational security and coercive power provide some resilience.",Vulnerability,Higher
Summary,AI Deployer,"Comments unanimously rated deployers as primarily to highly responsible for integrating systems in operational contexts where competitive or conflicting incentives emerge. Multiple responses emphasized deployers assemble multiple agents, plugins, and APIs into workflows, setting resource permissions and objective functions while implementing real-time monitoring, conflict detection, and shutdown mechanisms, bearing the brunt of cascading failures.",Responsibility,Higher
Summary,AI Deployer,"Comments consistently characterized deployers as extremely to highly vulnerable, directly exposed to failures in real-world settings serving as the command center of multi-agent systems. Responses noted conflict, collusion, or cascading failures primarily impact deployers with significant legal and reputational risks, facing technical challenges in agentic security, identity, authorization, and alignment evaluation.",Vulnerability,Higher
Summary,AI Developer (Specialized AI),"Comments consistently rated specialized developers as highly responsible, influencing architectures and coordination frameworks across agents. Responses emphasized they directly design agent interaction rules in vertical scenarios like autonomous driving platooning and algorithmic trading, ensuring conflict resolution, fault tolerance, and auditing capabilities.",Responsibility,Higher
Summary,AI Developer (Specialized AI),"Comments characterized specialized developers as highly to moderately vulnerable, with specialized systems in health, finance, or defense interacting in unpredictable ways with severe consequences. Responses noted vertical domain models operate within closed environments but still require interaction with external agents where improper protocol or incentive design leads to collaborative failure or manipulation.",Vulnerability,Higher
Summary,AI Infrastructure Provider,"Comments varied on infrastructure providers' responsibility, with most rating them as moderately to minimally responsible, primarily providing computing power and network resources. Responses noted they can mitigate amplification effects through rate limiting, quotas, and partitioning but don't directly determine agent strategies or incentives, being tech enablers enforcing operational safeguards.",Responsibility,Lower
Summary,AI Infrastructure Provider,"Comments consistently characterized infrastructure providers as minimally to moderately vulnerable, primarily providing computing power with limited exposure to internal incentive conflicts among agents. Responses noted connectivity or compute issues can amplify risks though they're not usually the root cause, with risks mitigated through resource isolation, quotas, and other measures.",Vulnerability,Lower
Summary,AI User,"Comments varied on user responsibility, with most rating them as moderately to not at all responsible, having little influence over technical design or integration. Responses noted users interact with outputs and can intentionally misuse them requiring clear standards, selecting which agents to collaborate with and allocating permissions, but lacking underlying technical control.",Responsibility,Lower
Summary,AI User,"Comments varied on user vulnerability from highly to moderately vulnerable, experiencing consequences of multi-agent failures with little awareness or control. Responses noted users simultaneously rely on multiple agents struggling to identify conflicts or manipulation leading to financial, privacy, or decision-making losses, bearing the brunt of risk when models aren't transparent unless catastrophic system failure occurs.",Vulnerability,Higher
Summary,Affected Stakeholder,"Comments unanimously characterized affected stakeholders as not at all responsible, having little influence over technical design or integration, being passively affected without participating in agent design or deployment processes and requiring protection by other entities.",Responsibility,Lower
Summary,Affected Stakeholder,"Comments consistently rated affected stakeholders as extremely to highly vulnerable, ultimately bearing harms of failures without ability to prevent them. Responses noted public users, employees, or partners are vulnerable to spillover effects of multi-agent chain failures like supply chain disruptions and algorithmic price manipulation, with lack of transparency and emergency response measures leading to significant losses.",Vulnerability,Higher
Summary,Finance and Insurance,"Comments unanimously rated finance as extremely vulnerable, relying heavily on interconnected multi-agent AI systems where cascading failures or collusion generate systemic risks. Multiple responses emphasized trading algorithms or risk models interacting can create flash crashes or systemic instability, with risks of illegal or detrimental collusive behavior being very real with current technology, particularly in automated interfaces governing industry outcomes.",Vulnerability,Higher
Summary,Information,"Comments consistently characterized information sector as extremely vulnerable due to critical dependencies, adversarial threat surfaces, and layered interactions between autonomous systems. Responses noted interacting recommender systems or bots can amplify misinformation and distort public discourse, likely affected in medium term as capable AI agents proliferate autonomously performing knowledge tasks.",Vulnerability,Higher
Summary,National Security,"Comments unanimously rated national security as extremely vulnerable due to critical dependencies and adversarial threat surfaces. Responses emphasized interactions between autonomous defense or surveillance systems can escalate into catastrophic failures, with the sector increasingly using multi-agent systems having greatest exposure to vulnerabilities from interaction of differently capable systems.",Vulnerability,Higher
Summary,Health Care and Social Assistance,"Comments consistently characterized healthcare as extremely to highly vulnerable, depending on distributed coordination across agents with consequences for safety and service delivery. Responses noted diagnostic and treatment systems interacting can lead to severe, even life-threatening errors, with reliance on AI for decision support in human-critical domains lacking robust cross-agent calibration protocols.",Vulnerability,Higher
Summary,"Trade, Transportation, and Utilities","Comments consistently rated transportation and utilities as highly vulnerable, with failures in logistics, traffic systems, or smart grids cascading across critical infrastructure due to dependence on distributed coordination across agents.",Vulnerability,Higher
Summary,Public Administration excluding National Security,"Comments consistently characterized public administration as highly vulnerable, depending on distributed coordination across agents with potential consequences for service delivery. Responses noted interacting AI in welfare, benefits, or policing can create systemic unfairness.",Vulnerability,Higher
Summary,Professional and Technical Services,"Comments rated professional services as highly vulnerable, with interacting AI tools in legal, consulting, or engineering contexts amplifying flawed advice, likely affected as capable AI agents proliferate autonomously performing professional tasks.",Vulnerability,Higher
Summary,Scientific Research and Development,"Comments consistently characterized scientific research as highly vulnerable, with AI collaboration across domains reinforcing false assumptions or unsafe results. Responses noted reliance on AI for decision support lacking robust cross-agent calibration protocols, likely affected as agents proliferate performing scientific tasks.",Vulnerability,Higher
Summary,Educational Services,"Comments varied on education vulnerability, with some rating it highly vulnerable due to reliance on AI for decision support lacking robust cross-agent calibration, while others rated it moderately vulnerable noting AI tutoring and testing tools may conflict but consequences are bounded. The sector is likely affected as capable agents proliferate performing educational tasks.",Vulnerability,Lower
Summary,"Agriculture, Mining, Construction and Manufacturing","Comments characterized these sectors as moderately vulnerable, with failures in robotics or automation disrupting production but being less systemic than other sectors.",Vulnerability,Lower
Summary,Real Estate and Rental and Leasing,"Comments consistently rated real estate as minimally vulnerable, with exposure to multi-agent architectures being relatively limited and AI interactions carrying narrower consequences.",Vulnerability,Lower
Summary,"Management, Administrative, and Support Services","Comments characterized management services as moderately vulnerable, with multi-agent HR or admin systems potentially amplifying bias or inefficiency but not causing systemic harm.",Vulnerability,Lower
Summary,"Arts, Entertainment, and Recreation","Comments characterized arts and entertainment as minimally to moderately vulnerable, with multi-agent interactions being complex but not structurally mission-critical in systemic stability terms. Responses noted generative models interacting can reinforce bias or distort content, though not safety-critical.",Vulnerability,Lower
Summary,"Accommodation, Food, and Other Services","Comments consistently rated accommodation and food services as minimally to moderately vulnerable, with multi-agent interactions not being structurally mission-critical. Responses noted failures in booking or recommendation systems may disrupt services but not cause systemic harm.",Vulnerability,Lower