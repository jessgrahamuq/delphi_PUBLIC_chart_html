<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>7.4 Lack of transparency or interpretability - Vulnerability</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;        }

        h1 {
            text-align: center;
            margin-bottom: 8px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .selection-title {


            text-align: center;


            font-size: 14px;


            font-weight: 600;


            color: #666666;


            margin-bottom: 10px;


        }



        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 15px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 12px 20px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #000000;
            color: white;
            border-color: #000000;
        }

        .actor-section {
            display: none;
        }

        .actor-section.active {
            display: block;
        }

        .content-grid {
            display: flex;
            width: 100%;
            gap: 10px;
        }

        .content-column {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;        }

        .criteria-header {
            font-size: 15px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid;
        }

        .criteria-header.higher {
            color: #FF0000;
            border-bottom-color: #FF0000;
        }

        .criteria-header.lower {
            color: #2E5C8A;
            border-bottom-color: #2E5C8A;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 14px;
            padding: 8px 0;
            border-bottom: 1px dotted #a32035;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 12px;
            line-height: 1.3;
            color: #000000;
        }

        @media (max-width: 768px) {
            .content-grid {
                gap: 10px;
            }

            .selection-title {


                text-align: center;


                font-size: 14px;


                font-weight: 600;


                color: #666666;


                margin-bottom: 10px;


            }



            .nav-pills {
                justify-content: flex-start;
            }

            .nav-pill {
                font-size: 10px;
                padding: 4px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>7.4 Lack of transparency or interpretability - Vulnerability</h1>

        
        <div class="selection-title">Select a sector:</div>
        <div class="nav-pills">
            
            <button class="nav-pill active" data-target="AgricultureMiningConstructionandManufacturing">
                Agriculture, Mining, Construction and Manufacturing
            </button>
            <button class="nav-pill " data-target="TradeTransportationandUtilities">
                Trade, Transportation, and Utilities
            </button>
            <button class="nav-pill " data-target="Information">
                Information
            </button>
            <button class="nav-pill " data-target="FinanceandInsurance">
                Finance and Insurance
            </button>
            <button class="nav-pill " data-target="RealEstateandRentalandLeasing">
                Real Estate and Rental and Leasing
            </button>
            <button class="nav-pill " data-target="ProfessionalandTechnicalServices">
                Professional and Technical Services
            </button>
            <button class="nav-pill " data-target="ScientificServices">
                Scientific Services
            </button>
            <button class="nav-pill " data-target="ManagementAdministrativeandSupportServices">
                Management, Administrative, and Support Services
            </button>
            <button class="nav-pill " data-target="EducationalServices">
                Educational Services
            </button>
            <button class="nav-pill " data-target="HealthCareandSocialAssistance">
                Health Care and Social Assistance
            </button>
            <button class="nav-pill " data-target="ArtsEntertainmentandRecreation">
                Arts, Entertainment, and Recreation
            </button>
            <button class="nav-pill " data-target="AccommodationFoodandOtherServices">
                Accommodation, Food, and Other Services
            </button>
            <button class="nav-pill " data-target="PublicAdministrationexcludingNationalSecurity">
                Public Administration excluding National Security
            </button>
            <button class="nav-pill " data-target="NationalSecurity">
                National Security
            </button>
        </div>

        <div class="content-sections">
            
            <div class="actor-section active" id="AgricultureMiningConstructionandManufacturing">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="TradeTransportationandUtilities">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="Information">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments consistently rated information as highly to extremely vulnerable, where opaque AI decisions may erode democratic accountability, with biased responses difficult to identify and high-stakes decisions requiring provenance of ideas.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"Lack of transparency and interpretability is most critical in information, healthcare, and national security, where opaque AI decisions may endanger lives, undermine strategic stability, or erode democratic accountability."</li><li>"Public admin, Nat Sec, Information, Science, finance etc are highly vulnerable because they involve significant requirements or expectations to be able to show provenance of ideas and decision making processes in order to justify high-impact decisions. Areas like education are highly vulnerable partly due to a need to justify decisions and be transparent about AI use, but more so because lack of transparency might lead to harms that affect individuals' education and long term outcomes which are even more high risk and long-term than a mistake in another sector."</li><li>"Deep learning models are often biased because of the data they are trained on is also biased. The lack of interpretability makes it difficult to identify biased responses/decisions. This is especially risky for information, education, and culture (but also for scientific research). LLMs in particular tend to lie pretty consistently about their responses being biased and lack of interpretabilty jeopardizes trust. Imagine AI reading CVs, loan applications, and making biased decisions but lying about it when asked. via prompt. Arts is also vulnerable because without interpretability, it's difficult to perform 'data attribution', i.e., understanding what human art the model used to produce generated art and attributing the original authors."</li><li>"Generally, my ratings for interpretability are based off of level of complexity. For smaller less capable models doing less complex tasks, lack of interpretability is less dangerous. But for information, science and natsec decision can be very consequential, high-stakes, opaque and possibly integrate knowledge humans themselves do not/cannot easily verify."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="FinanceandInsurance">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "Public admin, Nat Sec, Information, Science, finance etc are highly vulnerable because they involve significant requirements or expectations to be able to show provenance of ideas and decision making processes in order to justify high-impact decisions. Areas like education are highly vulnerable partly due to a need to justify decisions and be transparent about AI use, but more so because lack of transparency might lead to harms that affect individuals' education and long term outcomes which are even more high risk and long-term than a mistake in another sector."</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="RealEstateandRentalandLeasing">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "Sectors like real estate or accommodation are less exposed, as decision-making impact is less systemic."</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="ProfessionalandTechnicalServices">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "Finance and professional services are also highly vulnerable due to the reliance on explainability for compliance, trust, and risk management."</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="ScientificServices">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "Deep learning models are often biased because of the data they are trained on is also biased. The lack of interpretability makes it difficult to identify biased responses/decisions. This is especially risky for information, education, and culture (but also for scientific research). LLMs in particular tend to lie pretty consistently about their responses being biased and lack of interpretabilty jeopardizes trust. Imagine AI reading CVs, loan applications, and making biased decisions but lying about it when asked. via prompt. Arts is also vulnerable because without interpretability, it's difficult to perform 'data attribution', i.e., understanding what human art the model used to produce generated art and attributing the original authors."</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="ManagementAdministrativeandSupportServices">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="EducationalServices">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments varied, with some rating education as moderately vulnerable due to low current AI adoption, while others emphasized extreme vulnerability due to impact on vulnerable populations' long-term outcomes and inability to responsibly deploy AI without understanding system prompts.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"Education and research sectors face significant challenges as reproducibility, trust in knowledge, and accountability for teaching and research outputs depend on interpretability."</li><li>"Industries such as healthcare, agriculture, national security, and education face extreme vulnerability because they cannot reliably use AI systems in high-stakes situations without understanding the underlying rules and system prompts governing model behavior. In healthcare, practitioners cannot safely use AI for prescribing or diagnosing patients without understanding how the model makes the diagnosis. Similarly, educational services cannot responsibly deploy AI with students and teenagers without understanding what system prompts govern the model's responses and limitations."</li><li>"Public admin, Nat Sec, Information, Science, finance etc are highly vulnerable because they involve significant requirements or expectations to be able to show provenance of ideas and decision making processes in order to justify high-impact decisions. Areas like education are highly vulnerable partly due to a need to justify decisions and be transparent about AI use, but more so because lack of transparency might lead to harms that affect individuals' education and long term outcomes which are even more high risk and long-term than a mistake in another sector."</li><li>"Deep learning models are often biased because of the data they are trained on is also biased. The lack of interpretability makes it difficult to identify biased responses/decisions. This is especially risky for information, education, and culture (but also for scientific research). LLMs in particular tend to lie pretty consistently about their responses being biased and lack of interpretabilty jeopardizes trust. Imagine AI reading CVs, loan applications, and making biased decisions but lying about it when asked. via prompt. Arts is also vulnerable because without interpretability, it's difficult to perform 'data attribution', i.e., understanding what human art the model used to produce generated art and attributing the original authors."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "For educational services I labeled the vulnerability as moderate. This is because while I believe the sensitivity would be high due to the potential impact on vulnerable people's education, the exposure currently is relatively low since few educational institutions are using AI in critical domains"</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="HealthCareandSocialAssistance">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments unanimously rated healthcare as extremely vulnerable, emphasizing practitioners cannot safely use AI for prescribing or diagnosing without understanding how models make decisions, with potential for severe harm in critical healthcare applications.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"Lack of transparency and interpretability is most critical in information, healthcare, and national security, where opaque AI decisions may endanger lives, undermine strategic stability, or erode democratic accountability."</li><li>"Industries such as healthcare, agriculture, national security, and education face extreme vulnerability because they cannot reliably use AI systems in high-stakes situations without understanding the underlying rules and system prompts governing model behavior. In healthcare, practitioners cannot safely use AI for prescribing or diagnosing patients without understanding how the model makes the diagnosis. Similarly, educational services cannot responsibly deploy AI with students and teenagers without understanding what system prompts govern the model's responses and limitations."</li><li>"Without transparency, organizations developing and deploying AI can not be held accountable by AI Governance organizations... They also may deploy systems that cause severe harm in critical industries, such as healthcare and critical infrastructure."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="ArtsEntertainmentandRecreation">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "Deep learning models are often biased because of the data they are trained on is also biased. The lack of interpretability makes it difficult to identify biased responses/decisions. This is especially risky for information, education, and culture (but also for scientific research). LLMs in particular tend to lie pretty consistently about their responses being biased and lack of interpretabilty jeopardizes trust. Imagine AI reading CVs, loan applications, and making biased decisions but lying about it when asked. via prompt. Arts is also vulnerable because without interpretability, it's difficult to perform 'data attribution', i.e., understanding what human art the model used to produce generated art and attributing the original authors."</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AccommodationFoodandOtherServices">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="PublicAdministrationexcludingNationalSecurity">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "Public admin, Nat Sec, Information, Science, finance etc are highly vulnerable because they involve significant requirements or expectations to be able to show provenance of ideas and decision making processes in order to justify high-impact decisions. Areas like education are highly vulnerable partly due to a need to justify decisions and be transparent about AI use, but more so because lack of transparency might lead to harms that affect individuals' education and long term outcomes which are even more high risk and long-term than a mistake in another sector."</p>
                            
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="NationalSecurity">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments consistently rated national security as extremely vulnerable where opaque AI decisions may endanger lives, undermine strategic stability, and involve consequential high-stakes decisions humans cannot easily verify.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"Lack of transparency and interpretability is most critical in information, healthcare, and national security, where opaque AI decisions may endanger lives, undermine strategic stability, or erode democratic accountability."</li><li>"Industries such as healthcare, agriculture, national security, and education face extreme vulnerability because they cannot reliably use AI systems in high-stakes situations without understanding the underlying rules and system prompts governing model behavior. In healthcare, practitioners cannot safely use AI for prescribing or diagnosing patients without understanding how the model makes the diagnosis. Similarly, educational services cannot responsibly deploy AI with students and teenagers without understanding what system prompts govern the model's responses and limitations."</li><li>"Generally, my ratings for interpretability are based off of level of complexity. For smaller less capable models doing less complex tasks, lack of interpretability is less dangerous. But for information, science and natsec decision can be very consequential, high-stakes, opaque and possibly integrate knowledge humans themselves do not/cannot easily verify."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided for this sector.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.actor-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    // Remove active class from all pills and sections
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    // Add active class to clicked pill
                    this.classList.add('active');

                    // Show corresponding section
                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>