Category,Type,Quote,Criteria,Direction,,
Actor,AI Developer (General-purpose AI),General-purpose AI developers hold primary responsibility due to their system-wide impact.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),AI Developer (General-purpose AI): These developers create foundational models that can be misused for fraud or manipulation. Hence they bear primary responsibility for implementing safeguards.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),General-purpose AI developers are rated as extremely vulnerable because their models can be repurposed for harmful uses beyond their control.,Vulnerability,Higher,,
Actor,AI Developer (General-purpose AI),It's not really clear what it means for an AI developer to be a target of this risk. Is it the staff or the model systems they're providing (e.g. a jailbreak)?,Commentary,,,"General comment/question, exclude"
Actor,AI Developer (Specialized AI),Domain-specific and specialized developers have direct control over fine-tuned use cases and should be held highly responsible.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),AI Developer (Specialized AI): These developers create domain-specific models and have moderate responsibility due to their influence over targeted applications.,Responsibility,Higher,,
Actor,AI Deployer,AI Deployer: Deployers decide how and where AI systems are used making them highly responsible for preventing misuse.,Responsibility,Higher,,
Actor,AI Deployer,AI deployers face high vulnerability due to the risk of integrating AI into sensitive environments without full safeguards.,Vulnerability,Higher,,
Actor,AI Governance Actor,The role of governance in addressing fraud is critical so I assigned them as primary responsible. Even if governance actors dont execute fraud prevention directly they set the rules that make fraud prevention possible.,Responsibility,Higher,,
Actor,AI Governance Actor,Governance actors play a key but supporting role â€” they often lack the agility to prevent misuse proactively.,Responsibility,"Higher, Lower",,
Actor,AI Governance Actor,AI Governance Actor: These actors set policies and regulations playing a critical role in ensuring ethical use of AI thus highly responsible.,Responsibility,Higher,,
Actor,AI Governance Actor,Governance actors are less vulnerable thanks to oversight mechanisms though indirect influence remains a concern.,Vulnerability,Lower,,
Actor,AI Governance Actor,I think there's a category error by including AI Governance Actors in this assessment. They're different in kind of users developers and deployers. They're more like a sector if anything.,Commentary,,,remove - method critique that won't be useful for experts to update their assessments
Actor,AI Governance Actor,Governance is required to clean this up. Simply identifying anything AI-generated (and how) would be a good first step. Establishing human identity and non-human identity is important in combatting fraud and targeted manipulations. Evil robots have red eyes!,Responsibility,Higher,,
Actor,AI User,Responsibility can be two-ways as Users may be primary fraud actors,Responsibility,Higher,,
Actor,AI User,Users must also carry high responsibility as intent determines outcome.,Responsibility,Higher,,
Actor,AI User,When using AI for fraud users' malicious actions and developers' inadequate security measures are both responsible.,Responsibility,Higher,,
Actor,AI User,AI User: Users interact with AI systems and can misuse them but their control is limited compared to developers and deployers making them moderately responsible.,Responsibility,"Higher, Lower",,
Actor,AI User,Hopefully the end AI user will have access to greater automated tools to reduce the risk of becoming victim to fraud scams and targeted manipulation.,Commentary,,,
Actor,AI Infrastructure Provider,Infrastructure providers should be included when hosting models or APIs that are known to cause harm.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,AI Infrastructure Provider: They provide the hardware and cloud services but have limited control over AI applications hence minimally responsible.,Responsibility,Lower,,
Actor,AI Deployers,Platforms and publishers that host the concerned content. They should be held responsible to act fast and mitigate harm if possible,Responsibility,Higher,,
Actor,Affected Stakeholder,Affected Stakeholder: While impacted by AI misuse they do not influence its development or deployment thus minimally responsible.,Responsibility,Lower,,
Sector,All Sectors,I don't see any difference across industries for vulnerability ratings. Malicious actors go for the lowest hanging fruit and will target any industry with lower defenses. Likewise as each industry begins to use AI they all have high vulnerabilities. I don't see much difference at this point,Vulnerability Commentary ,,,
Sector,All Sectors,Every sector of the economy was vulnerable to fraud scams and manipulation prior to the rising use of AI and every sector of the economy remains vulnerable to these malicious activities. The question really is one of scale and scope meaning as AI continues to develop and proliferate across economic sectors we will likely see greater use of these malicious activities and thus greater instances of fraud scams and targeted manipulation.,Vulnerability Commentary ,,,
Sector,All Sectors,There is no real difference between industry sectors re: how vulnerable they are to AI-backed fraud scenarios.,Vulnerability Commentary ,,,
Sector,Finance,Based on my exoerience in the financial sector I see fraud against financial institutions (synthetic identities deepfake CEO scams etc) as particularly dangerous because it can have systemic consequences (undermining trust in financial institutions consumer confidence...) and this makes finance and insurance extremely vulnerable to Ai enabled fraud and scams.,Vulnerability,Higher,,
Sector,Finance,In the economic sectors finance healthcare and information are rated extremely vulnerable due to their reliance on data integrity and decision-making processes that can be easily disrupted by AI-generated content or manipulation. These sectors face high stakes if AI is misused including financial loss reputational damage or harm to individuals.,Vulnerability,Higher,,
Sector,Finance,The reason for financial services being a little higher is because many money-motivated campaigns could disproportionately affect that service but I could imagine many attacks on specific corporate accounts in other domains (e.g. a mining company a recreation company etc.),Vulnerability,Higher,,
Sector,Healthcare,In the economic sectors finance healthcare and information are rated extremely vulnerable due to their reliance on data integrity and decision-making processes that can be easily disrupted by AI-generated content or manipulation.,Vulnerability,Higher,,
Sector,Information,In the economic sectors finance healthcare and information are rated extremely vulnerable due to their reliance on data integrity and decision-making processes that can be easily disrupted by AI-generated content or manipulation.,Vulnerability,Higher,,
Sector,Commentary ,Vulnerability decreases with size and sophistication of product (e.g. AI-driven Electricity bill fraud would necessitate a collective and expensive effort while loan fraud aggregates faster),Vulnerability,Higher,,
General,Commentary,Again ability to oontrol but who can control crime and bad acts? It's diffuse.,Commentary,,,
General,AI Governance Actor,The laws and courts are the primary drivers of setting the scope of responsibility for these activities.,Commentary,,,
General,Commentary,The ratings aim to highlight where proactive risk mitigation is most urgent.,Commentary,,,
Summary,AI Developer (General-purpose AI),"Comments consistently emphasized GPAI developers' primary responsibility due to system-wide impact, creating foundational models that can be misused for fraud or manipulation requiring implementation of safeguards.",Responsibility,Higher,,
Summary,AI Developer (General-purpose AI),Comments rated GPAI developers as extremely vulnerable because their models can be repurposed for harmful uses beyond their control.,Vulnerability,Higher,,
Summary,AI Developer (Specialized AI),"Comments emphasized specialized developers have direct control over fine-tuned use cases with high responsibility, creating domain-specific models with moderate to high responsibility due to influence over targeted applications.",Responsibility,Higher,,
Summary,AI Deployer,"Comments consistently rated deployers as highly responsible for deciding how and where AI systems are used, making them responsible for preventing misuse. Comments noted platforms and publishers hosting concerned content should act fast to mitigate harm.",Responsibility,Higher,,
Summary,AI Deployer,Comments noted deployers face high vulnerability due to risk of integrating AI into sensitive environments without full safeguards.,Vulnerability,Higher,,
Summary,AI Governance Actor,"Comments emphasized governance actors' critical role in addressing fraud by setting rules that make fraud prevention possible and ensuring ethical AI use through policies and regulations. Multiple responses noted governance is required for establishing human versus non-human identity to combat fraud, though some suggested they lack agility for proactive prevention.",Responsibility,Higher,,
Summary,AI Governance Actor,"Comments characterized governance actors as less vulnerable thanks to oversight mechanisms, though indirect influence remains a concern.",Vulnerability,Lower,,
Summary,AI User,"Comments varied on user responsibility, noting users may be primary fraud actors with malicious actions, bearing high responsibility as intent determines outcome. However, one comment noted their control is limited compared to developers and deployers, making them moderately responsible. Comments emphasized both users' malicious actions and developers' inadequate security measures are responsible when AI is used for fraud.",Responsibility,Higher,,
Summary,AI Infrastructure Provider,"Comments varied on infrastructure providers' responsibility, with some noting they should be included when hosting models or APIs known to cause harm, while others characterized them as minimally responsible due to limited control over AI applications despite providing hardware and cloud services.",Responsibility,Lower,,
Summary,Affected Stakeholder,"Comments characterized affected stakeholders as minimally responsible, being impacted by AI misuse but not influencing its development or deployment.",Responsibility,Lower,,
Summary,Finance and Insurance,"Comments unanimously rated finance as extremely vulnerable due to reliance on data integrity and decision-making processes easily disrupted by AI-generated content. Multiple responses emphasized fraud against financial institutions through synthetic identities and deepfake CEO scams has systemic consequences undermining trust and consumer confidence, with money-motivated campaigns disproportionately affecting this sector.",Vulnerability,Higher,,
Summary,Health Care and Social Assistance,"Comments rated healthcare as extremely vulnerable due to reliance on data integrity and decision-making processes that can be easily disrupted by AI-generated content or manipulation, facing high stakes including harm to individuals.",Vulnerability,Higher,,
Summary,Information,"Comments characterized information sector as extremely vulnerable due to reliance on data integrity and decision-making processes easily disrupted by AI-generated content, facing high stakes including reputational damage.",Vulnerability,Higher,,