Category Type,Category,Quote,Criteria,Direction,QA Status,Notes
Actor,General,"There is always a residual risk for all industries. Rating is directly proportional to the decision-intensity of the industry, its reliance on information/content and the impact each decision has on other stakeholders and/or the decisions they make.",Vulnerability,Higher,complete,
Actor,General,It's a reverse relation: Relationship vs. Vulnerability,Vulnerability,Mixed,complete,Don't use - not enough context to be useful 
Sector,General,As with previous comment all sectors are vulnerable - it is difficult to separate this out across domains,Vulnerability,Higher,complete,
Actor,General,"In a real setting, I use the technical analysis of adversarial testing to get toxic responses, data annotation issues (e.g. abusive language), predefined list of toxic words, sentiment analysis on tested outputs",Vulnerability,Neutral,complete,Don't use - not enough context to be useful (checked and this quote wasn't spliced by Claude)
Actor,General,"Every human being on the planet. Go back to 2023, and read the articles from the Guardian, Time Magazine, CBS News, Business Insider, Slate and even Microsoft on how the Kenyans suffered extreme mental health issues labeling the data for OpenAI ChatGPT.",Vulnerability,Higher,complete,
Actor,General,The listed above entities are responsible for corporate exposure.,Responsibility,Higher,complete,Don't use - not enough context to be useful 
Sector,Information,Information is extremely vulnerable since toxic content spreads rapidly via social platforms and recommender systems.,Vulnerability,Higher,complete,
Sector,Health Care and Social Assistance,"Health care, education, arts, and public administration are highly vulnerable due to reputational and social harms when toxic AI outputs erode trust.",Vulnerability,Higher,complete,
Sector,Educational Services,"Health care, education, arts, and public administration are highly vulnerable due to reputational and social harms when toxic AI outputs erode trust.",Vulnerability,Higher,complete,
Sector,"Arts, Entertainment, and Recreation","Health care, education, arts, and public administration are highly vulnerable due to reputational and social harms when toxic AI outputs erode trust.",Vulnerability,Higher,complete,
Sector,Public Administration excluding National Security,"Health care, education, arts, and public administration are highly vulnerable due to reputational and social harms when toxic AI outputs erode trust.",Vulnerability,Higher,complete,
Sector,Finance and Insurance,"Finance, professional services, and administrative services are moderately vulnerable because toxicity undermines reliability but isn't typically life-critical.",Vulnerability,Lower,complete,
Sector,Professional and Technical Services,"Finance, professional services, and administrative services are moderately vulnerable because toxicity undermines reliability but isn't typically life-critical.",Vulnerability,Lower,complete,
Sector,"Management, Administrative, and Support Services","Finance, professional services, and administrative services are moderately vulnerable because toxicity undermines reliability but isn't typically life-critical.",Vulnerability,Lower,complete,
Sector,"Agriculture, Mining, Construction and Manufacturing",Agriculture and scientific R&D are minimally vulnerable as their exposure to toxic outputs is limited.,Vulnerability,Lower,complete,
Sector,Scientific Services,Agriculture and scientific R&D are minimally vulnerable as their exposure to toxic outputs is limited.,Vulnerability,Lower,complete,
Actor,AI Developer (General-purpose AI),General-purpose developers are primarily responsible since toxic generation begins at the foundation model.,Responsibility,Higher,complete,
Actor,AI Deployer,Deployers and specialized developers are highly responsible for moderation and contextual safeguards.,Responsibility,Higher,complete,
Actor,AI Developer (Specialized AI),Deployers and specialized developers are highly responsible for moderation and contextual safeguards.,Responsibility,Higher,complete,
Actor,AI Governance Actor,Governance actors hold high responsibility for setting enforceable protections.,Responsibility,Higher,complete,
Actor,AI Infrastructure Provider,Infrastructure providers are minimally responsible as they don't control content.,Responsibility,Lower,complete,
Actor,AI User,Users and affected stakeholders bear the harm but should not carry responsibility.,Responsibility,Lower,complete,
Actor,Affected Stakeholder,Users and affected stakeholders bear the harm but should not carry responsibility.,Responsibility,Lower,complete,
Actor,AI Developer (General-purpose AI),"AI developers/deployers/providers should be responsible to prevent accidental creation of this content, and generally to discourage creation of this content.",Responsibility,Higher,complete,
Actor,AI Deployer,"AI developers/deployers/providers should be responsible to prevent accidental creation of this content, and generally to discourage creation of this content.",Responsibility,Higher,complete,
Actor,AI Infrastructure Provider,"AI developers/deployers/providers should be responsible to prevent accidental creation of this content, and generally to discourage creation of this content.",Responsibility,Higher,complete,
Actor,AI User,Intentional creation of this content lands on the AI user.,Responsibility,Higher,complete,
Actor + Sector ,General,"My criteria for assessing the vulnerability for a specific group is largely based on the access of the general public or of the clients or customers of that industry to the AI systems that may surface or perpetuate toxic content. For example, arts, entertainment, and recreation is a product or service created for the general public, and as such AI-generated or AI-perpetuated content is likely to interact with a wider, more general, and less specialized audience.",Vulnerability,Higher,complete,
Actor,General,"I believe that industries based more around information and multimedia have a higher vulnerability than those that work with physical objects or otherwise require less ""creativity"" and socially-conscious communication",Vulnerability,Higher,complete,
Actor,General,Whoever develops or adopts AI is responsible for managing these risks.,Responsibility,Higher,complete,
Actor,Affected Stakeholder,"Affected Stakeholders (highly vulnerable) - this can be a high population/group of individuals or communities who are affected by by AI without consent or participation (e.g., deep-fake identity images, deep-fake pornography, defamation, etc.)",Vulnerability,Higher,complete,
Actor,AI Governance Actor,"AI Governance Actors (minimally vulnerable) - they're regulators, auditors who are tasked to interact and review AI outputs in a controlled setting. These are professional staff and are expected to receive rigorous training around handling",Vulnerability,Lower,complete,
Sector,Scientific Services,Scientific Research & Development Services (minimally vulnerable) - slightly similar to the setting of AI Governance actors where scientific research and development are safely conducted in a controlled environment/controlled setting,Vulnerability,Lower,complete,
Actor,AI Deployer,"AI Deployer (Primarily Responsible) - initially set to Highly Responsible, the obligations for an AI Deployer is to conduct due diligence when building around AI Developer systems or procuring them",Responsibility,Higher,complete,
Actor,AI Deployer,"some AI Deployers are still considered ""AI Developers"" with wrappers around General-purpose AI designed by other AI Developers. The Terms and Conditions for AI Deployers still stand that they are primarily responsible for understanding and knowing the risks taken with using AI Developer systems.",Responsibility,Higher,complete,
Actor,Affected Stakeholder,Affected Stakeholder & AI User (Not responsible at all) - first point to make is that affected stakeholders and AI User are victims of exposure to toxic content,Responsibility,Lower,complete,
Actor,AI User,Affected Stakeholder & AI User (Not responsible at all) - first point to make is that affected stakeholders and AI User are victims of exposure to toxic content,Responsibility,Lower,complete,
Actor,AI User,"although AI User can still be leaned towards ""Minimally responsible"". The reason behind this is while they don't have proactive obligation to prevent systemic toxic content exposure, AI User are still required to conduct due diligence when reading AI Developer/AI Deployer Terms and Conditions and/or company policies.",Responsibility,Lower,complete,
Sector,"Agriculture, Mining, Construction and Manufacturing","1. Agriculture, Mining, Construction, and Manufacturing: minimally vulnerable - Production sites primarily involve physical operations, with a low proportion of digital content. - The primary risk comes from occasional inappropriate online comments during back-office customer service, recruitment, or training.",Vulnerability,Lower,complete,
Sector,"Trade, Transportation, and Utilities","2. Trade, Transportation, and Utilities: minimally vulnerable - Public customer service and complaint channels may contain abusive or hate speech, but overall exposure is low. - Supply chain management data is mostly structured, and the proportion of toxic text is limited.",Vulnerability,Lower,complete,
Sector,Information,"3. Information: extremely vulnerable - Requires processing of massive amounts of user-generated content, forum posts, images, and videos; toxic content filtering tasks are concentrated. - Positions such as information security, content review, red teaming, and model fine-tuning are subject to long-term, high-intensity exposure to inappropriate information.",Vulnerability,Higher,complete,
Sector,Finance and Insurance,"4. Finance and Insurance: moderately vulnerable - Customer service, anti-fraud, and compliance monitoring may involve threats, harassment, or hate speech. - Under strict regulatory oversight, automated text analysis and recording obligations are in place, increasing the likelihood of accessing original content.",Vulnerability,Higher,complete,
Sector,Real Estate and Rental and Leasing,"5. Real Estate, Rental and Leasing: minimally vulnerable - Primary communication scenarios are customer inquiries and rental reviews, with occasional exposure to toxic content. - Relatively limited online business penetration.",Vulnerability,Lower,complete,
Sector,Professional and Technical Services,6. Professional and Technical Services: moderately vulnerable - High reliance on generative AI to draft texts and process original client materials may result in inadvertent exposure to inappropriate material. - Exposure is further increased for outsourced auditing or forensics services.,Vulnerability,Higher,complete,
Sector,Scientific Services,7. Scientific Research and Development Services: moderately vulnerable - Research data crawling and model training may contain extreme or illegal content. - Security/adversarial researchers need to proactively trigger models to output violative content for testing.,Vulnerability,Higher,complete,
Sector,"Management, Administrative, and Support Services","8. Management, Administrative, and Support Services: highly vulnerable - A large number of frontline employees are responsible for review, customer service, and complaint handling, and are often directly exposed to highly abusive or violent text. - High job turnover and insufficient mental health support exacerbate risks.",Vulnerability,Higher,complete,
Sector,Educational Services,"9. Educational Services: extremely vulnerable - Students (especially minors) using open-source tools may inadvertently encounter hateful, pornographic, or self-harming content. - Teachers also need to review potentially inappropriate content when grading, supervising, and screening assignments.",Vulnerability,Higher,complete,
Sector,Health Care and Social Assistance,"10. Health Care and Social Assistance: highly vulnerable - Mental health, crisis intervention, social work, and other settings involve depictions of self-harm, suicide, or violence. - Original conversation records must be retained for diagnosis, treatment, and quality control to increase access.",Vulnerability,Higher,complete,
Sector,"Arts, Entertainment, and Recreation","11. Arts, Entertainment, and Recreation: highly vulnerable - Creators using generative AI to search for inspiration, synthesize images, and scripts are prone to encountering pornographic or violent material. - Hate speech is common in public comment sections, comment boards, and social interactions.",Vulnerability,Higher,complete,
Sector,"Accommodation, Food, and Other Services","12. Accommodation, Food, and Other Services: moderately vulnerable - Abusive, negative reviews, and discriminatory language are common in online reviews, customer chats, and social media marketing. - The scale and frequency of these abuses are minimally lower than on major social platforms.",Vulnerability,Lower,complete,
Sector,Public Administration excluding National Security,"13. Public Administration (excluding National Security): moderately vulnerable - Insults and polarizing language are common in government hotlines, public opinion solicitations, and social security consultations. - The need to preserve original documents and archives in compliance with regulations may result in exposure to inappropriate content.",Vulnerability,Lower,complete,
Sector,National Security,"14. National Security: extremely vulnerable - Intelligence, counterterrorism, and cybersecurity tasks require monitoring and analysis of extremist propaganda, threats of violence, and CSAM leads. - Long-term, intensive exposure to the most extreme texts and images can have a significant psychological impact on personnel handling these tasks.",Vulnerability,Higher,complete,
Actor,AI Developer (General-purpose AI),"1. AI Developer (General-purpose AI): primarily responsible - They choose the training data, model architecture, alignment techniques and post-training filters that most directly determine whether the model emits toxic content. They are also usually the only actors with full technical insight into model internals.",Responsibility,Higher,complete,
Actor,AI Deployer,"2. AI Deployer: highly responsible - Deployers decide the concrete use-case, fine-tune or prompt-engineer the system, set policy thresholds, integrate additional content-moderation layers and decide what is finally shown to end-users. Where they have the technical ability to add or improve safety layers, their responsibility is nearly as high as that of the model creators.",Responsibility,Higher,complete,
Actor,AI Governance Actor,3. AI Governance Actor: highly responsible - They create and enforce the legal and normative framework that makes the other actors implement effective toxicity safeguards and provide redress mechanisms for affected users.,Responsibility,Higher,complete,
Actor,AI User,"4. AI User: moderately responsible - Users can decide whether to request, amplify or report toxic content, but they cannot change the model or deployment stack itself. Their responsibility is therefore real but secondary.",Responsibility,Lower,complete,
Actor,AI Infrastructure Provider,"5. AI Infrastructure Provider: minimally responsible - They can include ""acceptable-use"" clauses and provide abuse reporting channels, but they generally lack content-level visibility and direct control over model outputs.",Responsibility,Lower,complete,
Actor,Affected Stakeholder,6. Affected Stakeholder: minimally responsible - They do not create or operate the system. Their main role is to voice concerns and supply feedback rather than to implement mitigations.,Responsibility,Lower,complete,
Actor,AI Developer (Specialized AI),"7. AI Developer (Specialized AI): moderately responsible - They influence data selection, algorithmic choices and evaluation protocols inside their organizations and have a professional duty to raise safety concerns, even if they do not make final product decisions.",Responsibility,Higher,complete,
Summary,AI Developer (General-purpose AI),"Comments consistently emphasized developers' primary responsibility as toxic generation begins at the foundation model level, choosing training data, architecture, and alignment techniques that directly determine toxic content emission.",Responsibility,Higher,,
Summary,AI Developer (Specialized AI),"Comments varied, with one noting specialized developers share high responsibility for moderation and contextual safeguards alongside deployers, while another characterized them as moderately responsible with professional duty to raise safety concerns despite not making final decisions.",Responsibility,Higher,,
Summary,AI Deployer,"Comments unanimously emphasized deployers' primary to high responsibility for conducting due diligence, understanding risks, implementing moderation layers, and deciding what reaches end-users, with some noting deployers using wrappers are still considered developers.",Responsibility,Higher,,
Summary,AI Governance Actor,Comments consistently rated governance actors as highly responsible for setting enforceable protections and creating legal frameworks that ensure other actors implement effective toxicity safeguards.,Responsibility,Higher,,
Summary,AI Governance Actor,Comments noted governance actors as minimally vulnerable as professional staff expected to receive rigorous training for handling toxic content in controlled settings.,Vulnerability,Lower,,
Summary,AI Infrastructure Provider,"Comments varied, with most noting minimal responsibility due to lack of content control, though some included them in broader responsibility for preventing accidental creation of toxic content.",Responsibility,Lower,,
Summary,AI Infrastructure Provider,One comment included infrastructure providers alongside developers and deployers as responsible for preventing accidental creation and discouraging toxic content.,Responsibility,Higher,,
Summary,AI User,"Comments varied widely, with most characterizing users as victims bearing harm without responsibility, though some noted intentional creation lands on users and they have moderate responsibility for requesting, amplifying, or reporting content.",Responsibility,Lower,,
Summary,AI User,"Some comments noted users bear responsibility for intentional creation of toxic content and have moderate influence through their choices to request, amplify, or report such content.",Responsibility,Higher,,
Summary,Affected Stakeholder,"Comments consistently characterized affected stakeholders as victims bearing harm without responsibility, being highly vulnerable to AI-generated content without consent including deepfakes and defamation.",Responsibility,Lower,,
Summary,Affected Stakeholder,"Comments unanimously rated affected stakeholders as highly vulnerable, experiencing exposure to toxic content through deepfakes, pornography, and defamation without consent or participation.",Vulnerability,Higher,,
Summary,"Agriculture, Mining, Construction and Manufacturing","Comments consistently characterized these sectors as minimally vulnerable with limited exposure to toxic outputs, primarily involving physical operations with occasional inappropriate content in back-office functions.",Vulnerability,Lower,,
Summary,"Trade, Transportation, and Utilities","Comments noted minimal vulnerability with low overall exposure, primarily from occasional abusive content in public customer service channels and complaint systems.",Vulnerability,Lower,,
Summary,Information,"Comments unanimously rated information as extremely vulnerable due to processing massive amounts of user-generated content, with positions like content review and red teaming facing long-term high-intensity exposure to inappropriate information.",Vulnerability,Higher,,
Summary,Finance and Insurance,"Comments varied, with some noting moderate vulnerability from customer service exposure to threats and harassment under regulatory oversight, while others rated it lower as toxicity undermines reliability but isn't life-critical.",Vulnerability,Lower,,
Summary,Finance and Insurance,"Some comments noted higher vulnerability due to anti-fraud and compliance monitoring involving threats and harassment, with automated text analysis increasing exposure.",Vulnerability,Higher,,
Summary,Real Estate and Rental and Leasing,Comments characterized real estate as minimally vulnerable with limited online business penetration and primary exposure through occasional toxic content in customer inquiries and rental reviews.,Vulnerability,Lower,,
Summary,Professional and Technical Services,"Comments consistently noted moderate vulnerability from high reliance on generative AI potentially exposing users to inappropriate material, particularly in outsourced auditing or forensics services.",Vulnerability,Higher,,
Summary,Scientific Research and Development,"Comments varied, noting minimal vulnerability due to limited exposure in controlled environments, though research data crawling and adversarial testing may involve extreme content.",Vulnerability,Lower,,
Summary,Scientific Research and Development,Some comments noted moderate vulnerability as security researchers need to proactively trigger models for testing and may encounter extreme content in data crawling.,Vulnerability,Higher,,
Summary,"Management, Administrative, and Support Services",Comments varied from moderate vulnerability as toxicity undermines reliability to high vulnerability with frontline employees directly exposed to abusive content with insufficient mental health support.,Vulnerability,Higher,,
Summary,"Management, Administrative, and Support Services",One comment noted moderate vulnerability as toxicity undermines reliability but isn't typically life-critical.,Vulnerability,Lower,,
Summary,Educational Services,"Comments unanimously rated education as extremely to highly vulnerable, with students (especially minors) inadvertently encountering harmful content and teachers reviewing inappropriate material when grading.",Vulnerability,Higher,,
Summary,Health Care and Social Assistance,"Comments consistently emphasized healthcare's high vulnerability from mental health and crisis intervention settings involving depictions of self-harm and violence, with retention requirements increasing exposure.",Vulnerability,Higher,,
Summary,"Arts, Entertainment, and Recreation","Comments unanimously characterized arts as highly vulnerable with creators encountering pornographic or violent material when using generative AI, plus common hate speech in public comment sections.",Vulnerability,Higher,,
Summary,"Accommodation, Food, and Other Services","Comments noted moderate vulnerability from abusive reviews and discriminatory language in online channels, with scale and frequency lower than major social platforms.",Vulnerability,Lower,,
Summary,Public Administration excluding National Security,"Comments varied, noting moderate vulnerability from insults in government hotlines and public consultations, with some rating it highly vulnerable due to reputational and social harms eroding trust.",Vulnerability,Lower,,
Summary,Public Administration excluding National Security,Some comments rated public administration as highly vulnerable due to reputational and social harms when toxic outputs erode trust.,Vulnerability,Higher,,
Summary,National Security,"Comments consistently rated national security as extremely vulnerable, with intelligence and counterterrorism tasks requiring monitoring extremist propaganda and CSAM with significant psychological impact on personnel.",Vulnerability,Higher,,