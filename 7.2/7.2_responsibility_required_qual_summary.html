<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>7.2 AI possessing dangerous capabilities - Responsibility</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;        }

        h1 {
            text-align: center;
            margin-bottom: 8px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .selection-title {


            text-align: center;


            font-size: 14px;


            font-weight: 600;


            color: #666666;


            margin-bottom: 10px;


        }



        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 15px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 12px 20px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #000000;
            color: white;
            border-color: #000000;
        }

        .actor-section {
            display: none;
        }

        .actor-section.active {
            display: block;
        }

        .content-grid {
            display: flex;
            width: 100%;
            gap: 10px;
        }

        .content-column {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;        }

        .criteria-header {
            font-size: 15px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid;
        }

        .criteria-header.higher {
            color: #FF0000;
            border-bottom-color: #FF0000;
        }

        .criteria-header.lower {
            color: #2E5C8A;
            border-bottom-color: #2E5C8A;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 14px;
            padding: 8px 0;
            border-bottom: 1px dotted #a32035;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 12px;
            line-height: 1.3;
            color: #000000;
        }

        @media (max-width: 768px) {
            .content-grid {
                gap: 10px;
            }

            .selection-title {


                text-align: center;


                font-size: 14px;


                font-weight: 600;


                color: #666666;


                margin-bottom: 10px;


            }



            .nav-pills {
                justify-content: flex-start;
            }

            .nav-pill {
                font-size: 10px;
                padding: 4px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>7.2 AI possessing dangerous capabilities - Responsibility</h1>

        
        <div class="selection-title">Select an actor:</div>
        <div class="nav-pills">
            
            <button class="nav-pill active" data-target="AIDeveloperGeneralpurposeAI">
                AI Developer (General-purpose AI)
            </button>
            <button class="nav-pill " data-target="AIDeployer">
                AI Deployer
            </button>
            <button class="nav-pill " data-target="AIGovernanceActor">
                AI Governance Actor
            </button>
            <button class="nav-pill " data-target="AIUser">
                AI User
            </button>
        </div>

        <div class="content-sections">
            
            <div class="actor-section active" id="AIDeveloperGeneralpurposeAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments consistently emphasized GPAI developers' primary responsibility as dangerous capabilities stem from how models are trained, requiring extensive investment, with developers having technical control to prevent development while governments have obligations to citizens.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (8)</summary>
                <ul class="quote-list">
                    <li>"Responsibility for addressing dangerous AI capabilities sits primarily with AI developers (both general and specialized) and AI governance actors, as they design, release, and regulate models that could be exploited for large-scale harm."</li><li>"I rated model makers primarily responsible because dangerous capabilities first and foremost occur when models are trained a certain way. Such capabilities are only present after extensive investment into training and often done without supervision, hence it falls first on model developers."</li><li>"General-purpose developers and deployers must shoulder primary responsibility due to their proximity to core capabilities and deployment vectors."</li><li>"Responsibility rests with the developers and the governance organizations responsible for compelling them to develop safe tools."</li><li>"Once dangerous capabilities exist, containing them becomes exponentially harder. Primary responsibility lies with those who can prevent development or deployment. Both technical control (developers) and regulatory oversight (governance) are essential."</li><li>"Only developers have reasonable capability to intervene on this, while only governments have a strong obligation to do so on the behalf of their citizens."</li><li>"Of course malicious users or jailbreakers of models are responsible for their actions (which is why they are listed as moderately responsible) but the main responsibility to mitigate the harm is to prevent it from existing which is on the developers and on governments and other governance professionals to ensure these capabilities are not in the models."</li><li>"Agentic systems pursuing their own goals must be designed to account for potentially dangerous behavior; assume breach by default (is the zero trust mantra)."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments emphasized deployers' high responsibility for securing AI systems, controlling access, monitoring misuse, and enforcing policies, though noting they face strong pressures to maximize capabilities with limited obligations not to.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"General-purpose developers and deployers must shoulder primary responsibility due to their proximity to core capabilities and deployment vectors."</li><li>"Deployers are responsible for securing AI systems."</li><li>"Deployers and infrastructure providers share high responsibility by controlling access, monitoring misuse, and enforcing policies."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments overwhelmingly emphasized governance actors' responsibility for crafting policy on dual-use capabilities, enforcing provenance of digital activity, and compelling developers to build safe tools, as model developers lack proper incentives for mitigation.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (10)</summary>
                <ul class="quote-list">
                    <li>"Almost all dangerous capabilities stem from dual-use skills. Model developers do not have the right incentives for mitigating dangerous capabilities. Governance actors must craft policy here."</li><li>"Model deployers are under strong pressures to maximize realized capabilities in dangerous areas (e.g. cybersecurity), and arguably have little obligation to not maximize capabilities. Therefore, AI governance actors do."</li><li>"Responsibility for addressing dangerous AI capabilities sits primarily with AI developers (both general and specialized) and AI governance actors, as they design, release, and regulate models that could be exploited for large-scale harm."</li><li>"The main risk driver is are bad and careless actors, markets will not solve this, governance solutions are needed."</li><li>"Responsibility rests with the developers and the governance organizations responsible for compelling them to develop safe tools."</li><li>"Governance bodies need to enforce provenance of digital activity in order to hold deployers accountable for risks here."</li><li>"Almost all dangerous capabilities stem from dual-use skills. Model developers do not have the right incentives for mitigating dangerous capabilities. Governance actors must craft policy here."</li><li>"Model deployers are under strong pressures to maximize realized capabilities in dangerous areas (e.g. cybersecurity), and arguably have little obligation to not maximize capabilities. Therefore, AI governance actors do."</li><li>"Only developers have reasonable capability to intervene on this, while only governments have a strong obligation to do so on the behalf of their citizens."</li><li>"Of course malicious users or jailbreakers of models are responsible for their actions (which is why they are listed as moderately responsible) but the main responsibility to mitigate the harm is to prevent it from existing which is on the developers and on governments and other governance professionals to ensure these capabilities are not in the models."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Some comments noted users need awareness of possible harms and malicious actors may intentionally use dangerous capabilities for financial gains.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"AI users and stakeholders need to be aware of possible harms."</li><li>"My main risk driver here is bad actors using dangerous capabilities intentionally to obtain for financial gains, and states using these capabilities to weaken or sabotage other states."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Most comments characterized users as having limited responsibility as recipients of risk rather than active risk managers, though malicious users bear responsibility for their actions while main mitigation responsibility lies with developers and governance.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"Users and affected stakeholders have limited responsibility, as they are more recipients of risk than active risk managers."</li><li>"While users and affected stakeholders have influence, they should not bear the brunt of mitigation responsibility."</li><li>"Of course malicious users or jailbreakers of models are responsible for their actions (which is why they are listed as moderately responsible) but the main responsibility to mitigate the harm is to prevent it from existing which is on the developers and on governments and other governance professionals to ensure these capabilities are not in the models."</li><li>"Individual users, deployers, etc. are not in the causal chain except in their capacity as constituents of the relevant government."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.actor-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    // Remove active class from all pills and sections
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    // Add active class to clicked pill
                    this.classList.add('active');

                    // Show corresponding section
                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>