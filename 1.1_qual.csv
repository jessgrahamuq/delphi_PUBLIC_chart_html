Category,Type,Quote,Criteria,Direction,Notes,
Actor,AI Developer (General-purpose AI),General-purpose AI developers and governance actors are primarily responsible: they shape both the technological foundations and the regulatory environment.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),AI developer (general purpose): foundation model design/training choices create/increase bias at scale across ecosystems.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),Developers know the full picture of AI systems being deployed including training data sources data filtering processes system prompts and safety guidelines. They operate at the foundation of everything. With their technical expertise (high ability) they have a professional obligation to detect and thoroughly test models for potential bias and discrimination (high obligation).,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),AI developers hold ultimate power to shape AI systems at their root (high exposure). Unlike AI deployers they have the advantage of full awareness of their model's inner workings including system prompts and training data used in development.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),General-purpose AI developers are primarily responsible since bias often originates in design and training.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),AI developer (general purpose):- less direct end-user harm but exposed to reputational contractual and regulatory risks.,Vulnerability,Higher,,
Actor,AI Developer (General-purpose AI),Generally I hold all actors responsible in a shared model to handle the risks from unfair discrimination and misrepresentation. I also strongly believe that foundation models need to show more responsibility than what we see them doing today.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),I believe that the AI developers should have the highest responsibility whilst the other actors should also have 'shared responsibility' to different extents which I believe would be brought out via this research work.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),AI developer - They make fundamental design decisions that determine whether discrimination gets built into systems. Their technical expertise makes them uniquely positioned to implement fairness measures.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),Whoever develops and adopts an AI System is highly responsible for managing these design risks.,Responsibility,Higher,"Not likely to be useful for experts to update their assessments, exclude",
Actor,AI Developer (General-purpose AI),Given the state of information asymmetry about model discrimination risks all actors serving that product to the user are fully responsible (AI developer AI deployer specialized AI Infra Provider Governance Actor).,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),Those that develop the algorithms must provide as much clear information as is needed for users and deployers to have the data they need to make an informed decision on it's use.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),Developers and deployers are at the core because design choices training data selections.,Responsibility,Higher,,
Actor,AI Developer (General-purpose AI),Bias is within the training data and training processes ergo responsibility sits with the model trainers. Not all providers will do this and so policing monitoring and enforcement sits with governance actors.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),Specialized developers and deployers are highly responsible since they decide how AI is applied in sensitive contexts and they have both the technical and organizational capacity to mitigate risks.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),AI developer — specialised AI: High-stakes domains (e.g. health/defence/finance) magnify harm if models are not safe and provide incorrect/inaccurate outputs.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),AI developer — specialised AI -Developers must ensure representation and accuracy are embedded in ai systems with critical domains.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),Developers of specialized AI bear responsibility not only for technical model details but also carry even greater responsibility than general-purpose AI developers due to their domain expertise.,Responsibility,Higher,,
Actor,AI Developer (Specialized AI),Responsibility of the Specialized AI developers is entirely contingent on the domain of the model and its application,Commentary,,,
Actor,AI Deployer,AI deployer: Select models data and controls in real world environment where harms occur.,Responsibility,Higher,,
Actor,AI Deployer,Specialized developers and deployers are highly responsible since they decide how AI is applied in sensitive contexts.,Responsibility,Higher,,
Actor,AI Deployer,AI deployer:- Deploy and integrate AI into products/services—biased outputs can trigger legal operational and reputational harm.,Vulnerability,Higher,,
Actor,AI Deployer,AI Deployers are highly vulnerable since discriminatory outputs can damage their customers employees and reputation leading to legal and operational consequences.,Vulnerability,Higher,,
Actor,AI Deployer,Deployer and User have primary responsibility to ensure that the system they are deploying/using is appropriate for the stakeholders that will be (directly)affected by the AI.,Responsibility,Higher,,
Actor,AI Deployer,AI deployers are highly responsible for through testing of the AI system they deploy creating their own system prompts to guide model behavior customizing models for their specific use cases and establishing safety guidelines for models to follow (high obligation and high causal influence). However their ability is constrained when using closed-source models.,Responsibility,"Higher, Lower",,
Actor,AI Deployer,AI deployer - They are usually the crucial gatekeepers between development and impact on users.,Responsibility,Higher,,
Actor,AI Deployer,AI Deployers need to understand the characteristics of the models they provide AND provide guardrails on the model interactions.,Responsibility,Higher,,
Actor,AI Deployer,Any vulnerability ascribed to AI developers or deployers has to do with harms caused to their organizational reputation which is extremely different from the tangible individual harms that users would experience from this risk,Commentary,,,
Actor,AI Governance Actor,AI governance actor: Set/verify rules that prevent systemic bias responsible for prevention/certification of AI systems for use.,Responsibility,Higher,,
Actor,AI Governance Actor,General-purpose AI developers and governance actors are primarily responsible: they shape both the technological foundations and the regulatory environment.,Responsibility,Higher,,
Actor,AI Governance Actor,Governance actors are highly responsible for setting enforceable standards.,Responsibility,Higher,,
Actor,AI Governance Actor,AI governance actor - No direct harm but risks are related to non-compliance/reputation and legal aspects.,Vulnerability,Higher,,
Actor,AI Governance Actor,Governance actors are minimally vulnerable because while they may face erosion of trust they are not personally exposed to discriminatory outcomes.,Vulnerability,Lower,,
Actor,AI Governance Actor,Policymakers: Very high They bear very high responsibility because they create and enforce the legal and institutional frameworks through binding rules mandated impact assessments clear reporting duties funding for oversight.,Responsibility,Higher,,
Actor,AI Governance Actor,For AI Governance Actor this should probably primarily be existing bodies responsible for discrimination and misrepresentation e.g. EHRC rather than an AI-specific regulator. This is not really a problem that is at all unique to AI and happens across many systems in basically the same way.,Commentary,Higher,,
Actor,AI Governance Actor,AI governance actors - These actors create the policies and sometimes the standards but they most of the time lack direct enforcement power over technical implementations.,Responsibility,Higher,,
Actor,AI Governance Actor,Governance actors have the authority to create policies laws frameworks and standards. They bear responsibility for properly overseeing and evaluating AI models setting clear expectations for acceptable behavior and defining prohibited forms of discrimination.,Responsibility,Higher,,
Actor,Commentary,AI Governance Actor - Governance actors from underrepresented groups face a weird situation. Their expertise on discrimination is usually essential for the assessment of these problems yet often dismissed as activism rather than technical competence.,Vulnerability,Higher,,
Actor,AI User,AI user: Must apply responsible use practices and highlight issues so AI systems can be used by relevant stakeholders in safe and secure mannner.,Responsibility,Higher,,
Actor,AI User,AI user - Users use AI outputs in their decisions there may be bias/harmful outcomes but users can control on output with human in loop approach.,Vulnerability,Higher,,
Actor,AI User,AI Users and Affected Stakeholders are extremely vulnerable as they directly experience biased decisions in domains such as credit education or healthcare.,Vulnerability,Higher,,
Actor,AI User,Users and affected stakeholders should not be held responsible because they lack both the power and the resources to address systemic bias.,Responsibility,Lower,,
Actor,AI User,AI User - End users face the most direct impact from discriminatory AI systems across critical domains (employment housing healthcare criminal justice) while having minimal power to contest or understand these decisions. They often lack technical literacy to recognize bias and have limited legal recourse.,Vulnerability,Higher,,
Actor,AI User,AI user - They have zero technical control but I think they have some responsibility to report discriminatory outcomes (when possible).,Responsibility,Higher,,
Actor,AI User,AI users interact directly with AI systems (high exposure) and face vulnerability in two main ways: they may personally experience harm from unfair discrimination and misrepresentation in AI outputs (high sensitivity) or they may unknowingly use discriminatory AI outputs in their work making them directly liable for perpetuating discrimination.,Vulnerability,Higher,,
Actor,AI User,Users cannot control models' inner workings and often can not even set parameters like temperature if they are simply using the web interface (low capability). However they can employ prompt engineering techniques to help ensure outputs are not discriminatory or biased.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,Infrastructure providers only play a minimal role as their contribution is largely indirect.,Responsibility,Lower,,
Actor,AI Infrastructure Provider,AI infrastructure provider: Enforce policies monitoring and safety controls.,Responsibility,Higher,,
Actor,AI Infrastructure Provider,AI infrastructure provider: - provides platforms/infra layer some model extraction/inversion/prompt attacks can lead to theft of data/models.,Vulnerability,Higher,,
Actor,AI Infrastructure Provider,Infrastructure providers have limited influence over outcomes.,Responsibility,Lower,,
Actor,AI Infrastructure Provider,I believe cloud computing and computer chip providers bear minimal responsibility in this sector. However I rate this sector as highly responsible because of entities that provide data to train AI systems (which is why I suggest separating data providers as their own distinct actor category apart from other infrastructure providers like Nvidia).,Responsibility,Higher,,
Actor,AI Infrastructure Provider,Ascribed some responsibility to AI Infrastructure Providers because it included data providers. They certainly do have the capability to address this risk either through better data cleaning or by flagging inadequacies in their data or transparently reporting on their data collection practices that can inform downstream development,Responsibility,Higher,,
Actor,Affected Stakeholder,Affected stakeholder: Bear the impact not the responsibility.,Responsibility,Lower,,
Actor,Affected Stakeholder,Affected stakeholder - Directly affected by AI outputs biased or inaccurate outputs can impact livelihoods access and fundamental rights.,Vulnerability,Higher,,
Actor,Affected Stakeholder,Users and affected stakeholders should not be held responsible because they lack both the power and the resources to address systemic bias.,Responsibility,Lower,,
Actor,Affected Stakeholder,Affected stakeholders should be included in AI development to voice their concerns and share their perspectives. However they should not be held responsible when their voices are excluded from this process. Holding affected stakeholders responsible for discrimination and bias would constitute victim blaming.,Responsibility,Lower,,
Actor,Affected Stakeholder,Although affected stakeholders may not all have high exposure to AI or directly interact with AI they represent the most sensitive group of stakeholders in the AI ecosystem.,Vulnerability,Higher,,
Actor,Affected Stakeholder,Affected stakeholder generally responsible for surfacing instances where the risk materializes. Not necessarily responsible for the mitigation itself.,Responsibility,"Higher, Lower",,
Actor,Auditors,Auditors: High They are expected to provide independent checks before and after deployment in terms of strategy severity scoring and or red teaming that impact that internal teams,Responsibility,,"not an actor in our framework, remove",
Actor,AI Infrastructure Provider,Data collectors: They hold very high responsibility because their choices in sampling consent labeling and documentation establish the baseline for fairness in all downstream AI systems.,Responsibility,Higher,,
Actor,AI Governance Actor,I believe that industry bodies should be highly responsible for Unfair discrimination as self-regulation is the most common approach in many jurisdictions and industry bodies are empowered to establish industry standards that minimise common harms to each sector.,Responsibility,Higher,,
Sector,All Sectors,All actors are vulnerable. Only the degree to which they are exposed varies.,Vulnerability,Higher,,
Sector,All Sectors,All sectors since the Millenium are Threat Vectors. You cannot rate one business lane with more criticality over another or you will stand to see the escalation of attacks from the overlook lane.,Vulnerability,Higher,,
Sector,All Sectors,Every sector is vulnerable to AI risks depending on the context and use of AI within them.,Vulnerability,Higher,,
Sector,All Sectors,It seems like unfair discrimination and misrepresentation could impact across all sectors.,Vulnerability,Higher,,
Sector,All Sectors,Every sector and segment of society is highly vulnerable to discrimination and misrepresentation by AI systems where appropriate design factors and mitigation has not been embedded within the AI Solution (i.e. ensuring data accuracy data diversity groundedness testing).,Vulnerability,Higher,,
Sector,All Sectors,AI is already disrupting the labor force across nearly every sector of the economy.,Vulnerability,Higher,,
Sector,All Sectors,You can have the use cases that perform decisioning that creates unfair discriminiations for human subjects in all of these different sector,Vulnerability,Higher,,
Sector,Finance,Finance & Insurance: Highly vulnerable because AI-driven decisions rely heavily on sensitive personal and demographic data which can amplify bias.,Vulnerability,Higher,,
Sector,Finance,Finance and Insurance/Healthcare and Social Assistance face the most severe harm from AI bias and misrepresentation with little ability to challenge or mitigate these impacts.,Vulnerability,Higher,,
Sector,Finance,Extremely: Information Finance/Insurance Health Care — high AI exposure + high harm if biased (search/ranking credit/underwriting triage/benefits).,Vulnerability,Higher,,
Sector,Finance,finance healthcare and education are extremely vulnerable as biased AI in these domains directly restricts access to essential services and life opportunities.,Vulnerability,Higher,,
Sector,Healthcare,Finance and Insurance/Healthcare and Social Assistance face the most severe harm from AI bias and misrepresentation with little ability to challenge or mitigate these impacts.,Vulnerability,Higher,,
Sector,Healthcare,Extremely: Information Finance/Insurance Health Care — high AI exposure + high harm if biased (search/ranking credit/underwriting triage/benefits).,Vulnerability,Higher,,
Sector,Healthcare,finance healthcare and education are extremely vulnerable as biased AI in these domains directly restricts access to essential services and life opportunities.,Vulnerability,Higher,,
Sector,Healthcare,My rating reflects the potential negative effects on people's rights in each sector. In sectors where the affected people do not have a high level of education or knowledge I believe there is more vulnerability. For example in the healthcare sectors patients have little means to defend themselves and the harm is greater.,Vulnerability,Higher,,
Sector,Healthcare,High vulnerability in sectors affecting broad populations in significant life opportunities. Areas like health and national security can have important impact as well but applications (health) and number of affected individuals (national security) are smaller.,Vulnerability,Higher,,
Sector,Education,finance healthcare and education are extremely vulnerable as biased AI in these domains directly restricts access to essential services and life opportunities.,Vulnerability,Higher,,
Sector,Education,Highly: Real Estate Education Public Administration Mgmt/Admin/Support — housing/admissions/benefits/HR decisions directly impact protected classes.,Vulnerability,Higher,,
Sector,Education,Educational services — highly vulnerable. Students commonly use generative AI to assist with learning and create presentation visuals. Subtle cues embedded in biased human representations can accumulate into stereotypical impressions over time reinforcing existing gender imbalances in different domains especially computer science.,Vulnerability,Higher,,
Sector,Information,Information/REal Estate/Educational/Public Administration/National Security are highly exposed to discriminatory AI that can cause systemic harm and reputational or regulatory risk.,Vulnerability,Higher,,
Sector,Information,Extremely: Information Finance/Insurance Health Care — high AI exposure + high harm if biased (search/ranking credit/underwriting triage/benefits).,Vulnerability,Higher,,
Sector,Information,Information/professional & Technical Services: highly vulnerable because bias training data drives algorithms.,Vulnerability,Higher,,
Sector,Public Administration,Information/REal Estate/Educational/Public Administration/National Security are highly exposed to discriminatory AI that can cause systemic harm and reputational or regulatory risk.,Vulnerability,Higher,,
Sector,Public Administration,Highly: Real Estate Education Public Administration Mgmt/Admin/Support — housing/admissions/benefits/HR decisions directly impact protected classes.,Vulnerability,Higher,,
Sector,Public Administration,Public administration is also highly vulnerable since discrimination in welfare or justice processes undermines fairness and trust in institutions.,Vulnerability,Higher,,
Sector,National Security,Information/REal Estate/Educational/Public Administration/National Security are highly exposed to discriminatory AI that can cause systemic harm and reputational or regulatory risk.,Vulnerability,Higher,,
Sector,National Security,High vulnerability in sectors affecting broad populations in significant life opportunities. Areas like health and national security can have important impact as well but applications (health) and number of affected individuals (national security) are smaller.,Commentary,Higher,,
Sector,National Security,National security of small country due to AI system will likely to be highly vulnerable. The major AI system owners are located in advanced countries and small nation cant afford the investment.,Vulnerability,Higher,,
Sector,Real Estate,Information/REal Estate/Educational/Public Administration/National Security are highly exposed to discriminatory AI that can cause systemic harm and reputational or regulatory risk.,Vulnerability,Higher,,
Sector,Real Estate,Highly: Real Estate Education Public Administration Mgmt/Admin/Support — housing/admissions/benefits/HR decisions directly impact protected classes.,Vulnerability,Higher,,
Sector,Professional Services,Information/professional & Technical Services: highly vulnerable because bias training data drives algorithms.,Vulnerability,Higher,,
Sector,Professional Services,Trade/Professional/Management/Accommodation experience significant vulnerability through policy design and reputational consequences.,Vulnerability,Higher,,
Sector,Professional Services,Trade/Transport/Utilities Professional/Tech Arts/Entertainment — some AI screening/moderation; harms material but less systemic.,Vulnerability,Higher,,
Sector,Management,Trade/Professional/Management/Accommodation experience significant vulnerability through policy design and reputational consequences.,Vulnerability,Higher,,
Sector,Management,Highly: Real Estate Education Public Administration Mgmt/Admin/Support — housing/admissions/benefits/HR decisions directly impact protected classes.,Vulnerability,Higher,,
Sector,Agriculture,Agriculture/Manufacturing Scientific R&D Accommodation/Food — lower direct use of AI in high-stakes person-level decisions.,Vulnerability,Lower,,
Sector,Agriculture,Agriculture/Scientific/Arts have limited direct exposure to AI discrimination but still remain vulnerable to reputational or other downstream effects.,Vulnerability,"Lower, Higher",,
Sector,Agriculture,Agriculture — extremely vulnerable. The impact of general-purpose AI on agriculture has received limited attention in recent years. Agriculture faces AI risks in several key ways: Misrepresentation of farming practices. Current AI systems romanticize livestock farming depicting cows grazing on pastures under blue skies and pigs roaming freely outdoors. In reality most farmed animals in industrialized countries live indoors with severely limited space which conflicts with societal values.,Vulnerability,Higher,,
Sector,Manufacturing,Agriculture/Manufacturing Scientific R&D Accommodation/Food — lower direct use of AI in high-stakes person-level decisions.,Vulnerability,Lower,,
Sector,Manufacturing,Manufacturing and R&D are less vulnerable with harms occurring mainly through indirect pathways (biased datasets or workplace AI).,Vulnerability,Lower,,
Sector,Arts,Agriculture/Scientific/Arts have limited direct exposure to AI discrimination but still remain vulnerable to reputational or other downstream effects.,Vulnerability,Lower,,
Sector,Arts,Trade/Transport/Utilities Professional/Tech Arts/Entertainment — some AI screening/moderation; harms material but less systemic.,Vulnerability,Lower,,
Sector,Arts,Arts entertainment and recreation — highly vulnerable. Bias still emerges in real-world situations when prompts become complex and highly specific.,Vulnerability,Higher,,
Sector,Scientific R&D,Agriculture/Manufacturing Scientific R&D Accommodation/Food — lower direct use of AI in high-stakes person-level decisions.,Vulnerability,Lower,,
Sector,Scientific R&D,Agriculture/Scientific/Arts have limited direct exposure to AI discrimination but still remain vulnerable to reputational or other downstream effects.,Vulnerability,Lower,,
Sector,Scientific R&D,Manufacturing and R&D are less vulnerable with harms occurring mainly through indirect pathways (biased datasets or workplace AI).,Vulnerability,Lower,,
Sector,Transportation,Trade/Transport/Utilities Professional/Tech Arts/Entertainment — some AI screening/moderation; harms material but less systemic.,Vulnerability,Lower,,
Sector,Utilities,Trade/Transport/Utilities Professional/Tech Arts/Entertainment — some AI screening/moderation; harms material but less systemic.,Vulnerability,Lower,,
Sector,Trade,Trade/Professional/Management/Accommodation experience significant vulnerability through policy design and reputational consequences.,Vulnerability,Higher,,
Sector,Trade,Trade/Transport/Utilities Professional/Tech Arts/Entertainment — some AI screening/moderation; harms material but less systemic.,Vulnerability,Lower,,
Sector,Accommodation,Trade/Professional/Management/Accommodation experience significant vulnerability through policy design and reputational consequences.,Vulnerability,Higher,,
Sector,Accommodation,Agriculture/Manufacturing Scientific R&D Accommodation/Food — lower direct use of AI in high-stakes person-level decisions.,Vulnerability,Lower,,
Sector,Commentary,Employment is a sector that is highly sensitive and vulnerable to unfair discrimination which is not explicitly mentioned in this list. That is a typical sector where existing historical data brings several biases that without explicit intervention AI would replicate.,,,,remove/exclude - this is a recommendation for an additional actor/sector group
Sector,Mining,Mining and Constructions using AI to do project staff scheduling or job assignments,Vulnerability,Higher,,
Sector,Construction,Mining and Constructions using AI to do project staff scheduling or job assignments,Vulnerability,Higher,,
General,Commentary,Primarily driven by scale of deployment impact on critical infrastructure complex supply chains presence of vulnerable groups and high susceptibility to bias or manipulation particularly in high-stakes sectors like healthcare finance education and public services,Commentary,,,
General,Commentary,I have rated each sector relatively low for vulnerability with regard to discrimination but sectors do not make sense as categories here.,Commentary,,,
General,Commentary,Accountability for each of the AI ecosystem actors is a very important. In the whole AI life cycle AI architect ML engineer Prompt engineer Data engineer AI developer AI tester all of them have to check and challenge each other.,Commentary,,,
General,Commentary,All walks of life/domains are vulnerable to unfair discrimination and misrepresentation from AI,Commentary,,,
General,Commentary,My responsibility assessments distinguish between obligation capability and causal influence.,Commentary,,,
General,Commentary,The sector framework isn't resonating with me in terms of vulnerable use cases.,Commentary,,,
General,Commentary,Lets recategorize unfair discrimination. What discrimination is fair? We all have bias and prejudicial preferences. That is core to Darwinism. Discrimination on the other hand is intentional malicious separation of which some of the components are segregation and racism.,Commentary,,,
General,Commentary,Overall my assessment is that sector captures the highest fraction of total variance in determining vulnerability to unfair discrimination. Sectors that pre-AI already had discrimination risks are at highest risk now in the AI era.,Commentary,,,
General,Commentary,If a developer is employed by a company to deploy a system they didn't design the primary responsibility lies with the company as deployer.,Commentary,,,
General,Commentary,I'm assuming a GPAI provider is primarily a LLM model whereas I'm visualizing a developer as a traditional ML data scientist. Is that accurate? Seems like the latter builds more precisely biased models despite the wide GPAI reach.,Commentary,,,
General,Commentary,Fields that already have barriers to entry for underrepresented groups will likely have those barriers reinforced by AI models.,Commentary,,,
General,Commentary,Verticals that make decisions using AI about end user/stakeholder health or financial well-being are particularly vulnerable.,Commentary,,,
General,Commentary,I am rating these generally based on the essential nature of products and services provided by these sectors with the exception of public admin. and national security which are able to legislate or have greater power to mitigate their own vulnerability.,Commentary,,,
Summary,AI Developer (General-purpose AI),"Comments overwhelmingly emphasized GPAI developers' primary responsibility as they shape technological foundations, with bias originating in design and training choices that create discrimination at scale across ecosystems. Multiple responses noted developers know the full picture including training data and system prompts, having ultimate power and technical expertise with professional obligation to detect and test for bias. Comments stressed developers make fundamental design decisions determining whether discrimination gets built into systems, needing to show more responsibility than currently demonstrated.",Responsibility,Higher,,
Summary,AI Developer (General-purpose AI),"Comments characterized GPAI developers as facing less direct end-user harm but exposed to reputational, contractual, and regulatory risks.",Vulnerability,Higher,,
Summary,AI Developer (Specialized AI),"Comments consistently rated specialized developers as highly responsible, deciding how AI is applied in sensitive contexts with technical and organizational capacity to mitigate risks. Multiple responses emphasized they bear even greater responsibility than general-purpose developers due to domain expertise, with high-stakes domains like health, defense, and finance magnifying harm if models aren't safe. Comments stressed developers must ensure representation and accuracy in critical domains.",Responsibility,Higher,,
Summary,AI Deployer,"Comments unanimously emphasized deployers' high responsibility as crucial gatekeepers between development and user impact, selecting models and controls in real-world environments where harms occur. Multiple responses noted deployers must thoroughly test AI systems, create system prompts guiding behavior, customize models for use cases, and provide guardrails on interactions, though ability is constrained with closed-source models. Comments stressed deployers have primary responsibility ensuring systems are appropriate for affected stakeholders.",Responsibility,Higher,,
Summary,AI Deployer,"Comments characterized deployers as highly vulnerable since discriminatory outputs damage customers, employees, and reputation leading to legal and operational consequences. Comments noted biased outputs can trigger legal, operational, and reputational harm, though vulnerability relates to organizational reputation rather than tangible individual harms.",Vulnerability,Higher,,
Summary,AI Governance Actor,"Comments consistently emphasized governance actors' primary to high responsibility for setting and verifying rules preventing systemic bias, creating enforceable standards, and shaping regulatory environment. Multiple responses noted they create legal and institutional frameworks through binding rules and mandated impact assessments, bearing responsibility for oversight and defining prohibited discrimination. Comments suggested existing discrimination bodies like EHRC may be more appropriate than AI-specific regulators.",Responsibility,Higher,,
Summary,AI Governance Actor,"Comments varied on governance actors' vulnerability, with some noting no direct harm but risks related to non-compliance and reputation, while others characterized them as minimally vulnerable facing erosion of trust but not personal exposure to discriminatory outcomes. One comment noted governance actors from underrepresented groups face dismissal of their discrimination expertise as activism rather than technical competence.",Vulnerability,Lower,,
Summary,AI User,"Comments varied widely on user responsibility, with some emphasizing users must apply responsible practices, highlight issues, and employ prompt engineering to ensure non-discriminatory outputs. However, others stressed users should not be held responsible as they lack power and resources to address systemic bias, having zero technical control though some responsibility to report discriminatory outcomes when possible.",Responsibility,Lower,,
Summary,AI User,"Comments unanimously rated users as extremely vulnerable, directly experiencing biased decisions in domains like credit, education, and healthcare. Responses emphasized users face most direct impact from discriminatory AI across critical domains while having minimal power to contest decisions, often lacking technical literacy to recognize bias with limited legal recourse. Comments noted users may personally experience harm or unknowingly perpetuate discrimination making them liable.",Vulnerability,Higher,,
Summary,AI Infrastructure Provider,"Comments varied on infrastructure providers' responsibility, with most noting minimal indirect role and limited influence over outcomes. However, some emphasized data providers specifically have high responsibility through capability for better data cleaning, flagging inadequacies, and transparent reporting. Comments noted cloud and chip providers bear minimal responsibility, but data collectors hold very high responsibility as their sampling and labeling choices establish fairness baselines.",Responsibility,Lower,,
Summary,AI Infrastructure Provider,Comments noted infrastructure providers face some vulnerability through platform/infrastructure layer risks including model extraction and data theft attacks.,Vulnerability,Higher,,
Summary,Affected Stakeholder,"Comments unanimously characterized affected stakeholders as bearing impact not responsibility, lacking power and resources to address systemic bias. Multiple responses emphasized holding them responsible would constitute victim blaming, though they should be included in development to voice concerns. One comment noted stakeholders are generally responsible for surfacing instances where risk materializes but not mitigation itself.",Responsibility,Lower,,
Summary,Affected Stakeholder,"Comments consistently rated affected stakeholders as extremely vulnerable, directly affected by AI outputs where bias can impact livelihoods, access, and fundamental rights. Responses noted they represent the most sensitive group in the AI ecosystem despite not all having high exposure or direct AI interaction.",Vulnerability,Higher,,
Summary,Finance and Insurance,"Comments unanimously rated finance as highly to extremely vulnerable, with AI-driven decisions relying heavily on sensitive personal and demographic data amplifying bias. Multiple responses emphasized finance faces most severe harm from AI bias with little ability to challenge impacts, with biased AI directly restricting access to essential services and life opportunities through credit and underwriting decisions.",Vulnerability,Higher,,
Summary,Health Care and Social Assistance,"Comments consistently characterized healthcare as extremely vulnerable, facing most severe harm from AI bias with little ability to challenge or mitigate impacts. Responses noted biased AI directly restricts access to essential services, with patients having little means to defend themselves facing greater harm. Comments emphasized high vulnerability affects broad populations in significant life opportunities.",Vulnerability,Higher,,
Summary,Educational Services,"Comments consistently rated education as highly to extremely vulnerable, with biased AI directly restricting access to essential services and life opportunities through admissions and benefits decisions impacting protected classes. Responses noted students commonly using generative AI face subtle cues embedding biased representations that accumulate into stereotypical impressions, reinforcing existing gender imbalances especially in computer science.",Vulnerability,Higher,,
Summary,Information,"Comments unanimously characterized information sector as highly to extremely vulnerable, exposed to discriminatory AI causing systemic harm with reputational and regulatory risk. Responses emphasized high AI exposure combined with high harm if biased through search and ranking algorithms, with bias in training data driving algorithms.",Vulnerability,Higher,,
Summary,Public Administration excluding National Security,"Comments consistently rated public administration as highly vulnerable, with discriminatory AI causing systemic harm through housing, benefits, and HR decisions directly impacting protected classes. Responses noted discrimination in welfare or justice processes undermines fairness and trust in institutions.",Vulnerability,Higher,,
Summary,National Security,Comments characterized national security as highly vulnerable to discriminatory AI causing systemic harm and reputational risk. One response noted small countries are particularly vulnerable as major AI system owners are located in advanced countries and small nations can't afford the investment.,Vulnerability,Higher,,
Summary,Real Estate and Rental and Leasing,"Comments consistently rated real estate as highly vulnerable, exposed to discriminatory AI causing systemic harm with housing and admissions decisions directly impacting protected classes.",Vulnerability,Higher,,
Summary,Professional and Technical Services,"Comments characterized professional services as highly vulnerable, with bias in training data driving algorithms and significant vulnerability through policy design and reputational consequences. Some noted AI screening and moderation create material though less systemic harms.",Vulnerability,Higher,,
Summary,"Management, Administrative, and Support Services","Comments rated management services as highly vulnerable through housing, benefits, and HR decisions directly impacting protected classes, experiencing significant vulnerability through policy design and reputational consequences.",Vulnerability,Higher,,
Summary,"Agriculture, Mining, Construction and Manufacturing","Comments varied on these sectors, with most rating them as having lower direct use of AI in high-stakes person-level decisions and limited direct exposure to AI discrimination. However, one extensive comment rated agriculture extremely vulnerable due to AI misrepresenting farming practices by romanticizing livestock farming. Comments noted mining and construction face vulnerability when using AI for project staff scheduling or job assignments.",Vulnerability,Lower,,
Summary,Scientific Research and Development,"Comments consistently characterized scientific R&D as having lower direct use of AI in high-stakes person-level decisions with limited direct exposure to AI discrimination, though remaining vulnerable to reputational or downstream effects with harms mainly through indirect pathways like biased datasets.",Vulnerability,Lower,,
Summary,"Arts, Entertainment, and Recreation","Comments varied on arts vulnerability, with some noting limited direct exposure to AI discrimination and material but less systemic harms from AI screening. However, one comment rated it highly vulnerable noting bias emerges in real-world situations when prompts become complex and highly specific.",Vulnerability,Lower,,
Summary,"Trade, Transportation, and Utilities","Comments varied on these sectors, with trade experiencing significant vulnerability through policy design and reputational consequences, while transportation and utilities face some AI screening/moderation with material but less systemic harms.",Vulnerability,Lower,,
Summary,"Accommodation, Food, and Other Services","Comments varied on accommodation services, with some noting significant vulnerability through policy design and reputational consequences, while others emphasized lower direct use of AI in high-stakes person-level decisions.",Vulnerability,Lower,,