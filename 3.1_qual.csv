Category,Type,Quote,Criteria,Direction,
Actor,AI Developer (General-purpose AI),general-purpose developers and deployers are primarily responsible as they design and operate the systems that most often generate and distribute false or misleading information.,Responsibility,Higher,
Actor,AI Developer (General-purpose AI),AI Developers (General-purpose and Specialized): Primarily responsible. They build the foundational architecture and tuning protocols that determine how information is generated filtered and validated. Without built-in alignment safeguards drift becomes inevitable.,Responsibility,Higher,
Actor,AI Developer (General-purpose AI),AI Developer (General-purpose AI) — Extremely vulnerable: These models are trained on massive datasets with limited filtering capabilities and are often used across high-stakes contexts.,Vulnerability,Higher,
Actor,AI Developer (General-purpose AI),AI Developer (General-purpose) - Extremely Vulnerable: While developers have full awareness of their systems' inner workings they must mitigate false and misinformation across various use cases. When false information emerges from their systems responsibility traces directly back to them resulting in lawsuits reputation damage and investor withdrawal.,Vulnerability,Higher,
Actor,AI Developer (General-purpose AI),AI Developer (General-purpose) - Primarily Responsible: Developers have complete knowledge of their systems including training data system prompts and safety guidelines. With high technical ability and obligation they operate at the foundation level where false information originates.,Responsibility,Higher,
Actor,AI Developer (Specialized AI),Specialized developers are highly responsible in critical domains such as healthcare education or justice where misinformation has immediate harmful effects.,Responsibility,Higher,
Actor,AI Developer (Specialized AI),AI Developer (Specialized AI) - Primarily Responsible: These developers bear even greater responsibility than general-purpose developers due to their domain expertise. When specialized systems still produce false information in their area of expertise it's more severe. they possess both technical knowledge and domain understanding necessary for accurate information delivery.,Responsibility,Higher,
Actor,AI Deployer,general-purpose developers and deployers are primarily responsible as they design and operate the systems that most often generate and distribute false or misleading information.,Responsibility,Higher,
Actor,AI Deployer,AI Deployers: Highly responsible. They decide how where and to whom these models are deployed. If deployment occurs in sensitive contexts (e.g. healthcare education law) oversight mechanisms must be in place.,Responsibility,Higher,
Actor,AI Deployer,AI Deployer — Extremely vulnerable: Deployment choices (e.g. context prompts guardrails) can unintentionally enable misinformation spread at scale especially in public-facing applications.,Vulnerability,Higher,
Actor,AI Deployer,AI deployers and developers are highly vulnerable to reputational damage and concerns about system reliability.,Vulnerability,Higher,
Actor,AI Deployer,AI Deployer - Highly Responsible: Deployers must thoroughly test systems and create appropriate safety guidelines giving them high obligation and causal influence. However their ability is constrained with closed-source models where they lack access to inner workings and original system prompts that guide behavior.,Responsibility,Higher,
Actor,AI Deployer,AI Deployers are responsible for the use of models within a context. Stochastic models should not be treated as oracles of ground truth - some other curated reference should be used to establish veracity. AI Deployers are responsible for indicating when responses come strictly for models or when there is associated ground truth data to establish their claims.,Responsibility,Higher,
Actor,AI Governance Actor,Governance actors are also highly responsible since effective regulation and auditing frameworks are required to ensure systemic accountability.,Responsibility,Higher,
Actor,AI Governance Actor,AI Governance Actors: Primarily responsible. These actors are uniquely positioned to enforce standards compliance and auditability across the ecosystem. Without governance no accountability loop is closed.,Responsibility,Higher,
Actor,AI Governance Actor,AI Governance Actor — Highly vulnerable: While tasked with oversight governance actors can unknowingly act on or reinforce misleading information if internal or third-party data sources are compromised.,Vulnerability,Higher,
Actor,AI Governance Actor,AI Governance Actor - Highly Responsible: They have authority to create policies and standards bearing responsibility for proper oversight and defining acceptable AI behavior. Though they may lack technical expertise for direct modification they set the regulatory framework.,Responsibility,Higher,
Actor,Commentary,Based on the current state of GPAI technology false and misleading information is a given -- an important part of the solution is to create resilience in users by making sure they take nothing for granted.,Commentary,,
Actor,AI Governance Actor,It's hard to hold anyone primarily responsible for false information as many systems (like generative LLMs) are essentially text prediction engines. It seems that governance actors and the users themselves should do a better job at facilitating tech-literacy.,Responsibility,Higher,
Actor,AI Governance Actor,I think there's a category error by including AI Governance Actors in this assessment. They're different in kind of users developers and deployers. They're more like a sector if anything.,Commentary,,Methodological criticism - EXCLUDE
Actor,AI User,AI Users: Minimally responsible. While users can report issues or misuse they cannot fix or trace the root causes. Burdening them with more responsibility than they are structurally equipped to hold creates a dangerous deflection of accountability.,Responsibility,Lower,
Actor,AI User,AI User — Extremely vulnerable: Most users lack the tools training or awareness to verify AI-generated content leaving them highly susceptible to false information.,Vulnerability,Higher,
Actor,AI User,AI Users and Affected Stakeholders are extremely vulnerable as direct recipients of false information that can lead to harmful decision-making.,Vulnerability,Higher,
Actor,AI User,AI User - Extremely Vulnerable: AI users face direct exposure to false information through daily interactions with AI systems. They're vulnerable either because they are the direct recipients of misleading content or they used the misleading content in their own work potentially facing legal liability.,Vulnerability,Higher,
Actor,AI User,AI User - Highly Responsible: Users can employ prompt engineering and must verify outputs giving them significant obligation. However model behavior sometimes remains beyond their control - for example prompt revision processes users can't reliably control or even be aware of.,Responsibility,"Higher, Lower",
Actor,AI User,Added some responsibility to users but this is not a current measure of their capability. With sufficient awareness and training users could develop the capability to discern the reliability of different sources of information. But want to clarify that this in NO WAY encourages obligation from the user,Commentary,"Higher, Lower",
Actor,AI User,High responsibility for AI deployers because it can be up to them to implement their own safeguards and filters. Moderate responsibility for AI users because it is also up to them to cross-check any information received.,Responsibility,Higher,
Actor,AI Infrastructure Provider,Infrastructure providers users and affected stakeholders cannot reasonably be held responsible as they lack the causal influence to prevent or mitigate the risk.,Responsibility,Lower,
Actor,AI Infrastructure Provider,AI Infrastructure Providers: Moderately responsible. They host and scale the systems but do not create or fine-tune model behavior. However they have the ability to flag abuse patterns at scale and enforce certain safeguards.,Responsibility,"Lower, Higher",
Actor,AI Infrastructure Provider,AI Infrastructure Provider - Highly Responsible: Here I specifically referring to data providers like labeling companies (not cloud/chip providers). They should ensure diverse representation in training data and filter misleading and false information from datasets.,Responsibility,Higher,
Actor,AI Infrastructure Provider,Ascribed some responsibility to AI Infrastructure Providers because it included data providers. They certainly do have the capability to address this risk either through better data cleaning or by flagging inadequacies in their data or transparently reporting on their data collection practices that can inform downstream development,Responsibility,Higher,
Actor,Affected Stakeholder,Infrastructure providers users and affected stakeholders cannot reasonably be held responsible as they lack the causal influence to prevent or mitigate the risk.,Responsibility,Lower,
Actor,Affected Stakeholder,Affected Stakeholders: Minimally responsible. They bear the consequences not the cause. However their feedback is critical for informing iterative improvement.,Responsibility,Lower,
Actor,Affected Stakeholder,Affected Stakeholders — Extremely vulnerable: These groups often bear the brunt of the consequences without being in control of the systems — especially marginalized communities or high-risk populations.,Vulnerability,Higher,
Actor,Affected Stakeholder,AI Users and Affected Stakeholders are extremely vulnerable as direct recipients of false information that can lead to harmful decision-making.,Vulnerability,Higher,
Actor,Affected Stakeholder,Affected Stakeholder - Extremely Vulnerable: This group experiences the highest sensitivity to harm suffering the most direct mental physical and financial consequences from AI-generated false information even without direct AI interaction.,Vulnerability,Higher,
Actor,Affected Stakeholder,Affected Stakeholder - Not Responsible: Holding affected stakeholders responsible would constitute victim blaming.,Responsibility,Lower,
Actor,Affected Stakeholder,Since affected stakeholders included advocacy groups they can lend expertise which can be helpful to mitigate such risks in the future. This is purely about capability not obligation,Responsibility,Higher,
Actor,Fact-checking Bodies,Independent fact-checking bodies and academic institutions should also be considered responsible actors since they provide essential safeguards for verification research and public resilience.,Responsibility,Higher,
Sector,All Sectors,Everyone is vulnerable,General Vulnerability Comment,General Vulnerability Comment,
Sector,All Sectors,Same as 3.1 hard to find a sector that would be safe from risk 3.2 materializing,General Vulnerability Comment,General Vulnerability Comment,
Sector,All Sectors,We are all highly vulnerable.,General Vulnerability Comment,General Vulnerability Comment,
Sector,Healthcare,The most vulnerable sectors to false or misleading information are information/media healthcare finance education and national security where misleading content directly undermines health economic stability knowledge and democratic resilience.,Vulnerability,Higher,
Sector,Healthcare,The healthcare Educational Services Information and National Security sectors are extremely vulnerable due to life-critical decisions and their societal impact.,Vulnerability,Higher,
Sector,Healthcare,Health Care and Social Assistance — Extremely vulnerable: Misinformation here can lead to severe medical harm misdiagnoses or delayed care.,Vulnerability,Higher,
Sector,Healthcare,Healthcare: In this area even with less reliance on LLMs any reliance at all on unsafe systems will affect a lot of people. So the vulnerability of users in this specific area is very high.,Vulnerability,Higher,
Sector,Finance,The most vulnerable sectors to false or misleading information are information/media healthcare finance education and national security where misleading content directly undermines health economic stability knowledge and democratic resilience.,Vulnerability,Higher,
Sector,Finance,Financial services Healthcare and Public Administration are the entities that provide basic care and services to affected stakeholders. Misinformation from deployed AI systems have near immediate and at times life threatening impacts.,Vulnerability,Higher,
Sector,Finance,Loss of life or critical capabilities may be more harmful for national security administraion utilities health and finance.,Vulnerability,Higher,
Sector,Education,The most vulnerable sectors to false or misleading information are information/media healthcare finance education and national security where misleading content directly undermines health economic stability knowledge and democratic resilience.,Vulnerability,Higher,
Sector,Education,The healthcare Educational Services Information and National Security sectors are extremely vulnerable due to life-critical decisions and their societal impact.,Vulnerability,Higher,
Sector,Education,Bodies that regularly position themselves as sources of truth are particularly vulnerable to misinformation should they fail to catch the misinformation at the onset of receiving it. They become primary sources to propagate that misinformation with credibility and authority. This includes: Education Professional Services Information & Scientific Research.,Vulnerability,Higher,
Sector,Education,Educational Services — Extremely vulnerable: Students and educators may adopt or propagate AI-generated misinformation embedding inaccuracies in formative learning processes.,Vulnerability,Higher,
Sector,Education,Educational Services and Researchers: Teachers and students may develop inappropriate dependence on AI for learning and assessment,Vulnerability,Higher,
Sector,National Security,The most vulnerable sectors to false or misleading information are information/media healthcare finance education and national security where misleading content directly undermines health economic stability knowledge and democratic resilience.,Vulnerability,Higher,
Sector,National Security,The healthcare Educational Services Information and National Security sectors are extremely vulnerable due to life-critical decisions and their societal impact.,Vulnerability,Higher,
Sector,National Security,National Security — Extremely vulnerable: Nation-state actors or malicious agents can exploit misinformation loops to disrupt public trust influence elections or destabilize institutions.,Vulnerability,Higher,
Sector,National Security,Loss of life or critical capabilities may be more harmful for national security administraion utilities health and finance.,Vulnerability,Higher,
Sector,Information,The most vulnerable sectors to false or misleading information are information/media healthcare finance education and national security where misleading content directly undermines health economic stability knowledge and democratic resilience.,Vulnerability,Higher,
Sector,Information,The healthcare Educational Services Information and National Security sectors are extremely vulnerable due to life-critical decisions and their societal impact.,Vulnerability,Higher,
Sector,Information,Bodies that regularly position themselves as sources of truth are particularly vulnerable to misinformation. This includes: Education Professional Services Information & Scientific Research.,Vulnerability,Higher,
Sector,Information,Information Sector — Extremely vulnerable: Directly responsible for content generation news and dissemination. AI integration without safeguards can dramatically alter public discourse and belief systems.,Vulnerability,Higher,
Sector,Information,Information Sector - Extremely Vulnerable: This sector is particularly susceptible given its core function of information dissemination and the potential for AI-generated false information to compound existing fake news and misinformation challenges.,Vulnerability,Higher,
Sector,Information,Information sector: Journalists and researchers may unknowingly propagate AI-generated misinformation due to the plausible nature of LLM outputs,Vulnerability,Higher,
Sector,Scientific Research,Scientific research and public administration are also highly exposed as disinformation undermines trust in science and institutions.,Vulnerability,Higher,
Sector,Scientific Research,Scientific Research is highly vulnerable due to the potential contamination of research processes with false data.,Vulnerability,Higher,
Sector,Scientific Research,Bodies that regularly position themselves as sources of truth are particularly vulnerable to misinformation. This includes: Education Professional Services Information & Scientific Research.,Vulnerability,Higher,
Sector,Scientific Research,Scientific Research and Development — Extremely vulnerable: False or hallucinated outputs can skew experiments academic publications or public understanding of science.,Vulnerability,Higher,
Sector,Public Administration,Scientific research and public administration are also highly exposed as disinformation undermines trust in science and institutions.,Vulnerability,Higher,
Sector,Public Administration,Financial services Healthcare and Public Administration are the entities that provide basic care and services to affected stakeholders. Misinformation from deployed AI systems have near immediate and at times life threatening impacts.,Vulnerability,Higher,
Sector,Public Administration,Loss of life or critical capabilities may be more harmful for national security administraion utilities health and finance.,Vulnerability,Higher,
Sector,Professional Services,Bodies that regularly position themselves as sources of truth are particularly vulnerable to misinformation. This includes: Education Professional Services Information & Scientific Research.,Vulnerability,Higher,
Sector,Professional Services,Professional/Technical Services: Consultants and analysts risk over-relying on AI for complex problem-solving where nuanced human judgment is critical,Vulnerability,Higher,
Sector,Agriculture,Agriculture - Extremely Vulnerable: AI systems romanticize livestock farming with pastoral imagery while reality involves intensive indoor systems creating a dangerous trust gap.,Vulnerability,Higher,
Sector,General ,The sectors I rated as highly/extremely vulnerable share a common characteristic: heavy reliance on Large Language Models (LLMs) by employees and stakeholders. The fundamental challenge with LLMs is their mostly correct problem - they generate plausible coherent responses that are accurate most of the time making it extremely difficult to identify when they produce errors hallucinations or biased outputs.,General Vulnerability Comment,General Vulnerability Comment,
General,Commentary,Primarily driven by scale of deployment impact on critical infrastructure complex supply chains presence of vulnerable groups and high susceptibility to bias or manipulation particularly in high-stakes sectors like healthcare finance education and public services,General Vulnerability Comment,General Vulnerability Comment,
General,Commentary,A number of the impacts and vulnerability to the risk overlap with current vulnerability to active misinformation operations,General Vulnerability Comment,General Vulnerability Comment,
General,Commentary,This is complicated because: - People frequently make harmful decisions - People who make these decisions often demonstrably hold false beliefs - AI systems often produce false information including false information aligned with the above. However it is hard to quantify how much AI really contributes to the problem because people made plenty of bad decisions based on false beliefs prior to AI systems rising to prominence.,General Vulnerability Comment,General Vulnerability Comment,
General,Commentary,Any vulnerability ascribed to AI developers or deployers has to do with harms caused to their organizational reputation which is extremely different from the tangible individual harms that users would experience from this risk,General Vulnerability Comment,General Vulnerability Comment,
General,AI Developer (Specialized AI),Responsibility of the Specialized AI developers is entirely contingent on the domain of the model and its application,General Responsibility Comment,General Responsibility Comment,
Summary,AI Developer (General-purpose AI),"Comments consistently emphasized GPAI developers' primary responsibility as they design systems generating and distributing false information, with complete knowledge of training data and system prompts, though building foundational architecture where false information originates.",Responsibility,Higher,
Summary,AI Developer (General-purpose AI),"Comments characterized GPAI developers as extremely vulnerable, facing lawsuits, reputation damage, and investor withdrawal when false information emerges from their systems, despite having full awareness of inner workings.",Vulnerability,Higher,
Summary,AI Developer (Specialized AI),"Comments emphasized specialized developers bear even greater responsibility than general-purpose developers due to domain expertise, making false information in their specialty areas more severe, particularly in critical domains like healthcare, education, and justice.",Responsibility,Higher,
Summary,AI Deployer,"Comments consistently rated deployers as primarily to highly responsible for deciding deployment contexts and creating safety guidelines, though their ability is constrained with closed-source models where they lack access to inner workings.",Responsibility,Higher,
Summary,AI Deployer,"Comments characterized deployers as extremely vulnerable to reputational damage and reliability concerns, with deployment choices potentially enabling misinformation spread at scale in public-facing applications.",Vulnerability,Higher,
Summary,AI Governance Actor,"Comments overwhelmingly emphasized governance actors' primary to high responsibility for enforcing standards, compliance, and auditing across the ecosystem, with unique positioning to close accountability loops and facilitate tech-literacy.",Responsibility,Higher,
Summary,AI Governance Actor,Comments noted governance actors as highly vulnerable because they can unknowingly act on or reinforce misleading information if internal or third-party data sources are compromised.,Vulnerability,Higher,
Summary,AI Infrastructure Provider,"Comments varied on infrastructure providers' responsibility, with most noting moderate to low responsibility as they host but don't create model behavior, though data providers specifically should ensure diverse representation and filter misleading information.",Responsibility,Lower,
Summary,AI Infrastructure Provider,"Some comments emphasized higher responsibility for data providers specifically, who should ensure diverse representation and transparent reporting on data collection practices.",Responsibility,Higher,
Summary,AI User,"Comments varied widely, with some noting users have minimal responsibility as they cannot fix root causes, while others emphasized high responsibility for employing prompt engineering and verifying outputs, though model behavior remains beyond their control.",Responsibility,Lower,
Summary,AI User,"Some comments noted users have higher responsibility for cross-checking information and could develop capability to discern reliability with sufficient training, though this doesn't imply obligation.",Responsibility,Higher,
Summary,AI User,"Comments consistently rated users as extremely vulnerable, lacking tools, training, or awareness to verify AI-generated content, facing direct exposure through daily interactions with potential legal liability from using misleading content.",Vulnerability,Higher,
Summary,Affected Stakeholder,"Comments consistently characterized affected stakeholders as minimally responsible, bearing consequences not causes, with any responsibility assignment constituting victim blaming, though advocacy groups can lend expertise through capability not obligation.",Responsibility,Lower,
Summary,Affected Stakeholder,"Comments unanimously rated affected stakeholders as extremely vulnerable, bearing the brunt of consequences without system control, experiencing the highest sensitivity to mental, physical, and financial harm even without direct AI interaction.",Vulnerability,Higher,
Summary,Fact-checking Bodies,One comment noted independent fact-checking bodies and academic institutions should be considered responsible for providing essential safeguards through verification and research.,Responsibility,Higher,
Summary,"Agriculture, Mining, Construction and Manufacturing","Comments noted agriculture as extremely vulnerable due to AI systems romanticizing livestock farming with pastoral imagery while reality involves intensive indoor systems, creating a dangerous trust gap.",Vulnerability,Higher,
Summary,"Trade, Transportation, and Utilities",Comments noted utilities face vulnerability where loss of critical capabilities may be particularly harmful from false information.,Vulnerability,Higher,
Summary,Information,"Comments unanimously rated information as extremely vulnerable, directly responsible for content generation and dissemination where AI integration without safeguards can dramatically alter public discourse and compound existing misinformation challenges.",Vulnerability,Higher,
Summary,Finance and Insurance,"Comments consistently characterized finance as highly to extremely vulnerable, undermining economic stability and providing basic services where misinformation has near immediate and life-threatening impacts.",Vulnerability,Higher,
Summary,Real Estate and Rental and Leasing,No specific vulnerability comments provided for real estate regarding false or misleading information.,Vulnerability,N/A,
Summary,Professional and Technical Services,"Comments noted professional services as highly vulnerable as bodies positioning themselves as sources of truth become primary propagators of misinformation with credibility, with consultants risking over-reliance on AI where human judgment is critical.",Vulnerability,Higher,
Summary,Scientific Research and Development,"Comments unanimously rated scientific research as extremely vulnerable due to potential contamination with false data, with false or hallucinated outputs skewing experiments and academic publications.",Vulnerability,Higher,
Summary,"Management, Administrative, and Support Services",No specific vulnerability comments provided for management and administrative services regarding false or misleading information.,Vulnerability,N/A,
Summary,Educational Services,"Comments consistently emphasized education's extreme vulnerability, with students and educators potentially adopting and propagating AI-generated misinformation in formative learning processes, developing inappropriate dependence on AI.",Vulnerability,Higher,
Summary,Health Care and Social Assistance,"Comments unanimously rated healthcare as extremely vulnerable where misinformation can lead to severe medical harm, misdiagnoses, or delayed care, with life-critical decisions having immediate and life-threatening impacts.",Vulnerability,Higher,
Summary,"Arts, Entertainment, and Recreation",No specific vulnerability comments provided for arts and entertainment regarding false or misleading information.,Vulnerability,N/A,
Summary,"Accommodation, Food, and Other Services",No specific vulnerability comments provided for accommodation and food services regarding false or misleading information.,Vulnerability,N/A,
Summary,Public Administration excluding National Security,"Comments consistently rated public administration as highly vulnerable, providing basic services where misinformation has near immediate impacts and undermines trust in institutions.",Vulnerability,Higher,
Summary,National Security,"Comments unanimously characterized national security as extremely vulnerable, where nation-state actors can exploit misinformation to disrupt public trust, influence elections, and destabilize institutions, with loss of life or critical capabilities being particularly harmful.",Vulnerability,Higher,