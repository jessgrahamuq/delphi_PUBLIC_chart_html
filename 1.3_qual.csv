Category Type,Category,Quote,Criteria,Direction,QA Status ,Comments
Actor,General,"I tried to focus on specific cases that I am aware of, but I am not sure the sector categorization is the most suitable. For example, where do Deliveroo riders fit?",Vulnerability,Neutral,complete,
Actor,AI Developer (General-purpose AI),"Bias in AI and datasets are issues primarily known by AI developers and AI providers, who are the only ones with actual power to do something about it. So they should be the most responsible.",Responsibility,Higher,complete,
Actor,AI Infrastructure Provider,"Bias in AI and datasets are issues primarily known by AI developers and AI providers, who are the only ones with actual power to do something about it. So they should be the most responsible.",Responsibility,Higher,complete,
Actor,Finance and Insurance,"Service industries as well as public services to the general population. For example, pricing inequalities in insurance.",Vulnerability,Higher,complete,"doesn't provide reasoning, not useful, exclude"
Actor,General,AI System Owners (unless it is the same thing as Deployer). It is essential to ensure clear accountability is established.,Responsibility,Higher,complete,"not useful, exclude"
Actor,General,inversely proportional to vulnerability in this case,Responsibility,Neutral,complete,"not useful, exclude"
Actor,AI User,"My assessments reflect both direct and systemic exposure to unequal AI performance. AI users and affected stakeholders are extremely vulnerable, since they are the ones who experience inaccurate or unfair outcomes (e.g., patients misdiagnosed, students mis-scored, applicants denied opportunities).",Vulnerability,Higher,complete,
Actor,Affected Stakeholder,"My assessments reflect both direct and systemic exposure to unequal AI performance. AI users and affected stakeholders are extremely vulnerable, since they are the ones who experience inaccurate or unfair outcomes (e.g., patients misdiagnosed, students mis-scored, applicants denied opportunities).",Vulnerability,Higher,complete,
Actor,AI Deployer,"Deployers and specialized developers are highly vulnerable, as biased performance in their systems creates legal, reputational, and operational consequences.",Vulnerability,Higher,complete,
Actor,AI Developer (Specialized AI),"Deployers and specialized developers are highly vulnerable, as biased performance in their systems creates legal, reputational, and operational consequences.",Vulnerability,Higher,complete,
Sector,Finance and Insurance,"Finance, healthcare, and education are the most vulnerable sectors, because group-level disparities in accuracy directly affect rights, health, and life opportunities.",Vulnerability,Higher,complete,
Sector,Health Care and Social Assistance,"Finance, healthcare, and education are the most vulnerable sectors, because group-level disparities in accuracy directly affect rights, health, and life opportunities.",Vulnerability,Higher,complete,
Sector,Educational Services,"Finance, healthcare, and education are the most vulnerable sectors, because group-level disparities in accuracy directly affect rights, health, and life opportunities.",Vulnerability,Higher,complete,
Sector,Public Administration excluding National Security,"Public administration is also highly exposed, as unequal treatment in welfare or justice undermines equity and trust.",Vulnerability,Higher,complete,
Sector,"Agriculture, Mining, Construction and Manufacturing","By contrast, manufacturing and R&D are less vulnerable, with exposure limited to secondary effects such as biased datasets or workforce allocation.",Vulnerability,Lower,complete,
Sector,Scientific Services,"By contrast, manufacturing and R&D are less vulnerable, with exposure limited to secondary effects such as biased datasets or workforce allocation.",Vulnerability,Lower,complete,
Actor,General,"An additional actor that should be considered responsible is the standardization and certification bodies (e.g., ISO, professional accreditation agencies). They play a crucial role in setting benchmarks for testing AI performance across groups and ensuring that fairness metrics are systematically applied in practice. Their responsibility lies in providing independent, enforceable standards that complement regulation and technical development.",Responsibility,Higher,complete,"suggestion for additional actor, suggest removing - or are these part of AI governance actors?"
Actor,AI Developer (General-purpose AI),"My responsibility assessments emphasize that accountability should be placed on those who have both causal influence and capacity. General-purpose developers and governance actors are primarily responsible, as they define the foundations and frameworks for fairness.",Responsibility,Higher,complete,
Actor,AI Governance Actor,"My responsibility assessments emphasize that accountability should be placed on those who have both causal influence and capacity. General-purpose developers and governance actors are primarily responsible, as they define the foundations and frameworks for fairness.",Responsibility,Higher,complete,
Actor,AI Developer (Specialized AI),"Specialized developers and deployers are highly responsible, because they control application in sensitive domains and can mitigate performance disparities.",Responsibility,Higher,complete,
Actor,AI Deployer,"Specialized developers and deployers are highly responsible, because they control application in sensitive domains and can mitigate performance disparities.",Responsibility,Higher,complete,
Actor,AI Infrastructure Provider,"Infrastructure providers have only a marginal role, while users and affected stakeholders cannot reasonably be held responsible since they lack agency and resources.",Responsibility,Lower,complete,
Actor,AI User,"Infrastructure providers have only a marginal role, while users and affected stakeholders cannot reasonably be held responsible since they lack agency and resources.",Responsibility,Lower,complete,
Actor,Affected Stakeholder,"Infrastructure providers have only a marginal role, while users and affected stakeholders cannot reasonably be held responsible since they lack agency and resources.",Responsibility,Lower,complete,
Actor,General,"Independent standardization bodies should also be included as responsible actors, as they are key in defining measurable fairness criteria across industries.",Responsibility,Higher,complete,"not sure if this belongs in governance actors? if suggestion for new actor, remove"
Sector,Finance and Insurance,"The greatest vulnerabilities appear in finance, healthcare, information services, and national secutity, where bias AI decisions can cause large-scale and irreversible harm.",Vulnerability,Higher,complete,
Sector,Health Care and Social Assistance,"The greatest vulnerabilities appear in finance, healthcare, information services, and national secutity, where bias AI decisions can cause large-scale and irreversible harm.",Vulnerability,Higher,complete,
Sector,Information,"The greatest vulnerabilities appear in finance, healthcare, information services, and national secutity, where bias AI decisions can cause large-scale and irreversible harm.",Vulnerability,Higher,complete,
Sector,National Security,"The greatest vulnerabilities appear in finance, healthcare, information services, and national secutity, where bias AI decisions can cause large-scale and irreversible harm.",Vulnerability,Higher,complete,
Actor,AI Developer (General-purpose AI),AI developers are the root cause of technical disparities.,Responsibility,Higher,complete,
Actor,AI Deployer,AI deployers operationalize fairness.,Responsibility,Higher,complete,
Actor,AI Governance Actor,Governance actors enforce compliance.,Responsibility,Higher,complete,
Actor,General,Same reasoning as applied to 1.2,Responsibility,Neutral,complete,exclude - incomplete/empty
Actor,General,Governments/regulators?,Responsibility,Higher,complete,exclude - incomplete/empty
Actor,General,None,Responsibility,Neutral,complete,exclude - incomplete/empty
Actor,General,No,Responsibility,Neutral,complete,exclude - incomplete/empty
Actor,General,No,Responsibility,Neutral,complete,exclude - incomplete/empty
Sector,Finance and Insurance,"Sectors like Finance, Healthcare, National Security, and Information should be rated extremely vulnerable due to the combination of historical inequities, high-stakes outcomes, and widespread AI deployment.",Vulnerability,Higher,complete,
Sector,Health Care and Social Assistance,"Sectors like Finance, Healthcare, National Security, and Information should be rated extremely vulnerable due to the combination of historical inequities, high-stakes outcomes, and widespread AI deployment.",Vulnerability,Higher,complete,
Sector,National Security,"Sectors like Finance, Healthcare, National Security, and Information should be rated extremely vulnerable due to the combination of historical inequities, high-stakes outcomes, and widespread AI deployment.",Vulnerability,Higher,complete,
Sector,Information,"Sectors like Finance, Healthcare, National Security, and Information should be rated extremely vulnerable due to the combination of historical inequities, high-stakes outcomes, and widespread AI deployment.",Vulnerability,Higher,complete,
Sector,Educational Services,Education and Public Administration are also highly vulnerable because unequal performance compounds systemic inequities.,Vulnerability,Higher,complete,
Sector,Public Administration excluding National Security,Education and Public Administration are also highly vulnerable because unequal performance compounds systemic inequities.,Vulnerability,Higher,complete,
Sector,Scientific Services,"By contrast, sectors like Scientific R&D and Accommodation have relatively lower vulnerability, though they may indirectly propagate biases downstream.",Vulnerability,Lower,complete,
Sector,"Accommodation, Food, and Other Services","By contrast, sectors like Scientific R&D and Accommodation have relatively lower vulnerability, though they may indirectly propagate biases downstream.",Vulnerability,Lower,complete,
Actor,General,Auditors / Third-party Evaluators,Responsibility,Higher,complete,incomplete/no justification - exclude
Actor,General,Data provider/curator – Primarily responsible,Responsibility,Higher,complete,incomplete/no justification - exclude
Actor,General,Labeling/annotation vendor – Primarily responsible,Responsibility,Higher,complete,incomplete/no justification - exclude
Actor,General,"Assign responsibility to actors with control over data, labels, model choices, thresholds, and deployment context.",Responsibility,Higher,complete,incomplete/no justification - exclude
Actor,General,Personal information,Vulnerability,Neutral,complete,incomplete/no justification - exclude
Actor,General,None.,Responsibility,Neutral,complete,incomplete/no justification - exclude
Actor,General,Omission,Responsibility,Neutral,complete,incomplete/no justification - exclude
Actor,General,training data provider,Responsibility,Higher,complete,incomplete/no justification - exclude
Sector,Finance and Insurance,"Finance, health care, housing, education, and national security are extremely or highly vulnerable since unequal performance has life-altering consequences.",Vulnerability,Higher,complete,
Sector,Health Care and Social Assistance,"Finance, health care, housing, education, and national security are extremely or highly vulnerable since unequal performance has life-altering consequences.",Vulnerability,Higher,complete,
Sector,Real Estate and Rental and Leasing,"Finance, health care, housing, education, and national security are extremely or highly vulnerable since unequal performance has life-altering consequences.",Vulnerability,Higher,complete,
Sector,Educational Services,"Finance, health care, housing, education, and national security are extremely or highly vulnerable since unequal performance has life-altering consequences.",Vulnerability,Higher,complete,
Sector,National Security,"Finance, health care, housing, education, and national security are extremely or highly vulnerable since unequal performance has life-altering consequences.",Vulnerability,Higher,complete,
Sector,Information,Information systems amplify bias at scale.,Responsibility,Higher,complete,
Actor,General,HR and credit-scoring intermediaries are critical actors since they mediate high-stakes decisions.,Responsibility,Higher,complete,
Sector,"Agriculture, Mining, Construction and Manufacturing","By contrast, agriculture and scientific R&D are minimally vulnerable, as unequal performance in those contexts has limited direct demographic impact.",Vulnerability,Lower,complete,
Sector,Scientific Services,"By contrast, agriculture and scientific R&D are minimally vulnerable, as unequal performance in those contexts has limited direct demographic impact.",Vulnerability,Lower,complete,
Actor,AI Deployer,"Deployers have the highest capability in this case because they can decide the deployment context, which includes knowledge about which groups will be affected. Therefore, they are primarily responsible.",Responsibility,Higher,complete,
Actor,AI Developer (General-purpose AI),Developers and deployers bare the lions share of responsibility of assuring their models are trained on unbiased data.,Responsibility,Higher,complete,
Actor,AI Deployer,Developers and deployers bare the lions share of responsibility of assuring their models are trained on unbiased data.,Responsibility,Higher,complete,
Actor,AI User,The users bare responsibility of researching the model's they use and making responsible selections.,Responsibility,Higher,complete,
Actor,AI Developer (General-purpose AI),Developers are responsible for creating ethically developed tech and users are responsible for doing their homework and picking an ethical and representative model.,Responsibility,Higher,complete,
Actor,AI User,Developers are responsible for creating ethically developed tech and users are responsible for doing their homework and picking an ethical and representative model.,Responsibility,Higher,complete,
Sector,Health Care and Social Assistance,In health care and social assistance the social and biological realities of users being part of different subgroups may reasonably lead to differences in the logic of how a prediction may need to be performed. An algorithm trained without considering this reality may learn only to accurately perform on the majority class(es). The sensitivity is extremely high since it could lead to death or severe harm to people in certain critical contexts in which AI may be used and the exposure is relatively high due to the increasing use of AI in health care and social assistance,Vulnerability,Higher,complete,
Actor,AI Developer (General-purpose AI),"I assigned ""High responsibility"" to AI developers due to their potential to control model's behavior. However, I do not believe they are primarily responsible since they may often be unaware of how their systems may be deployed or used by third-parties, in which case the responsibility would fall onto the deployers since they are the ones who control the specific deployment and have an understanding on which populations the AI will be used",Responsibility,Higher,complete,
Actor,AI Deployer,"I assigned ""High responsibility"" to AI developers due to their potential to control model's behavior. However, I do not believe they are primarily responsible since they may often be unaware of how their systems may be deployed or used by third-parties, in which case the responsibility would fall onto the deployers since they are the ones who control the specific deployment and have an understanding on which populations the AI will be used",Responsibility,Higher,complete,
Actor,General,"Employment is a sector that is highly sensitive and vulnerable to unequal performance, which is not explicitly mentioned in this list. That is a typical sector where existing historical data brings several biases that, without explicit intervention, AI would replicate. AI users, the employment marketplace, marginalised groups, and the entire society become vulnerable in this scenario.",Vulnerability,Higher,complete,"suggestion for new sector, exclude from comments"
Actor,General,Government (high) and industry bodies (high),Responsibility,Higher,complete,"exclude - vague, not useful "
Actor,General,"I believe that industry bodies should be highly responsible for this risk, as self-regulation is the most common approach in many jurisdictions, and industry bodies are empowered to establish industry standards that minimise common harms to each sector.",Responsibility,Higher,complete,
Sector,National Security,"I get my take on national security being highly vulnerable is probably a bit contrarian, but I do worry that defense will begin to rely too much on these outputs and stop using common sense and human consultation. This is already happening with laparoscopic surgeons, critical thinking skills suffer when reliance on AI copilots becomes a habit. This could be a disaster for national security. Many of these decisions require more than 90% accuracy",Vulnerability,Higher,complete,"This person doesn't appear to be commenting on the right risk, or has a very poor understanding of the risk being asked about exclude"
Actor,General,"Again, focusing on the potential unequal outcomes from the use of AI among the underlying labor force supporting each of these sectors of the economy, each is at the very least somewhat or moderately vulnerable.",Vulnerability,Higher,complete,
Actor,General,The degree to which society deems the various actors in the AI ecosystem responsible for unequal performance across groups rests primarily in the realm of public policy and the courts.,Responsibility,Neutral,complete,
Actor,General ,"Data Curators & Annotation Teams, and that would be at a high resp. level as well due to the fact that they: Ensuring representative sampling across groups. Apply diverse annotation teams to minimize subjective bias. Document dataset composition and potential limitations. Use bias-mitigation techniques during curation.",Responsibility,Higher,complete,"suggesting addition of new actor group, not likely to be useful for updating assessments, exclude"
Sector,"Agriculture, Mining, Construction and Manufacturing","[1] Agriculture – highly vulnerable. As mentioned in my previous comments, generative AI demonstrates unequal performance and accuracy across different farm animal groups, exhibits significant bias in romanticizing livestock farming, and lacks realistic representation of actual farming practices. This risks widening the gap between reality and public perception, potentially threatening the livestock industry's social license to operate when the public discovers the truth. I rated agriculture as highly vulnerable also because AI risks to non-human animals are frequently overlooked in AI risk discussions.",Vulnerability,Higher,complete,
Sector,Commentary ,"Additionally, most AI-based precision livestock farming (PLF) products are designed for monitoring indoor rather than outdoor animals. Several factors drive this trend: First, most farm animals worldwide are housed exclusively indoors, making intensive farms the primary PLF consumers (particularly since large intensive operations typically have resources to purchase PLF products). Second, indoor housing enables easier control of lighting conditions, better protection from dust for hardware, and internet access, all of which contribute to higher model performance and ease of operation. However, this creates incentives to keep animals exclusively indoors for monitoring and management convenience, further intensifying farming systems and moving away from practices that are sustainable long-term and aligned with societal values.",Vulnerability,Higher,complete,"exclude - too much content for comments section, and subtantially off topic"
Sector,Educational Services,"[2] Educational services – highly vulnerable. Many have been saying that AI could help democratize education, make education and personal AI tutor more accessible to communities that traditionally has less resources. However, Unequal performance across groups, such as less knowledge and worse answer when the user is asking in languages spoken by marginalized communities, could mean that AI is furthering and broadening the imbalance between those from privileged English-speaking background, compared to those who do not speak English.",Vulnerability,Higher,complete,
Sector,Health Care and Social Assistance,"[3] Health care and social assistance – extremely vulnerable. Previous research has shown that existing medical data and diagnostic tools are designed primarily with Caucasian populations' medical conditions in mind, and perform poorly in detecting certain medical conditions in people of color. I've rated this as extremely vulnerable because unequal treatment in healthcare can directly affect people's health and lives.",Vulnerability,Higher,complete,
Sector,National Security,"[4] National Security – extremely vulnerable. I've rated this as extremely vulnerable because national security sector involves serious actions in large scale and consequences. When AI systems exhibit bias against certain groups of individuals (e.g., people of color) and are combined with automated weapons possessing great destructive power, this creates a recipe for disaster, tragedy, and democratic backlash.",Vulnerability,Higher,complete,
Sector,Finance and Insurance,"[5] I've rated ""Finance and insurance"", ""real estate and rental and leasing"", ""professional and technical services"", ""management, administrative, and support services"", ""public administration"" as highly vulnerable. This is because unequal AI performance, such as disproportionately favoring men in hiring decisions, judging people of color as more likely to be guilty, providing smaller loans to minorities, or approving rental applications primarily for Caucasian applicants—carries serious consequences. These biases deny opportunities to people of color, minorities, and marginalized communities while reinforcing existing discrimination and power imbalances against these groups.",Vulnerability,Higher,complete,
Sector,Real Estate and Rental and Leasing,"[5] I've rated ""Finance and insurance"", ""real estate and rental and leasing"", ""professional and technical services"", ""management, administrative, and support services"", ""public administration"" as highly vulnerable. This is because unequal AI performance, such as disproportionately favoring men in hiring decisions, judging people of color as more likely to be guilty, providing smaller loans to minorities, or approving rental applications primarily for Caucasian applicants—carries serious consequences. These biases deny opportunities to people of color, minorities, and marginalized communities while reinforcing existing discrimination and power imbalances against these groups.",Vulnerability,Higher,complete,
Sector,Professional and Technical Services,"[5] I've rated ""Finance and insurance"", ""real estate and rental and leasing"", ""professional and technical services"", ""management, administrative, and support services"", ""public administration"" as highly vulnerable. This is because unequal AI performance, such as disproportionately favoring men in hiring decisions, judging people of color as more likely to be guilty, providing smaller loans to minorities, or approving rental applications primarily for Caucasian applicants—carries serious consequences. These biases deny opportunities to people of color, minorities, and marginalized communities while reinforcing existing discrimination and power imbalances against these groups.",Vulnerability,Higher,complete,
Sector,"Management, Administrative, and Support Services","[5] I've rated ""Finance and insurance"", ""real estate and rental and leasing"", ""professional and technical services"", ""management, administrative, and support services"", ""public administration"" as highly vulnerable. This is because unequal AI performance, such as disproportionately favoring men in hiring decisions, judging people of color as more likely to be guilty, providing smaller loans to minorities, or approving rental applications primarily for Caucasian applicants—carries serious consequences. These biases deny opportunities to people of color, minorities, and marginalized communities while reinforcing existing discrimination and power imbalances against these groups.",Vulnerability,Higher,complete,
Sector,Public Administration excluding National Security,"[5] I've rated ""Finance and insurance"", ""real estate and rental and leasing"", ""professional and technical services"", ""management, administrative, and support services"", ""public administration"" as highly vulnerable. This is because unequal AI performance, such as disproportionately favoring men in hiring decisions, judging people of color as more likely to be guilty, providing smaller loans to minorities, or approving rental applications primarily for Caucasian applicants—carries serious consequences. These biases deny opportunities to people of color, minorities, and marginalized communities while reinforcing existing discrimination and power imbalances against these groups.",Vulnerability,Higher,complete,
Actor,General,"Original data and content creators (i.e., all of us who have created content on the internet). AI models are fundamentally numeric systems. In many ways, AI holds up a mirror reflecting the biases, stereotypes, discrimination, and unequal treatment humans already exhibit toward certain groups and communities. Therefore, all of us who have created internet content bear some responsibility for the biased material that contributes to unequal AI performance across groups. Whether it's police officers more likely to judge Black individuals as guilty, or livestock marketing professionals who consistently romanticize farming as cows grazing on pastures under clear blue skies, original content creators are responsible for the unequal performance patterns that AI systems have learned.",Responsibility,Higher,complete,"suggesting new categories of actors, not useful for experts updating their ratings"
Actor,General,"Our pre-internet ancestors may also bear indirect responsibility, as they created the original cultural narratives and histories that embedded these stereotypes and biases into our collective consciousness, shaping how we were raised and how we think. These deeply rooted patterns then influence the content we create, which subsequently trains AI systems.",Responsibility,Higher,,"not a useful comment for experts updating their ratings, remove"
Actor,AI Developer (General-purpose AI),"[1] AI developer (General-purpose AI) – primarily responsible. General-purpose AI developers hold ultimate responsibility because they possess complete knowledge of their AI systems, including training data, filtering processes, system prompts, and safety guidelines. With their technical expertise (high ability) and professional obligation to detect and thoroughly test for unequal treatment and performance across groups (high obligation). They operate at the foundation of the AI ecosystem and bear primary responsibility for AI's behavior.",Responsibility,Higher,complete,
Actor,AI Deployer,"[2] AI deployer - moderately responsible. AI deployers are responsible for thoroughly testing deployed AI systems, creating system prompts to guide model behavior, customizing models for specific use cases, and establishing safety guidelines (high obligation and high causal influence). However, their ability is constrained when using closed-source models, because they lack access to black-box systems' inner workings, training data, and original system prompts (low-to-medium ability).",Responsibility,Lower,complete,
Actor,AI Governance Actor,"[3] AI governance actor - primarily responsible. Governance actors has the authority to create policies, laws, frameworks, and standards governing AI systems. They bear responsibility for properly overseeing and evaluating AI models, which involves detecting when AI systems are showing unfair treatment across groups. Although they may lack technical expertise to directly modify AI behaviors, their regulatory authority makes them primarily responsible for establishing the frameworks that prevent unequal performance across groups.",Responsibility,Higher,complete,
Actor,AI User,"[3] AI user - highly responsible. Although users cannot control models' inner workings (low-to-medium capability), they can employ prompt engineering techniques to balance performance across different groups, they are also responsible for checking and verifying results are not biased against certain groups (high obligation and causal influence). However, some model behaviors remain beyond user control even with extensive prompt engineering, such as automated prompt revision processes that cannot be disabled.",Responsibility,Higher,complete,
Actor,AI Infrastructure Provider,"[4] AI infrastructure provider - primarily responsible. While cloud computing and chip providers bear minimal responsibility, I rate this sector as primarily responsible due to ""data providers"" within this category. Data labeling and crowdsourcing companies like Outlier AI and Amazon MTurk are responsible to an extent to recruit people from diverse backgrounds to label data, ensure diverse representation, ensure fair treatment across groups, and filter out discriminatory, biased, and toxic content from training data. They should review labeled content and establish clear guidelines about unacceptable and discriminatory content on their platforms.",Responsibility,Higher,complete,
Actor,AI Developer (Specialized AI),"[5] AI developer (specialized AI) - primarily responsible. Specialized AI developers bear even greater responsibility than general-purpose developers due to their domain expertise. When domain-specialized AI systems still produce biased representations despite developers possessing both technical expertise and domain knowledge, this represents a more severe case with greater responsibility since they have the necessary knowledge to create fair treatment or performance across groups.",Responsibility,Higher,complete,
Actor,Affected Stakeholder,"[6] Affected stakeholder - not at all responsible. Affected stakeholders should be included in AI development to voice concerns and share perspectives, ensuring equal treatment across groups. However, they should not be held responsible when their voices are excluded from this process, or when they do not get treated equally, as holding them responsible would constitute victim blaming.",Responsibility,Lower,complete,
Actor,General,Data curators / Aggregators - Highly responsible,Responsibility,Higher,complete,"empty/no justifications in content, remove "
Actor,General,Auditors - Highly responsible,Responsibility,Higher,complete,"empty/no justifications in content, remove "
Actor,General,Data providers,Responsibility,Higher,complete,"empty/no justifications in content, remove "
Actor,General,Much like 1.2,Responsibility,Neutral,complete,"empty/no justifications in content, remove "
Sector,Finance and Insurance,Finance and Insurance/Health Care and Social Assistance (Extremely vulnerable) - While finance and health care are considered extremely vulnerable as we're dealing with wealth disparities via biased financial decisions and misdiagnosis and life-threatening disparities.,Vulnerability,Higher,complete,
Sector,Health Care and Social Assistance,Finance and Insurance/Health Care and Social Assistance (Extremely vulnerable) - While finance and health care are considered extremely vulnerable as we're dealing with wealth disparities via biased financial decisions and misdiagnosis and life-threatening disparities.,Vulnerability,Higher,complete,
Sector,Professional and Technical Services,"Professional & Technical Services / Management Administrative, and Support Services (Highly Vulnerable) - some services can be considered moderately vulnerable such as consulting and professional decision-making, as bias can have a negative affect with client recommendations and service qualities. But with legal service tied to professional services as well, collectively, this is marked as highly vulnerable since legal decision making can be detrimental with bias.",Vulnerability,Higher,complete,
Sector,"Management, Administrative, and Support Services","Professional & Technical Services / Management Administrative, and Support Services (Highly Vulnerable) - some services can be considered moderately vulnerable such as consulting and professional decision-making, as bias can have a negative affect with client recommendations and service qualities. But with legal service tied to professional services as well, collectively, this is marked as highly vulnerable since legal decision making can be detrimental with bias.",Vulnerability,Higher,complete,
Actor,AI Deployer,"AI Deployers (Highly Responsible) - AI Deployer has a direct user impact while implementing around AI Developer systems. While deployers decide which foundational model to use, they need to ensure that the model is fair as well as provide fairness constraints - direct duty to users who are using the deployer's platform",Responsibility,Higher,complete,
Actor,AI Governance Actor,AI Governance Actors (Highly Responsible) - ensures the control of the regulatory environment and ensures fairness and protect civil rights in the AI systems,Responsibility,Higher,complete,
Actor,"Commentary, AI Developer (General-purpose AI)","Any ""vulnerability"" ascribed to AI developers or deployers has to do with harms caused to their organizational reputation, which is extremely different from the tangible individual harms that users would experience from this risk",Vulnerability,Neutral ,complete,
Actor,"Commentary, AI Developer (General-purpose AI)","Any ""vulnerability"" ascribed to AI developers or deployers has to do with harms caused to their organizational reputation, which is extremely different from the tangible individual harms that users would experience from this risk",Vulnerability,Neutral ,complete,
Actor,AI Infrastructure Provider,Ascribed some responsibility to AI Infrastructure Providers because it included data providers. They certainly do have the capability to address this risk either through better data cleaning or by flagging inadequacies in their data or transparently reporting on their data collection practices that can inform downstream development,Responsibility,Higher,complete,
Actor,Affected Stakeholder,"Since affected stakeholders included advocacy groups, ascribed some responsibility to them given their expertise on the impact on target group's which can be helpful to mitigate such risks in the future",Responsibility,Higher,complete,
Actor,AI Developer (Specialized AI),Responsibility of the Specialized AI developers is entirely contingent on the domain of the model and its application,Responsibility,Neutral,complete,
Sector,General,"Unequal performance across groups can concern any type of group (not only group of people), for instance in trade it can be unequal performance between goods A and goods B. I don't see why this would affect certain sectors less than others, so I rated them all as ""Highly vulnerable"".",Vulnerability,Higher,complete,
Actor,AI Developer (Specialized AI),"Higher responsibility for AI developers if specialized than GPAI: the more specialized the system is, the easier it is to identify relevant groups for the use case and the more they should investigate group differences.",Responsibility,Higher,complete,
Actor,AI Developer (General-purpose AI),"Higher responsibility for AI developers if specialized than GPAI: the more specialized the system is, the easier it is to identify relevant groups for the use case and the more they should investigate group differences.",Responsibility,Lower,complete,
Actor,General,"Same issues, not enough context for the use case in these sectors",Responsibility,Neutral,complete,exclude - not useful for updating assessments
Summary,AI Developer (General-purpose AI),"Comments overwhelmingly emphasized GPAI developers' primary responsibility as they are the root cause of technical disparities, defining foundations and frameworks for fairness with actual power to address bias issues. Multiple responses noted developers control model behavior, training data, and have complete knowledge of systems including safety guidelines, though some noted they may be unaware of third-party deployment contexts. Comments emphasized developers bear responsibility for creating ethically developed tech and ensuring models are trained on unbiased data.",Responsibility,Higher,,
Summary,AI Developer (Specialized AI),"Comments consistently rated specialized developers as highly to primarily responsible, with even greater responsibility than general-purpose developers due to domain expertise. Multiple responses emphasized the more specialized the system, the easier to identify relevant groups and investigate differences, with control over application in sensitive domains enabling mitigation of performance disparities. One comment noted responsibility is entirely contingent on domain and application.",Responsibility,Higher,,
Summary,AI Developer (Specialized AI),"Comments noted specialized developers face high vulnerability as biased performance creates legal, reputational, and operational consequences.",Vulnerability,Higher,,
Summary,AI Deployer,"Comments unanimously emphasized deployers' high to primary responsibility as they operationalize fairness, control application in sensitive domains, and have highest capability through deployment context knowledge. Multiple responses noted deployers decide specific deployment, understand affected populations, and bear responsibility for ensuring models are fair and providing fairness constraints, with direct duty to platform users.",Responsibility,Higher,,
Summary,AI Deployer,"Comments characterized deployers as highly vulnerable alongside specialized developers, as biased performance in their systems creates legal, reputational, and operational consequences, though vulnerability relates to organizational reputation rather than tangible individual harms.",Vulnerability,Higher,,
Summary,AI Infrastructure Provider,"Comments varied on infrastructure providers' responsibility, with most noting marginal role as bias issues are primarily known by developers. However, some emphasized data providers specifically have high responsibility through capability to address risks via better data cleaning, flagging inadequacies, and transparent reporting. Comments noted data labeling companies should ensure diverse representation and filter discriminatory content.",Responsibility,Lower,,
Summary,AI Governance Actor,"Comments consistently emphasized governance actors' primary to high responsibility as they enforce compliance, define frameworks for fairness, and ensure control of regulatory environment protecting civil rights. Multiple responses noted they create policies and standards with authority for oversight despite potentially lacking technical expertise. One comment highlighted industry bodies' responsibility through self-regulation and establishing industry standards.",Responsibility,Higher,,
Summary,AI User,"Comments varied widely on user responsibility, with most characterizing users as having minimal responsibility lacking agency and resources. However, several emphasized users bear responsibility for researching models, making responsible selections, and doing homework to pick ethical models. Some noted users can employ prompt engineering to balance performance and verify results aren't biased, though model behaviors often remain beyond control.",Responsibility,Lower,,
Summary,AI User,"Comments consistently rated users as extremely vulnerable alongside affected stakeholders, directly experiencing inaccurate or unfair outcomes such as patients misdiagnosed, students mis-scored, and applicants denied opportunities.",Vulnerability,Higher,,
Summary,Affected Stakeholder,"Comments unanimously characterized affected stakeholders as having no responsibility, lacking agency and resources, with holding them responsible constituting victim blaming. Comments noted advocacy groups can lend expertise helpful for mitigating risks through capability not obligation, and stakeholders should be included to voice concerns but not held responsible when excluded.",Responsibility,Lower,,
Summary,Affected Stakeholder,"Comments unanimously rated affected stakeholders as extremely vulnerable, directly experiencing inaccurate or unfair outcomes including misdiagnosis, mis-scoring, and denied opportunities.",Vulnerability,Higher,,
Summary,Finance and Insurance,"Comments unanimously characterized finance as extremely to highly vulnerable, with bias in AI decisions causing large-scale irreversible harm through wealth disparities via biased financial decisions. Multiple responses noted historical inequities, high-stakes outcomes, and life-altering consequences from unequal performance in lending and insurance pricing, with the sector amplifying existing discrimination against minorities.",Vulnerability,Higher,,
Summary,Health Care and Social Assistance,"Comments unanimously rated healthcare as extremely vulnerable, with group-level disparities directly affecting rights, health, and life opportunities. Multiple responses emphasized social and biological realities require different prediction logic for subgroups, with existing medical data designed primarily for Caucasian populations performing poorly for people of color, potentially leading to death or severe harm in critical contexts.",Vulnerability,Higher,,
Summary,Educational Services,"Comments consistently characterized education as highly to extremely vulnerable, with unequal performance compounding systemic inequities. Multiple responses noted AI could democratize education but instead furthers imbalance when performing worse in languages of marginalized communities, broadening gaps between privileged English-speaking backgrounds and others.",Vulnerability,Higher,,
Summary,National Security,"Comments consistently rated national security as extremely to highly vulnerable, combining historical inequities with high-stakes outcomes. Multiple responses emphasized AI bias combined with automated weapons creates recipe for disaster with serious large-scale consequences, with bias against certain groups creating democratic backlash.",Vulnerability,Higher,,
Summary,Public Administration excluding National Security,"Comments consistently characterized public administration as highly vulnerable, with unequal treatment in welfare or justice undermining equity and trust while compounding systemic inequities. Multiple responses noted AI performance disparities in judgments disproportionately affect people of color, reinforcing existing discrimination and power imbalances.",Vulnerability,Higher,,
Summary,Information,"Comments consistently rated information sector as extremely to highly vulnerable, with bias decisions causing large-scale irreversible harm and systems amplifying bias at scale through widespread AI deployment.",Vulnerability,Higher,,
Summary,Real Estate and Rental and Leasing,"Comments characterized real estate as highly vulnerable with life-altering consequences, particularly through AI approving rental applications primarily for Caucasian applicants, denying opportunities to minorities and reinforcing discrimination.",Vulnerability,Higher,,
Summary,Professional and Technical Services,"Comments rated professional services as highly vulnerable, with unequal AI performance disproportionately favoring men in hiring decisions while denying opportunities to marginalized communities and reinforcing existing power imbalances. Legal services face particularly detrimental impacts from bias in decision-making.",Vulnerability,Higher,,
Summary,"Management, Administrative, and Support Services","Comments characterized management services as highly vulnerable, particularly in hiring decisions disproportionately favoring men, denying opportunities to minorities and reinforcing existing discrimination and power imbalances.",Vulnerability,Higher,,
Summary,Scientific Research and Development,"Comments varied on scientific research vulnerability, with most characterizing it as minimally to lower vulnerable with limited direct demographic impact and exposure limited to secondary effects like biased datasets, though they may indirectly propagate biases downstream.",Vulnerability,Lower,,
Summary,"Agriculture, Mining, Construction and Manufacturing","Comments characterized these sectors as minimally to lower vulnerable with limited direct demographic impact and exposure limited to secondary effects. One comment rated agriculture highly vulnerable regarding AI performance across farm animal groups and precision livestock farming, focusing on intensive farming systems and animal monitoring.",Vulnerability,Lower,,
Summary,"Accommodation, Food, and Other Services","Comments characterized accommodation services as having relatively lower vulnerability, though they may indirectly propagate biases downstream.",Vulnerability,Lower,,
Summary,"Arts, Entertainment, and Recreation",No comments specifically addressed this sector's vulnerability to unequal performance across groups.,Vulnerability,Lower,,
Summary,"Trade, Transportation, and Utilities",No comments specifically addressed these sectors' vulnerability to unequal performance across groups.,Vulnerability,Lower,,