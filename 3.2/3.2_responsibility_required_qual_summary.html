<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3.2 Pollution of information ecosystem and loss of consensus reality - Responsibility</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;        }

        h1 {
            text-align: center;
            margin-bottom: 8px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .legend {
            text-align: center;
            font-size: 12px;
            color: #888888;
            font-style: italic;
            margin-bottom: 12px;
            padding: 8px;
            background-color: #f9f9f9;
            border-radius: 5px;
            border: 1px solid #e0e0e0;
        }

        .selection-title {


            text-align: center;


            font-size: 14px;


            font-weight: 600;


            color: #666666;


            margin-bottom: 10px;


        }



        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 15px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 12px 20px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #000000;
            color: white;
            border-color: #000000;
        }

        .actor-section {
            display: none;
        }

        .actor-section.active {
            display: block;
        }

        .content-grid {
            display: flex;
            width: 100%;
            gap: 10px;
            min-width: 0;
        }

        .content-column {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;            min-width: 0;
            overflow-wrap: break-word;
        }

        .criteria-header {
            font-size: 15px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid;
        }

        .criteria-header.higher {
            color: #FF0000;
            border-bottom-color: #FF0000;
        }

        .criteria-header.lower {
            color: #2E5C8A;
            border-bottom-color: #2E5C8A;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 14px;
            padding: 8px 0;
            border-bottom: 1px dotted #a32035;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 12px;
            line-height: 1.3;
            color: #000000;
        }

    </style>
</head>
<body>
    <div class="container">
        <h1>3.2 Pollution of information ecosystem and loss of consensus reality - Responsibility</h1>

        
        <div class="legend">Numbers in brackets (X) indicate the number of expert comments supporting each assessment</div>
        <div class="selection-title">Select an actor:</div>
        <div class="nav-pills">
            
            <button class="nav-pill active" data-target="AIDeveloperGeneralpurposeAI">
                AI Developer (General-purpose AI)
            </button>
            <button class="nav-pill " data-target="AIDeployer">
                AI Deployer
            </button>
            <button class="nav-pill " data-target="AIGovernanceActor">
                AI Governance Actor
            </button>
            <button class="nav-pill " data-target="AIUser">
                AI User
            </button>
        </div>

        <div class="content-sections">
            
            <div class="actor-section active" id="AIDeveloperGeneralpurposeAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments consistently emphasized GPAI developers' primary responsibility for creating and distributing systems that pollute the information ecosystem, with strong causal influence through model design, defaults, and release practices that shape misinformation supply. Multiple responses noted developers control personalization features and core capabilities that enable echo chambers, with one noting their need to ensure diverse training data to avoid model collapse.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (6)</summary>
                <ul class="quote-list">
                    <li>"My assessments highlight that general-purpose developers and deployers are primarily responsible, since they create and distribute the AI systems that can pollute the information ecosystem."</li><li>"The primary burden lies on general-purpose AI developers who shape the core capabilities of models."</li><li>"- General-purpose AI developers: strong causal influence. Model design, defaults, tooling, and release practices shape misinformation supply; they can ship provenance/watermarking, detection APIs, rate limits, red-team and eval protocols."</li><li>"[1] AI Developer (general-purpose) - primarily responsible: I rated general-purpose AI developers as primarily responsible because they have ultimate control over model behavior and design. They make deliberate choices about personalization features, such as having models remember user chat history and preferences. These design decisions directly enable echo chambers by creating systems that increasingly align with users' existing beliefs rather than challenging them with diverse perspectives. They have both the technical capability and decision-making authority to prevent information ecosystem pollution."</li><li>"AI developers, deployers, and governments should fund AI literacy programs that go beyond teaching people merely how to use—or not misuse—the tools. Such programs should also focus on training individuals to critically assess AI outputs, given that current models are flawed, prone to hallucinations, and subject to bias."</li><li>"Primary responsibility should lie with AI model developers / vendors, due to the perverse incentives surrounding making AI output indistinguishable from human-created output."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">One commenter said: "Reduced the level of responsibility of GPAI developers because this risk manifest mainly in the context of its deployment"</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments unanimously emphasized deployers' primary to high responsibility for creating and distributing systems that can pollute the information ecosystem, with greatest operational capability through choosing fine-tunes, prompts, guardrails, and moderation. Multiple responses noted deployers should explain provenance of AI-generated content and bear responsibility for user-facing system design, though those using closed models have less control than developers.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (6)</summary>
                <ul class="quote-list">
                    <li>"My assessments highlight that general-purpose developers and deployers are primarily responsible, since they create and distribute the AI systems that can pollute the information ecosystem."</li><li>"...deployers and governance actors serve as critical buffers and enablers of (or protection from) misuse."</li><li>"- AI deployers: greatest operational capability. They choose fine-tunes, prompts, guardrails, moderation, UX, and distribution; they monitor misuse and can throttle or roll back."</li><li>"[2] AI Deployer - highly responsible: AI deployers bear high responsibility as they design the user-facing systems and can choose how to implement personalization features on their platforms. However, when using closed models via APIs, they have less control than general-purpose developers since they don't have full visibility into the underlying model architecture and behavior."</li><li>"AI Deployers are responsible to delivering content, but that may need to appeal to users. Deployers should explain provenance of AI-generated content as possible."</li><li>"AI developers, deployers, and governments should fund AI literacy programs that go beyond teaching people merely how to use—or not misuse—the tools. Such programs should also focus on training individuals to critically assess AI outputs, given that current models are flawed, prone to hallucinations, and subject to bias."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">No comments provided.</p>
                            
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments overwhelmingly rated governance actors as highly responsible for regulation, transparency requirements, and oversight essential to mitigate filter bubbles and disinformation. Multiple responses emphasized their obligation to set provenance/transparency rules, fund detection capacity, and coordinate public-information safeguards, with one noting they should promote diverse and healthy ecosystems for reality-based information. Some comments noted governance actors shouldn't legislate shared reality for freedom of speech reasons.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (7)</summary>
                <ul class="quote-list">
                    <li>"Governance actors are highly responsible, as regulation, transparency requirements, and oversight are essential to mitigate filter bubbles and disinformation campaigns."</li><li>"...deployers and governance actors serve as critical buffers and enablers of (or protection from) misuse."</li><li>"I so not see a techical or market-based fix to loss of consensus reality risks, therefore it becomes a regulatory problem. Specifically, regulators can take initiatives to promote a diverse and healthy ecosystem for reality-based information,"</li><li>"#NAME?"</li><li>"[3] AI Governance Actor - highly responsible: Governance actors are highly responsible because they set standards and regulations that could prevent or mitigate information ecosystem pollution. Though they lack direct technical control over individual models."</li><li>"AI developers, deployers, and governments should fund AI literacy programs that go beyond teaching people merely how to use—or not misuse—the tools. Such programs should also focus on training individuals to critically assess AI outputs, given that current models are flawed, prone to hallucinations, and subject to bias."</li><li>"AI Governance Actor - highly responsible, due to the reason that the regulatory frameworks requiring algorithmic transparency and content diversity where the EU's Digital Services Act represents the first major attempt to address this gap."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">[SUMMARY NOT FOUND - SUMMARY NEEDED]</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"For some other AI harms, we may want the government regulator to absolutely forbid certain behaviors or the the AI developer to voluntarily absolutely abstain from certain behaviors in the absence of regulation, but for the information ecosystem, we don't want either of those entities to try to legislate a shared reality."</li><li>"Governance has little to offer here besides offering some oracle for 'ground truth.'"</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
            <div class="actor-section " id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text">[SUMMARY NOT FOUND - SUMMARY NEEDED]</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"I marked AI User as moderately responsible because I think a focus on personal responsibility to remain skeptical of information presented is important."</li><li>"It's incumbent upon users and stakeholders to understand that provenance is as important as content when evaluating information."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Responsibility</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>Summary of expert comments:</strong> Comments varied widely on user responsibility, with most characterizing users as having minimal responsibility due to lack of systemic influence and limited capability. However, several noted moderate responsibility for personal skepticism, understanding provenance importance, and potential to amplify negative effects through content distribution. One comment emphasized users' deliberate employment of AI for campaigns bears direct responsibility.</p>
                            
            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"Users and affected stakeholders cannot reasonably be held responsible, as they lack systemic influence."</li><li>"Users and infrastructure providers are downstream and have less direct influence, though user education remains important."</li><li>"Low responsibility: AI users (limited capability)."</li><li>"AI User - moderately responsible: Average users have moderate responsibility because most don't understand how AI personalization works or recognize echo chamber formation. It's unrealistic to expect all users to be critical thinkers about AI behavior or to understand the philosophical implications of personalized responses. They often believe AI outputs are objectively correct rather than tailored to their preferences."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.actor-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    // Remove active class from all pills and sections
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    // Add active class to clicked pill
                    this.classList.add('active');

                    // Show corresponding section
                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>